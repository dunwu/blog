<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: light)">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/blog/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/blog/uploads/favicon.ico">
  <link rel="icon" type="image/png" sizes="16x16" href="/blog/uploads/favicon.ico">
  <link rel="mask-icon" href="/blog/images/logo.svg" color="#222">

<link rel="stylesheet" href="/blog/css/main.css">



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@7.0.0/css/all.min.css" integrity="sha256-VHqXKFhhMxcpubYf9xiWdCiojEbY9NexQ4jh8AxbvcM=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/themes/blue/pace-theme-minimal.css">
  <script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js" integrity="sha256-gqd7YTjg/BtfqWSwsJOvndl0Bxc8gFImLEkXQT8+qj0=" crossorigin="anonymous" defer></script>

<script class="next-config" data-name="main" type="application/json">{"hostname":"dunwu.github.io","root":"/blog/","images":"/blog/images","scheme":"Pisces","darkmode":true,"version":"8.25.0","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":true,"codeblock":{"theme":{"light":"atom-one-light","dark":"atom-one-dark"},"prism":{"light":"atom-one-light","dark":"atom-one-dark"},"copy_button":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"language":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":"gitalk","storage":true,"lazyload":true,"nav":null,"activeClass":"gitalk"},"stickytabs":false,"motion":{"enable":true,"async":false,"duration":200,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/blog/search.xml","localsearch":{"enable":true,"top_n_per_article":1,"unescape":false,"preload":false,"trigger":"auto"}}</script><script src="/blog/js/config.js" defer></script>

    <meta name="description" content="钝悟的个人博客">
<meta property="og:type" content="website">
<meta property="og:title" content="Dunwu Blog">
<meta property="og:url" content="https://dunwu.github.io/blog/page/13/index.html">
<meta property="og:site_name" content="Dunwu Blog">
<meta property="og:description" content="钝悟的个人博客">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="钝悟 ◾ Dunwu">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://dunwu.github.io/blog/page/13/">


<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"zh-CN","comments":"","permalink":"","path":"page/13/index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>Dunwu Blog</title>
  








  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous" defer></script>
<script src="/blog/js/utils.js" defer></script><script src="/blog/js/motion.js" defer></script><script src="/blog/js/sidebar.js" defer></script><script src="/blog/js/next-boot.js" defer></script>

  <script src="https://cdn.jsdelivr.net/npm/hexo-generator-searchdb@1.5.0/dist/search.js" integrity="sha256-xFC6PJ82SL9b3WkGjFavNiA9gm5z6UBxWPiu4CYjptg=" crossorigin="anonymous" defer></script>
<script src="/blog/js/third-party/search/local-search.js" defer></script>





  <script src="/blog/js/third-party/pace.js" defer></script>


  





  <noscript>
    <link rel="stylesheet" href="/blog/css/noscript.css">
  </noscript>
<style>.darkmode--activated{--body-bg-color:#282828;--content-bg-color:#333;--card-bg-color:#555;--text-color:#ccc;--blockquote-color:#bbb;--link-color:#ccc;--link-hover-color:#eee;--brand-color:#ddd;--brand-hover-color:#ddd;--table-row-odd-bg-color:#282828;--table-row-hover-bg-color:#363636;--menu-item-bg-color:#555;--btn-default-bg:#222;--btn-default-color:#ccc;--btn-default-border-color:#555;--btn-default-hover-bg:#666;--btn-default-hover-color:#ccc;--btn-default-hover-border-color:#666;--highlight-background:#282b2e;--highlight-foreground:#a9b7c6;--highlight-gutter-background:#34393d;--highlight-gutter-foreground:#9ca9b6}.darkmode--activated img{opacity:.75}.darkmode--activated img:hover{opacity:.9}.darkmode--activated code{color:#69dbdc;background:0 0}button.darkmode-toggle{z-index:9999}.darkmode-ignore,img{display:flex!important}.beian img{display:inline-block!important}</style></head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/blog/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">Dunwu Blog</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">大道至简，知易行难</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/blog/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/blog/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/blog/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签<span class="badge">428</span></a></li><li class="menu-item menu-item-categories"><a href="/blog/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类<span class="badge">124</span></a></li><li class="menu-item menu-item-archives"><a href="/blog/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档<span class="badge">508</span></a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
      <div class="search-header">
        <span class="search-icon">
          <i class="fa fa-search"></i>
        </span>
        <div class="search-input-container">
          <input autocomplete="off" autocapitalize="off" maxlength="80"
                placeholder="搜索..." spellcheck="false"
                type="search" class="search-input">
        </div>
        <span class="popup-btn-close" role="button">
          <i class="fa fa-times-circle"></i>
        </span>
      </div>
      <div class="search-result-container">
        <div class="search-result-icon">
          <i class="fa fa-spinner fa-pulse fa-5x"></i>
        </div>
      </div>
    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="钝悟 ◾ Dunwu"
      src="/blog/uploads/avatar.gif">
  <p class="site-author-name" itemprop="name">钝悟 ◾ Dunwu</p>
  <div class="site-description" itemprop="description">钝悟的个人博客</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/blog/archives/">
          <span class="site-state-item-count">508</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/blog/categories/">
        <span class="site-state-item-count">124</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/blog/tags/">
        <span class="site-state-item-count">428</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/dunwu" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;dunwu" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:forbreak@163.com" title="E-Mail → mailto:forbreak@163.com" rel="noopener me" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>
  <div class="cc-license animated" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" class="cc-opacity" rel="noopener" target="_blank"><img src="https://cdn.jsdelivr.net/npm/@creativecommons/vocabulary@2020.11.3/assets/license_badges/small/by_nc_sa.svg" alt="Creative Commons"></a>
  </div>

        </div>
      </div>
        <div class="back-to-top animated" role="button" aria-label="返回顶部">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://dunwu.github.io/blog/pages/d101fb71/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/blog/uploads/avatar.gif">
      <meta itemprop="name" content="钝悟 ◾ Dunwu">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Dunwu Blog">
      <meta itemprop="description" content="钝悟的个人博客">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | Dunwu Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/blog/pages/d101fb71/" class="post-title-link" itemprop="url">RocketMQ FAQ</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-07-12 07:49:48" itemprop="dateCreated datePublished" datetime="2022-07-12T07:49:48+08:00">2022-07-12</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-09-13 17:56:53" itemprop="dateModified" datetime="2025-09-13T17:56:53+08:00">2025-09-13</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/blog/categories/%E5%88%86%E5%B8%83%E5%BC%8F/" itemprop="url" rel="index"><span itemprop="name">分布式</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/blog/categories/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F%E9%80%9A%E4%BF%A1/" itemprop="url" rel="index"><span itemprop="name">分布式通信</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/blog/categories/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F%E9%80%9A%E4%BF%A1/MQ/" itemprop="url" rel="index"><span itemprop="name">MQ</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/blog/categories/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F%E9%80%9A%E4%BF%A1/MQ/RocketMQ/" itemprop="url" rel="index"><span itemprop="name">RocketMQ</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>1.6k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>1 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="RocketMQ-FAQ"><a href="#RocketMQ-FAQ" class="headerlink" title="RocketMQ FAQ"></a>RocketMQ FAQ</h1><h2 id="API-问题"><a href="#API-问题" class="headerlink" title="API 问题"></a>API 问题</h2><h3 id="connect-to-failed"><a href="#connect-to-failed" class="headerlink" title="connect to &lt;172.17.0.1:10909&gt; failed"></a>connect to <code>&lt;172.17.0.1:10909&gt;</code> failed</h3><p>启动后，Producer 客户端连接 RocketMQ 时报错：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">org.apache.rocketmq.remoting.exception.RemotingConnectException: connect to &lt;<span class="number">172.17</span><span class="number">.0</span><span class="number">.1</span>:<span class="number">10909</span>&gt; failed</span><br><span class="line">    at org.apache.rocketmq.remoting.netty.NettyRemotingClient.invokeSync(NettyRemotingClient.java:<span class="number">357</span>)</span><br><span class="line">    at org.apache.rocketmq.client.impl.MQClientAPIImpl.sendMessageSync(MQClientAPIImpl.java:<span class="number">343</span>)</span><br><span class="line">    at org.apache.rocketmq.client.impl.MQClientAPIImpl.sendMessage(MQClientAPIImpl.java:<span class="number">327</span>)</span><br><span class="line">    at org.apache.rocketmq.client.impl.MQClientAPIImpl.sendMessage(MQClientAPIImpl.java:<span class="number">290</span>)</span><br><span class="line">    at org.apache.rocketmq.client.impl.producer.DefaultMQProducerImpl.sendKernelImpl(DefaultMQProducerImpl.java:<span class="number">688</span>)</span><br><span class="line">    at org.apache.rocketmq.client.impl.producer.DefaultMQProducerImpl.sendSelectImpl(DefaultMQProducerImpl.java:<span class="number">901</span>)</span><br><span class="line">    at org.apache.rocketmq.client.impl.producer.DefaultMQProducerImpl.send(DefaultMQProducerImpl.java:<span class="number">878</span>)</span><br><span class="line">    at org.apache.rocketmq.client.impl.producer.DefaultMQProducerImpl.send(DefaultMQProducerImpl.java:<span class="number">873</span>)</span><br><span class="line">    at org.apache.rocketmq.client.producer.DefaultMQProducer.send(DefaultMQProducer.java:<span class="number">369</span>)</span><br><span class="line">    at com.emrubik.uc.mdm.sync.utils.MdmInit.sendMessage(MdmInit.java:<span class="number">62</span>)</span><br><span class="line">    at com.emrubik.uc.mdm.sync.utils.MdmInit.main(MdmInit.java:<span class="number">2149</span>)</span><br></pre></td></tr></table></figure>

<p>原因：RocketMQ 部署在虚拟机上，内网 ip 为 10.10.30.63，该虚拟机一个 docker0 网卡，ip 为 172.17.0.1。RocketMQ broker 启动时默认使用了 docker0 网卡，Producer 客户端无法连接 172.17.0.1，造成以上问题。</p>
<p>解决方案</p>
<p>（1）干掉 docker0 网卡或修改网卡名称</p>
<p>（2）停掉 broker，修改 broker 配置文件，重启 broker。</p>
<p>修改 conf&#x2F;broker.conf，增加两行来指定启动 broker 的 IP：</p>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">namesrvAddr</span> = <span class="number">10.10</span>.<span class="number">30.63</span>:<span class="number">9876</span></span><br><span class="line"><span class="attr">brokerIP1</span> = <span class="number">10.10</span>.<span class="number">30.63</span></span><br></pre></td></tr></table></figure>

<p>启动时需要指定配置文件</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">nohup</span> sh bin/mqbroker -n localhost:9876 -c conf/broker.conf &amp;</span><br></pre></td></tr></table></figure>
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://dunwu.github.io/blog/pages/6344ebff/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/blog/uploads/avatar.gif">
      <meta itemprop="name" content="钝悟 ◾ Dunwu">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Dunwu Blog">
      <meta itemprop="description" content="钝悟的个人博客">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | Dunwu Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/blog/pages/6344ebff/" class="post-title-link" itemprop="url">话术</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-07-11 09:12:29" itemprop="dateCreated datePublished" datetime="2022-07-11T09:12:29+08:00">2022-07-11</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-09-13 17:56:53" itemprop="dateModified" datetime="2025-09-13T17:56:53+08:00">2025-09-13</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/blog/categories/%E5%B7%A5%E4%BD%9C/" itemprop="url" rel="index"><span itemprop="name">工作</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/blog/categories/%E5%B7%A5%E4%BD%9C/%E6%95%88%E8%83%BD/" itemprop="url" rel="index"><span itemprop="name">效能</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/blog/categories/%E5%B7%A5%E4%BD%9C/%E6%95%88%E8%83%BD/%E6%96%B9%E6%B3%95%E8%AE%BA/" itemprop="url" rel="index"><span itemprop="name">方法论</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>4.4k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>4 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="话术"><a href="#话术" class="headerlink" title="话术"></a>话术</h1><h2 id="职场“黑话”"><a href="#职场“黑话”" class="headerlink" title="职场“黑话”"></a>职场“黑话”</h2><h3 id="二字动词"><a href="#二字动词" class="headerlink" title="二字动词"></a>二字动词</h3><p>复盘，赋能，加持，沉淀，倒逼，落地，串联，协同，反哺，兼容，包装，重组，履约，响应，量化，布局，联动，细分，梳理，输出，加速，共建，支撑，融合，聚合，集成，对标，聚焦，抓手，拆解，抽象，摸索，提炼，打通，打透，吃透，迁移，分发，分装，辐射，围绕，复用，渗透，扩展，开拓，皮实，共创，共建，解耦，集成，对齐，拉齐，对焦，给到，拿到，死磕</p>
<h3 id="三字名词"><a href="#三字名词" class="headerlink" title="三字名词"></a>三字名词</h3><p>感知度，方法论，组合拳，引爆点，点线面，精细化，差异化，平台化，结构化，影响力，耦合性，便捷性，一致性，端到端，短平快，护城河，体验感，<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=%E9%A2%97%E7%B2%92%E5%BA%A6&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22:%22answer%22,%22sourceId%22:2272005267%7D">颗粒度</a></p>
<h3 id="四字名词"><a href="#四字名词" class="headerlink" title="四字名词"></a>四字名词</h3><p>生命周期，价值转化，强化认知，资源倾斜，完善逻辑，抽离透传，复用打法，商业模式，快速响应，定性定量，关键路径，去中心化，结果导向，垂直领域，归因分析，体验度量，信息屏障，资源整合</p>
<h3 id="术语应用"><a href="#术语应用" class="headerlink" title="术语应用"></a>术语应用</h3><p>比如原来你提问：这个问题你准备怎么解决？</p>
<p>现在的你可以说：你这个问题的底层逻辑是什么？顶层设计在哪？最终交付价值是什么？过程的抓手在哪？如何保证回答闭环？你比别人的亮点在哪？优势在哪？你的思考和沉淀是什么？这个问题换成我来问是否会不一样？在这之前，有自己的思考和沉淀吗？这些问题的颗粒度是怎样拆分的，能作为爆点，引发回答者对问题关键路径的探索吗？别人回答了，你能反哺赋能他们，共建团队意识生态吗？只会问而不会解决，你有自己独有的价值吗？</p>
<p>比如你之前只会一脸懵逼的看着他，愣着不敢说话，现在你可以这么回复他：</p>
<p>我们这款产品底层逻辑是打通信息屏障，创建行业新生态。顶层设计是聚焦用户感知赛道，通过差异化和颗粒度达到引爆点。交付价值是在垂直领域采用复用打法达成持久收益。抽离透传归因分析作为抓手为产品赋能，体验度量作为闭环的评判标准。亮点是载体，优势是链路。思考整个生命周期，完善逻辑考虑资源倾斜。方法论是组合拳达到平台化标准。</p>
<h2 id="模板"><a href="#模板" class="headerlink" title="模板"></a>模板</h2><h3 id="yes-and-法则"><a href="#yes-and-法则" class="headerlink" title="yes and 法则"></a>yes and 法则</h3><p>当别人提出一个观点，自己不认同时，我们往往会说，yes，but，这样别人会觉得“那就这样吧，你说什么就是什么吧”的想法，无法形成有效的沟通。</p>
<p>yes-and 的原则首先是要接纳，而不是全身都是刺，即当别人提出观点的时候还没仔细思考就先给予否定，尤其当对方不认可攻击你时，很多人立马想到的就是反击。</p>
<p>然后关键是这里的 and，这里的 and 并不是转折或反驳，而是并且或附加的内容，可以巧妙地避免意见不同甚至冲突，所以 yes-and 不仅仅是做事方式，也是一种特别好的沟通方式，让对方感受很舒服。</p>
<p>【示例】</p>
<p>男朋友特别喜欢爬山，有一天男朋友邀请女生去爬山，女生说了下面的一段话 “我不爱爬上，但是我特别好奇你到山顶后看到的风景，你能爬上去之后能给我拍几样张照片吗？专门为我拍的，然后你下来以后，我在哪个咖啡馆等你，你跟我讲讲此次的经历！”</p>
<p>可以听出来，这位女生并不爱爬山，也没有勉强自己去迎合新的男朋友，而是肯定了男朋友的爱好，并且在此基础上创造了新的情景来继续他们的交流！</p>
<h3 id="PREP-模型"><a href="#PREP-模型" class="headerlink" title="PREP 模型"></a>PREP 模型</h3><blockquote>
<p>PREP 模型用于<strong>表达观点</strong>。</p>
</blockquote>
<p>PREP 四个英文字母分别代表：Point，观点；Reason，理由；Example，案例；Point，再次讲观点。这是最经典的表达结构。</p>
<p>整个 PREP 结构的关键是，开始就要讲出你的观点，点明主题；后面再举出理由来论证观点；案例部分，最好讲自己的经历或故事来解释，这样听众比较容易听懂；最后再重复和强调一下你的观点。</p>
<h3 id="SCQ-A-模型"><a href="#SCQ-A-模型" class="headerlink" title="SCQ-A 模型"></a>SCQ-A 模型</h3><blockquote>
<p>SCQ-A 模型 用于<strong>提出问题，请求帮助</strong>。</p>
</blockquote>
<ul>
<li><strong>situation</strong>：阐述背景</li>
<li><strong>conflict</strong>：阐述冲突</li>
<li><strong>question</strong>：为了解决冲突，你提出要解决的问题</li>
<li><strong>answer</strong>：你的看法</li>
</ul>
<p>【示例】</p>
<p>老板，最近竞争对手上任了新的 CEO，做了一系列措施，比如下调了产品的价格，增大推广和营销，导致现在我们的很多市场被对方蚕食了。</p>
<p>我们现在该如何调整应应对当前的情况，保持市场上的领导位置。</p>
<p>目前我的看法就是优化目前的营销渠道，全面包围对手。</p>
<h3 id="FFC-赞美法则"><a href="#FFC-赞美法则" class="headerlink" title="FFC 赞美法则"></a>FFC 赞美法则</h3><p>所谓 FFC 赞美法，就是指在赞美人的时候，先用自己的语言来表达感受（Feel），然后再进一步通过陈述事实（Fact）来论证自己的感受，最后再通过比较（Compare），来加深对对方的认可，这样对方会感觉特别好。</p>
<h3 id="让对方服从你行为的经典话术"><a href="#让对方服从你行为的经典话术" class="headerlink" title="让对方服从你行为的经典话术"></a>让对方服从你行为的经典话术</h3><p>这个话术一般来讲模板是这样的： 是..还是…&#x2F;是否&#x2F;要不要，xxx 好处是这样。</p>
<p>这里的关键是尽量不让用户思考，提供非 A 即 B 的选项，说某个选项的好处，从而让对方服从你。</p>
<p>比如麦当劳、肯德基有 3 个经典话术，进行快推式产品营销：</p>
<ul>
<li>您是否要加一包薯条，这样可以凑成一个套餐，节省 2 元？（实际上多消费 5 元）</li>
<li>您要不要加 3 元把可乐换成大杯，可以多一半哦？</li>
<li>您要不要加 10 元买个玩具给小朋友呢？</li>
</ul>
<h3 id="沟通中的万能表达模型-观察-感受-需求-请求"><a href="#沟通中的万能表达模型-观察-感受-需求-请求" class="headerlink" title="沟通中的万能表达模型- 观察+感受+需求+请求"></a>沟通中的万能表达模型- 观察+感受+需求+请求</h3><ul>
<li>观察：即你观察的客观事实是什么？注意这里要是事实才行</li>
<li>感受：通过观察之后，你心情感受是怎样的？</li>
<li>需求：你内心希望要解决的问题是什么？</li>
<li>请求：向对方请求你的需求需要得到满足</li>
</ul>
<h3 id="FFA-法则"><a href="#FFA-法则" class="headerlink" title="FFA 法则"></a>FFA 法则</h3><ul>
<li>Fact——事实</li>
<li>Feeling——感受</li>
<li>Action——行动</li>
</ul>
<p>最近一段团队不少新人加入，整体运营效率下降了 30%。（事实）我感觉主要是业务知识传递有些跟不上。（感受）接下来的一周，我会安排老员工一对一辅导每位新人。（行动）</p>
<h2 id="实战"><a href="#实战" class="headerlink" title="实战"></a>实战</h2><p><strong>别人求你办事，如果你说：“这事儿不太好办”，那么资源置换就来了。</strong></p>
<p>不好办说明能办，但需要附加条件，懂的人自然知道接下来应该怎么办。</p>
<p><strong>拒绝借钱：“你知道的，我最近 XX，也没钱。”</strong></p>
<p>遇到借钱，只要你平时不太露富，就好用。</p>
<p>朋友管你借钱，用“你知道的”直接把皮球踢回去，再给个具体理由，比如买了什么东西、投入基金股票里了，随便什么都行。</p>
<p>只要把对方放在知道你没钱的位置上，他就不好再开下一句口，一般会主动结束对话。</p>
<p><strong>表示体贴，但不想真的去接客户，先打电话沟通：“约的地方有点远，需要我去接您吗？”</strong></p>
<p>绝大部分人遇到这样的问句，本能反应是不用，你的目的就达到了。</p>
<p>不过如果真遇到要你接的，这人多半有点矫情，以后相处要注意多恭维一下。</p>
<p><strong>经典汇报话术 1：“老板，我们团队做了 A、B 两版方案，各有优势，您给提提意见，看选哪个好。”</strong></p>
<p>该话术利用了沉锚效应，抛出了二者选其一的锚，避开全部拒绝的选项，引导领导“选一个”、“提意见”，减小被全部驳回的风险。</p>
<p><strong>经典汇报话术 2：“领导，我是这么想的，XXX。第一，X；第二，X；第三，X。”</strong></p>
<p>我们的大脑被训练得听到“第一、第二”就默认为其中有条理、有逻辑，不管其中是不是真的严丝合缝地支撑你的观点。善用一二三做汇报，领导会觉得你准备得很充分，考虑周全。</p>
<p><strong>遇到问题请求领导帮忙：“经过了解，现在碰到了一些情况，我的解决办法是 XX，您看还有没有什么更好的办法。”</strong></p>
<p>不要直接说自己解决不了，让领导想办法。不管自己提出的办法多平庸，都一定要提。</p>
<p><strong>请求他人帮忙：“能请你帮我打印一下文件吗，因为我一会儿真有事。”、“不好意思，能插一下队吗，因为我真的着急。”</strong></p>
<p>善用“因为所以”，“因为所以”是十几年语文教学留给我们的条件反射，不管多离奇的理由，听到的时候都会默认有道理。</p>
<p><strong>聊天想聊下去：揪住对方句子里的关键词+延伸过往彼此交流过的信息。</strong></p>
<blockquote>
<p><strong>例 1</strong></p>
<p>朋友：“今天又加班，烦死了。”</p>
<p>你：“怎么又加班啊，又是上回让你加班的那个领导吗？”</p>
<p><strong>例 2</strong></p>
<p>闺蜜：“我爱豆塌房子了！”</p>
<p>你：“哪个爱豆？上回你说的 XXX？我去！”</p>
</blockquote>
<p><strong>聊天不想继续聊下去：重复关键词+<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=%E6%84%9F%E5%8F%B9%E8%AF%8D&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22:%22answer%22,%22sourceId%22:1791556343%7D">感叹词</a>。重点！不要扩展任何有效信息。</strong></p>
<blockquote>
<p><strong>例 1</strong></p>
<p>朋友：“今天又加班，烦死了”</p>
<p>你：“怎么又加班啊，唉，这叫啥事啊，我无语。”</p>
<p><strong>例 2</strong></p>
<p>闺蜜：“我爱豆又塌房子了！”</p>
<p>你：“又塌房子！我去，也太那个了，绝了！”</p>
</blockquote>
<p><strong>领导说：“辛苦了。”</strong></p>
<p><strong>你：“从中学到很多，很有收获。”</strong></p>
<p>敏而好学、不居功，领导更喜欢这样的下属。</p>
<p><strong>给领导的节日问候：尊称+感谢+互动+祝福</strong></p>
<p>尊称放在前面，引起注意。互动要具体、细节，才有记忆点。</p>
<blockquote>
<p>XX，过年好！<br>感谢您一直的关照，从您身上学到很多。</p>
<p>上次 XX，您说 XXX 我一直记得，受益匪浅。</p>
<p>又到新的一年，祝您和家人新年快乐！</p>
</blockquote>
<p><strong>改变一个人的想法：认同立场，替换观点。</strong></p>
<p>无论任何人，观点不是不可改变的，但立场很难动摇。</p>
<p>比如你的预算交上去，被砍了很大一块，你能做的不是抱怨老板抠门，而是认同老板砍预算是为了控制成本，<strong>开公司是为了赚钱的，这就是老板该有的立场。</strong></p>
<p>所以，如果你不想自己的预算被砍掉，只有你能向老板展示，你做的方案能为他赚更多钱，老板就不会不同意。</p>
<h3 id="工作汇报"><a href="#工作汇报" class="headerlink" title="工作汇报"></a>工作汇报</h3><table>
<thead>
<tr>
<th>实情</th>
<th>话术</th>
</tr>
</thead>
<tbody><tr>
<td>新项目玩砸了</td>
<td>进行了积极的试错，吸收了宝贵的经验。</td>
</tr>
<tr>
<td>数据不好看</td>
<td>有较大的增长空间</td>
</tr>
<tr>
<td>啥也没干</td>
<td>稳定发展</td>
</tr>
<tr>
<td>接下来，我依旧打算啥也不干</td>
<td>保持现有成绩，稳定成果</td>
</tr>
<tr>
<td>数据稍微好看一点</td>
<td>取得了较大增长</td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
</tbody></table>
<h3 id="沟通"><a href="#沟通" class="headerlink" title="沟通"></a>沟通</h3><p><strong>当你觉得对方特别啰嗦，又不好意思打断对方谈话</strong></p>
<p>直接给对方说的话下定义，作评判。例如：“好的”、“那确实不错”、“的确是这样”、“嗯，你说的对” 等等。</p>
<p>对方会瞬间失去表达欲望。</p>
<p><strong>当你接到你不想做的任务时</strong></p>
<ul>
<li>我仔细看了一下这个需求，我这里可能存在 XXX XXX XXX 方面的短板</li>
<li>“领导，我仔细看了一下这个需求，我这里可能存在 XXX XXX XXX 方面的短板”</li>
<li>“想要推进这件事情的话，我可能需要 XXX XXX XXX 方面的支持”</li>
</ul>
<p>好的可能：领导感觉你是认真经过调研，分析了可行性，确实你不太适合，他表示会再考虑考虑</p>
<p>坏的可能：你还是得做，但是这句话的意思已经很明确了：我可是给你说清楚了啊，这件事办砸了，你可不能赖我</p>
<p><strong>当我想刺探什么秘密的时候，我会先说一个结论，然后看对方的反应</strong></p>
<ul>
<li>“我们公司下个月要发奖金你知道对吧，想好怎么花了么？”<ul>
<li>“卧槽你这消息灵通啊”——真的要发</li>
<li>“你听谁说的”——不知道真假，但是可以继续测</li>
</ul>
</li>
<li>这个时候我会再补一句：“我能得到这个消息，说明肯定有人放风给我”<ul>
<li>“胡扯，没有这个规划”——下个月不发奖金</li>
<li>“你每天花花肠子怎么这么多”——没有明确的回应这个问题，我的猜测 80%是真实的</li>
</ul>
</li>
</ul>
<p><strong>临时要交什么汇报，或者做工作总结的时候，不要紧张</strong></p>
<p>【你日常都在做什么】+【这件事的目的是什么】+【你在做这件事的时候有什么困难】+【怎么把这件事做的更好】</p>
<p>比如：</p>
<p>我最近在更新我的知乎账号，坚持回答问题，这是为了能够积累更多的粉丝数，获得更多的认同，也培养自己输出的习惯</p>
<p>但是我发现我的阅读量上去了，但是点赞量还没有起来</p>
<p>所以我决定在写到这一段的时候给读者老爷们磕个头求个赞，哐哐哐</p>
<p><strong>想要说服别人的时候</strong></p>
<p>注意两点：</p>
<ul>
<li><p>先肯定对方的想法</p>
</li>
<li><p>尽量不要出现比较主观的用语，如：“我觉得”、“照我看”、“我认为”</p>
</li>
</ul>
<p>【示例】我仔细听了你的诉求，很有道理，这个需求是可以理解的。但是，我们换个角度想一想：……。而且，我还听别人说：…..。所以，不妨折中一下：…..。你觉得这样如何呢？</p>
<p>当别人给你布置杂活的时候</p>
<p>我们要死扣细节，不停问细节：</p>
<ul>
<li><p>“你说的这件事大概什么时候需要？”</p>
</li>
<li><p>“这个时间点具体到几点？”</p>
</li>
<li><p>“我是微信给你还是邮箱给你？”</p>
</li>
<li><p>“那需要我先给一个计划，你帮我看看合适不合适么？”</p>
</li>
<li><p>……</p>
</li>
</ul>
<p>一个杂活而已，你不停地追问细节，会极大地增加你们之间的沟通成本，让对方崩溃，从此再也不想给你安排杂活。</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2>
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://dunwu.github.io/blog/pages/80a0db57/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/blog/uploads/avatar.gif">
      <meta itemprop="name" content="钝悟 ◾ Dunwu">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Dunwu Blog">
      <meta itemprop="description" content="钝悟的个人博客">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | Dunwu Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/blog/pages/80a0db57/" class="post-title-link" itemprop="url">《极客时间教程 - 职场求生攻略》笔记</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-07-11 07:23:21" itemprop="dateCreated datePublished" datetime="2022-07-11T07:23:21+08:00">2022-07-11</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-09-13 17:56:53" itemprop="dateModified" datetime="2025-09-13T17:56:53+08:00">2025-09-13</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/blog/categories/%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index"><span itemprop="name">笔记</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/blog/categories/%E7%AC%94%E8%AE%B0/%E5%B7%A5%E4%BD%9C/" itemprop="url" rel="index"><span itemprop="name">工作</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>598</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>1 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="《极客时间教程-职场求生攻略》笔记"><a href="#《极客时间教程-职场求生攻略》笔记" class="headerlink" title="《极客时间教程 - 职场求生攻略》笔记"></a>《极客时间教程 - 职场求生攻略》笔记</h1><h2 id="学会如何工作，和学习技术同等重要"><a href="#学会如何工作，和学习技术同等重要" class="headerlink" title="学会如何工作，和学习技术同等重要"></a>学会如何工作，和学习技术同等重要</h2><p>以利益为视角，以换位思考为手段。</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20220711064451.png"></p>
<h2 id="优先级：工作中那么多事情，我要如何安排优先级？"><a href="#优先级：工作中那么多事情，我要如何安排优先级？" class="headerlink" title="优先级：工作中那么多事情，我要如何安排优先级？"></a>优先级：工作中那么多事情，我要如何安排优先级？</h2><h3 id="基于工作性质安排优先级"><a href="#基于工作性质安排优先级" class="headerlink" title="基于工作性质安排优先级"></a>基于工作性质安排优先级</h3><p>工作可以划分为：</p>
<p>业务拓展：需求分析、设计、开发都属于这范畴。</p>
<p>安全问题：安全无小事。要高度重视安全问题。</p>
<p>线上问题：直接影响用户体验和权益。要第一优先级去处理。</p>
<h3 id="基于合作安排优先级"><a href="#基于合作安排优先级" class="headerlink" title="基于合作安排优先级"></a>基于合作安排优先级</h3><p>事情如果没有明显的轻重缓急，优先做那些会阻塞别人工作的事情。</p>
<h3 id="做事情本身的优先级"><a href="#做事情本身的优先级" class="headerlink" title="做事情本身的优先级"></a>做事情本身的优先级</h3><p>我们做事情的时候，如果能把其中的每一步都想清楚，理清依赖关系，安排得井井有条，这就已经事半功倍了。</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20220711065205.png"></p>
<h2 id="沟通：邮件那么重要，你还在轻视邮件吗？"><a href="#沟通：邮件那么重要，你还在轻视邮件吗？" class="headerlink" title="沟通：邮件那么重要，你还在轻视邮件吗？"></a>沟通：邮件那么重要，你还在轻视邮件吗？</h2><h3 id="邮件的特性"><a href="#邮件的特性" class="headerlink" title="邮件的特性"></a>邮件的特性</h3><ol>
<li>异步交流：邮件是一种异步交流的方式，双方有足够的时间准备邮件内容。</li>
<li>无法修改：邮件内容无法修改，这是邮件可靠的基石。</li>
<li>方便扩散：邮件有邮件组，可以很方便地把相关人员加进来，并且保留邮件历史记录。</li>
</ol>
<h3 id="邮件是公司内部的合同"><a href="#邮件是公司内部的合同" class="headerlink" title="邮件是公司内部的合同"></a>邮件是公司内部的合同</h3><p>场景 1：设计确认（邮件的“确认”功能）</p>
<p>场景 2：优先级（邮件的“证据链”功能）</p>
<p>场景 3：大促（邮件的“沟通协调”功能）</p>
<p>场景 4：新业务接入（邮件的“防遗忘”功能）</p>
<p>场景 5：技术升级和 Bug 修复（邮件的“广而告之”功能）</p>
<h3 id="邮件的魅力"><a href="#邮件的魅力" class="headerlink" title="邮件的魅力"></a>邮件的魅力</h3><p>我们都是普通人，普通人没有“背锅”的压力，就没有持久的把事情做好的动力。</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20220711065742.png"></p>
<h2 id="沟通：程序员为什么应该爱上交流？"><a href="#沟通：程序员为什么应该爱上交流？" class="headerlink" title="沟通：程序员为什么应该爱上交流？"></a>沟通：程序员为什么应该爱上交流？</h2><h3 id=""><a href="#" class="headerlink" title=""></a><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20220711070152.png"></h3><h2 id="主观能动性：为什么程序员，需要发挥主观能动性？"><a href="#主观能动性：为什么程序员，需要发挥主观能动性？" class="headerlink" title="主观能动性：为什么程序员，需要发挥主观能动性？"></a>主观能动性：为什么程序员，需要发挥主观能动性？</h2><p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20220711070531.png"></p>
<h2 id="责任的边界：程序员的职责范围仅仅只是被安排的任务吗？"><a href="#责任的边界：程序员的职责范围仅仅只是被安排的任务吗？" class="headerlink" title="责任的边界：程序员的职责范围仅仅只是被安排的任务吗？"></a>责任的边界：程序员的职责范围仅仅只是被安排的任务吗？</h2><p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20220711070722.png"></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://dunwu.github.io/blog/pages/9b5ed9a6/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/blog/uploads/avatar.gif">
      <meta itemprop="name" content="钝悟 ◾ Dunwu">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Dunwu Blog">
      <meta itemprop="description" content="钝悟的个人博客">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | Dunwu Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/blog/pages/9b5ed9a6/" class="post-title-link" itemprop="url">RocketMQ 基本原理</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-07-08 19:02:04" itemprop="dateCreated datePublished" datetime="2022-07-08T19:02:04+08:00">2022-07-08</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-09-13 17:56:53" itemprop="dateModified" datetime="2025-09-13T17:56:53+08:00">2025-09-13</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/blog/categories/%E5%88%86%E5%B8%83%E5%BC%8F/" itemprop="url" rel="index"><span itemprop="name">分布式</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/blog/categories/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F%E9%80%9A%E4%BF%A1/" itemprop="url" rel="index"><span itemprop="name">分布式通信</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/blog/categories/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F%E9%80%9A%E4%BF%A1/MQ/" itemprop="url" rel="index"><span itemprop="name">MQ</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/blog/categories/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F%E9%80%9A%E4%BF%A1/MQ/RocketMQ/" itemprop="url" rel="index"><span itemprop="name">RocketMQ</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>3k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>3 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="RocketMQ-基本原理"><a href="#RocketMQ-基本原理" class="headerlink" title="RocketMQ 基本原理"></a>RocketMQ 基本原理</h1><h2 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h2><p>分布式消息系统作为实现分布式系统可扩展、可伸缩性的关键组件，需要具有高吞吐量、高可用等特点。而谈到消息系统的设计，就回避不了两个问题：</p>
<ol>
<li>消息的顺序问题</li>
<li>消息的重复问题</li>
</ol>
<h3 id="顺序消息"><a href="#顺序消息" class="headerlink" title="顺序消息"></a>顺序消息</h3><h4 id="第一种模型"><a href="#第一种模型" class="headerlink" title="第一种模型"></a>第一种模型</h4><p>假如生产者产生了 2 条消息：M1、M2，要保证这两条消息的顺序，应该怎样做？你脑中想到的可能是这样：</p>
<div align="center">
<img src="http://upload-images.jianshu.io/upload_images/3101171-bb5ec534363e2fb4" />
</div>

<p>假定 M1 发送到 S1，M2 发送到 S2，如果要保证 M1 先于 M2 被消费，那么需要 M1 到达消费端被消费后，通知 S2，然后 S2 再将 M2 发送到消费端。</p>
<p>这个模型存在的问题是，如果 M1 和 M2 分别发送到两台 Server 上，就不能保证 M1 先达到 MQ 集群，也不能保证 M1 被先消费。换个角度看，如果 M2 先于 M1 达到 MQ 集群，甚至 M2 被消费后，M1 才达到消费端，这时消息也就乱序了，说明以上模型是不能保证消息的顺序的。</p>
<div align="center">
<img src="http://upload-images.jianshu.io/upload_images/3101171-5a6313fe906a678b" />
</div>

<h4 id="第二种模型"><a href="#第二种模型" class="headerlink" title="第二种模型"></a>第二种模型</h4><p>如何才能在 MQ 集群保证消息的顺序？一种简单的方式就是将 M1、M2 发送到同一个 Server 上：</p>
<p>这样可以保证 M1 先于 M2 到达 MQServer（生产者等待 M1 发送成功后再发送 M2），根据先达到先被消费的原则，M1 会先于 M2 被消费，这样就保证了消息的顺序。</p>
<p>这个模型也仅仅是理论上可以保证消息的顺序，在实际场景中可能会遇到下面的问题：</p>
<div align="center">
<img src="http://upload-images.jianshu.io/upload_images/3101171-d430f5a3ec6c48ad" />
</div>

<p>只要将消息从一台服务器发往另一台服务器，就会存在网络延迟问题。如上图所示，如果发送 M1 耗时大于发送 M2 的耗时，那么 M2 就仍将被先消费，仍然不能保证消息的顺序。即使 M1 和 M2 同时到达消费端，由于不清楚消费端 1 和消费端 2 的负载情况，仍然有可能出现 M2 先于 M1 被消费的情况。</p>
<p>如何解决这个问题？将 M1 和 M2 发往同一个消费者，且发送 M1 后，需要消费端响应成功后才能发送 M2。</p>
<p>这可能产生另外的问题：如果 M1 被发送到消费端后，消费端 1 没有响应，那是继续发送 M2 呢，还是重新发送 M1？一般为了保证消息一定被消费，肯定会选择重发 M1 到另外一个消费端 2，就如下图所示。</p>
<div align="center">
<img src="http://upload-images.jianshu.io/upload_images/3101171-3c0e822d37a85e1e" />
</div>

<p>这样的模型就严格保证消息的顺序，细心的你仍然会发现问题，消费端 1 没有响应 Server 时有两种情况，一种是 M1 确实没有到达(数据在网络传送中丢失)，另外一种消费端已经消费 M1 且已经发送响应消息，只是 MQ Server 端没有收到。如果是第二种情况，重发 M1，就会造成 M1 被重复消费。也就引入了我们要说的第二个问题，消息重复问题，这个后文会详细讲解。</p>
<p>回过头来看消息顺序问题，严格的顺序消息非常容易理解，也可以通过文中所描述的方式来简单处理。总结起来，要实现严格的顺序消息，简单且可行的办法就是：</p>
<p><strong>保证生产者 - MQServer - 消费者是一对一对一的关系。</strong></p>
<p>这样的设计虽然简单易行，但也会存在一些很严重的问题，比如：</p>
<ol>
<li>并行度就会成为消息系统的瓶颈（吞吐量不够）</li>
<li>更多的异常处理，比如：只要消费端出现问题，就会导致整个处理流程阻塞，我们不得不花费更多的精力来解决阻塞的问题。</li>
</ol>
<p>RocketMQ 的解决方案：通过合理的设计或者将问题分解来规避。如果硬要把时间花在解决问题本身，实际上不仅效率低下，而且也是一种浪费。从这个角度来看消息的顺序问题，我们可以得出两个结论：</p>
<ol>
<li>不关注乱序的应用实际大量存在</li>
<li>队列无序并不意味着消息无序</li>
</ol>
<p>最后我们从源码角度分析 RocketMQ 怎么实现发送顺序消息。</p>
<p>RocketMQ 通过轮询所有队列的方式来确定消息被发送到哪一个队列（负载均衡策略）。比如下面的示例中，订单号相同的消息会被先后发送到同一个队列中：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// RocketMQ 通过 MessageQueueSelector 中实现的算法来确定消息发送到哪一个队列上</span></span><br><span class="line"><span class="comment">// RocketMQ 默认提供了两种 MessageQueueSelector 实现：随机/Hash</span></span><br><span class="line"><span class="comment">// 当然你可以根据业务实现自己的 MessageQueueSelector 来决定消息按照何种策略发送到消息队列中</span></span><br><span class="line"><span class="type">SendResult</span> <span class="variable">sendResult</span> <span class="operator">=</span> producer.send(msg, <span class="keyword">new</span> <span class="title class_">MessageQueueSelector</span>() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> MessageQueue <span class="title function_">select</span><span class="params">(List&lt;MessageQueue&gt; mqs, Message msg, Object arg)</span> &#123;</span><br><span class="line">        <span class="type">Integer</span> <span class="variable">id</span> <span class="operator">=</span> (Integer) arg;</span><br><span class="line">        <span class="type">int</span> <span class="variable">index</span> <span class="operator">=</span> id % mqs.size();</span><br><span class="line">        <span class="keyword">return</span> mqs.get(index);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;, orderId);</span><br></pre></td></tr></table></figure>

<p>在获取到路由信息以后，会根据 MessageQueueSelector 实现的算法来选择一个队列，同一个 OrderId 获取到的肯定是同一个队列。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> SendResult <span class="title function_">send</span><span class="params">()</span>  &#123;</span><br><span class="line">    <span class="comment">// 获取topic路由信息</span></span><br><span class="line">    <span class="type">TopicPublishInfo</span> <span class="variable">topicPublishInfo</span> <span class="operator">=</span> <span class="built_in">this</span>.tryToFindTopicPublishInfo(msg.getTopic());</span><br><span class="line">    <span class="keyword">if</span> (topicPublishInfo != <span class="literal">null</span> &amp;&amp; topicPublishInfo.ok()) &#123;</span><br><span class="line">        <span class="type">MessageQueue</span> <span class="variable">mq</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line">        <span class="comment">// 根据我们的算法，选择一个发送队列</span></span><br><span class="line">        <span class="comment">// 这里的arg = orderId</span></span><br><span class="line">        mq = selector.select(topicPublishInfo.getMessageQueueList(), msg, arg);</span><br><span class="line">        <span class="keyword">if</span> (mq != <span class="literal">null</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="built_in">this</span>.sendKernelImpl(msg, mq, communicationMode, sendCallback, timeout);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="消息重复"><a href="#消息重复" class="headerlink" title="消息重复"></a>消息重复</h3><p>造成消息重复的根本原因是：网络不可达。只要通过网络交换数据，就无法避免这个问题。所以解决这个问题的办法就是绕过这个问题。那么问题就变成了：如果消费端收到两条一样的消息，应该怎样处理？</p>
<ol>
<li>消费端处理消息的业务逻辑保持幂等性。</li>
<li>保证每条消息都有唯一编号且保证消息处理成功与去重表的日志同时出现。</li>
</ol>
<p>第 1 条很好理解，只要保持幂等性，不管来多少条重复消息，最后处理的结果都一样。</p>
<p>第 2 条原理就是利用一张日志表来记录已经处理成功的消息的 ID，如果新到的消息 ID 已经在日志表中，那么就不再处理这条消息。</p>
<p>第 1 条解决方案，很明显应该在消费端实现，不属于消息系统要实现的功能。</p>
<p>第 2 条可以消息系统实现，也可以业务端实现。正常情况下出现重复消息的概率其实很小，如果由消息系统来实现的话，肯定会对消息系统的吞吐量和高可用有影响，所以最好还是由业务端自己处理消息重复的问题，这也是 RocketMQ 不解决消息重复的问题的原因。</p>
<p><strong>RocketMQ 不保证消息不重复，如果你的业务需要保证严格的不重复消息，需要你自己在业务端去重。</strong></p>
<h3 id="事务消息"><a href="#事务消息" class="headerlink" title="事务消息"></a>事务消息</h3><p>RocketMQ 除了支持普通消息，顺序消息，另外还支持事务消息。</p>
<p>假设这样的场景：</p>
<p><img src="https://upload-images.jianshu.io/upload_images/3101171-253d8bd65736694f.png" alt="img"></p>
<p>图中执行本地事务（Bob 账户扣款）和发送异步消息应该保证同时成功或者同时失败，也就是扣款成功了，发送消息一定要成功，如果扣款失败了，就不能再发送消息。那问题是：我们是先扣款还是先发送消息呢？</p>
<p><img src="http://upload-images.jianshu.io/upload_images/3101171-088dc074c4ecd192" alt="img"></p>
<p>RocketMQ 分布式事务步骤：</p>
<p>发送 Prepared 消息 2222222222222222222，并拿到接受消息的地址。<br>执行本地事务<br>通过第 1 步骤拿到的地址去访问消息，并修改消息状态。</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul>
<li><a target="_blank" rel="noopener" href="http://rocketmq.apache.org/docs/quick-start/">RocketMQ 官方文档</a></li>
<li><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/453c6e7ff81c">分布式开放消息系统(RocketMQ)的原理与实践</a></li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://dunwu.github.io/blog/pages/3b200f49/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/blog/uploads/avatar.gif">
      <meta itemprop="name" content="钝悟 ◾ Dunwu">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Dunwu Blog">
      <meta itemprop="description" content="钝悟的个人博客">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | Dunwu Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/blog/pages/3b200f49/" class="post-title-link" itemprop="url">《Kafka 核心源码解读》笔记</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-07-03 14:53:05" itemprop="dateCreated datePublished" datetime="2022-07-03T14:53:05+08:00">2022-07-03</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-09-13 17:56:53" itemprop="dateModified" datetime="2025-09-13T17:56:53+08:00">2025-09-13</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/blog/categories/%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index"><span itemprop="name">笔记</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/blog/categories/%E7%AC%94%E8%AE%B0/%E5%88%86%E5%B8%83%E5%BC%8F/" itemprop="url" rel="index"><span itemprop="name">分布式</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/blog/categories/%E7%AC%94%E8%AE%B0/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F%E9%80%9A%E4%BF%A1/" itemprop="url" rel="index"><span itemprop="name">分布式通信</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>13k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>12 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="《Kafka-核心源码解读》笔记"><a href="#《Kafka-核心源码解读》笔记" class="headerlink" title="《Kafka 核心源码解读》笔记"></a>《Kafka 核心源码解读》笔记</h1><h2 id="开篇词"><a href="#开篇词" class="headerlink" title="开篇词"></a>开篇词</h2><p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20220703152740.png"></p>
<p>从功能上讲，Kafka 源码分为四大模块。</p>
<ul>
<li>服务器端源码：实现 Kafka 架构和各类优秀特性的基础。</li>
<li>Java 客户端源码：定义了与 Broker 端的交互机制，以及通用的 Broker 端组件支撑代码。</li>
<li>Connect 源码：用于实现 Kafka 与外部系统的高性能数据传输。</li>
<li>Streams 源码：用于实现实时的流处理功能。</li>
</ul>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20220703152803.png"></p>
<h2 id="导读"><a href="#导读" class="headerlink" title="导读"></a>导读</h2><blockquote>
<p>构建 Kafka 工程和源码阅读环境、Scala 语言热身</p>
</blockquote>
<p>kafka 项目主要目录结构</p>
<ul>
<li><strong>bin</strong> 目录：保存 Kafka 工具行脚本，我们熟知的 kafka-server-start 和 kafka-consoleproducer 等脚本都存放在这里。</li>
<li><strong>clients</strong> 目录：保存 Kafka 客户端代码，比如生产者和消费者的代码都在该目录下。</li>
<li><strong>config</strong> 目录：保存 Kafka 的配置文件，其中比较重要的配置文件是 server.properties。</li>
<li><strong>connect</strong> 目录：保存 Connect 组件的源代码。我在开篇词里提到过，Kafka Connect 组件是用来实现 Kafka 与外部系统之间的实时数据传输的。</li>
<li><strong>core</strong> 目录：保存 Broker 端代码。Kafka 服务器端代码全部保存在该目录下。</li>
<li><strong>streams</strong> 目录：保存 Streams 组件的源代码。Kafka Streams 是实现 Kafka 实时流处理的组件。</li>
</ul>
<h2 id="日志段"><a href="#日志段" class="headerlink" title="日志段"></a>日志段</h2><blockquote>
<p>保存消息文件的对象是怎么实现的？</p>
</blockquote>
<h3 id="Kafka-日志结构"><a href="#Kafka-日志结构" class="headerlink" title="Kafka 日志结构"></a>Kafka 日志结构</h3><p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20220704204019.png"></p>
<p>Kafka 日志对象由多个日志段对象组成，而每个日志段对象会在磁盘上创建一组文件，包括<strong>消息日志文件（.log）</strong>、<strong>位移索引文件（.index）</strong>、<strong>时间戳索引文件（.timeindex）</strong>以及已中止（Aborted）事务的<strong>索引文件（.txnindex）</strong>。当然，如果你没有使用 Kafka 事务，已中止事务的索引文件是不会被创建出来的。</p>
<p>一个 Kafka 主题有很多分区，每个分区就对应一个 Log 对象，在物理磁盘上则对应于一个子目录。比如你创建了一个双分区的主题 test-topic，那么，Kafka 在磁盘上会创建两个子目录：test-topic-0 和 test-topic-1。而在服务器端，这就是两个 <strong><code>Log</code></strong> 对象。每个子目录下存在多组日志段，也就是多组 <strong><code>.log</code><strong>、</strong><code>.index</code><strong>、</strong><code>.timeindex</code></strong> 文件组合，只不过文件名不同，因为每个日志段的起始位移不同。</p>
<h3 id="日志段源码解析"><a href="#日志段源码解析" class="headerlink" title="日志段源码解析"></a>日志段源码解析</h3><p>日志段源码位于 Kafka 的 core 工程的 <code>LogSegment.scala</code> 中。该文件下定义了三个 Scala 对象：</p>
<ul>
<li><code>LogSegment class</code>：日志段类</li>
<li><code>LogSegment object</code>：保存静态变量或静态方法。相当于 <code>LogSegment class</code> 的工具类。</li>
<li><code>LogFlushStats object</code>：尾部有个 stats，用于统计，负责为日志落盘进行计时。</li>
</ul>
<h4 id="LogSegment-class-声明"><a href="#LogSegment-class-声明" class="headerlink" title="LogSegment class 声明"></a>LogSegment class 声明</h4><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LogSegment</span> <span class="title">private</span>[log] (<span class="params">val log: <span class="type">FileRecords</span>,</span></span></span><br><span class="line"><span class="params"><span class="class">                               val lazyOffsetIndex: <span class="type">LazyIndex</span>[<span class="type">OffsetIndex</span>],</span></span></span><br><span class="line"><span class="params"><span class="class">                               val lazyTimeIndex: <span class="type">LazyIndex</span>[<span class="type">TimeIndex</span>],</span></span></span><br><span class="line"><span class="params"><span class="class">                               val txnIndex: <span class="type">TransactionIndex</span>,</span></span></span><br><span class="line"><span class="params"><span class="class">                               val baseOffset: <span class="type">Long</span>,</span></span></span><br><span class="line"><span class="params"><span class="class">                               val indexIntervalBytes: <span class="type">Int</span>,</span></span></span><br><span class="line"><span class="params"><span class="class">                               val rollJitterMs: <span class="type">Long</span>,</span></span></span><br><span class="line"><span class="params"><span class="class">                               val time: <span class="type">Time</span></span>) <span class="keyword">extends</span> <span class="title">Logging</span> </span>&#123; ... &#125;</span><br></pre></td></tr></table></figure>

<p>参数说明：</p>
<ul>
<li><code>log</code>：<strong>包含日志条目的文件记录</strong>。<code>FileRecords</code> 就是实际保存 Kafka 消息的对象。</li>
<li><code>lazyOffsetIndex</code>：<strong>偏移量索引</strong>。</li>
<li><code>lazyTimeIndex</code>：<strong>时间戳索引</strong>。</li>
<li><code>txnIndex</code>：<strong>事务索引</strong>。</li>
<li><code>baseOffset</code>：<strong>此段中偏移量的下限</strong>。事实上，在磁盘上看到的 Kafka 文件名就是 <code>baseOffset</code> 的值。每个 <code>LogSegment</code> 对象实例一旦被创建，它的起始位移就是固定的了，不能再被更改。</li>
<li><code>indexIntervalBytes</code>：<strong>索引中条目之间的近似字节数</strong>。indexIntervalBytes 值其实就是 Broker 端参数 <code>log.index.interval.bytes</code> 值，它控制了日志段对象新增索引项的频率。默认情况下，日志段至少新写入 4KB 的消息数据才会新增一条索引项。</li>
<li><code>rollJitterMs</code>：<strong>日志段对象新增倒计时的“扰动值”</strong>。因为目前 Broker 端日志段新增倒计时是全局设置，这就是说，在未来的某个时刻可能同时创建多个日志段对象，这将极大地增加物理磁盘 I&#x2F;O 压力。有了 rollJitterMs 值的干扰，每个新增日志段在创建时会彼此岔开一小段时间，这样可以缓解物理磁盘的 I&#x2F;O 负载瓶颈。</li>
<li><code>time</code>：**<code>Timer</code> 实例**。</li>
</ul>
<h4 id="append-方法"><a href="#append-方法" class="headerlink" title="append 方法"></a>append 方法</h4><p>append 方法接收 4 个参数：分别表示</p>
<ul>
<li><code>largestOffset</code>：待写入消息批次中消息的最大位移值</li>
<li><code>largestTimestamp</code>：最大时间戳</li>
<li><code>shallowOffsetOfMaxTimestamp</code>：最大时间戳对应消息的位移</li>
<li><code>records</code>：真正要写入的消息集合</li>
</ul>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20220705062643.png"></p>
<ul>
<li>第一步：在源码中，首先调用 <code>log.sizeInBytes</code> 方法判断该日志段是否为空，如果是空的话， Kafka 需要记录要写入消息集合的最大时间戳，并将其作为后面新增日志段倒计时的依据。</li>
<li>第二步：代码调用 <code>ensureOffsetInRange</code> 方法确保输入参数最大位移值是合法的。那怎么判断是不是合法呢？标准就是看它与日志段起始位移的差值是否在整数范围内，即 <code>largestOffset - baseOffset</code> 的值是不是 介于 <code>[0，Int.MAXVALUE]</code> 之间。在极个别的情况下，这个差值可能会越界，这时， <code>append</code> 方法就会抛出异常，阻止后续的消息写入。一旦你碰到这个问题，你需要做的是升级你的 Kafka 版本，因为这是由已知的 Bug 导致的。</li>
<li>第三步：待这些做完之后，<code>append</code> 方法调用 <code>FileRecords</code> 的 <code>append</code> 方法执行真正的写入。它的工作是将内存中的消息对象写入到操作系统的页缓存就可以了。</li>
<li>第四步：再下一步，就是更新日志段的最大时间戳以及最大时间戳所属消息的位移值属性。每个日志段都要保存当前最大时间戳信息和所属消息的位移信息。还记得 Broker 端提供定期删除日志的功能吗？比如我只想保留最近 7 天的日志，没错，当前最大时间戳这个值就是判断的依据；而最大时间戳对应的消息的位移值则用于时间戳索引项。虽然后面我会详细介绍，这里我还是稍微提一下：时间戳索引项保存时间戳与消息位移的对应关系。在这步操作中，Kafka 会更新并保存这组对应关系。</li>
<li>第五步：append 方法的最后一步就是更新索引项和写入的字节数了。我在前面说过，日志段每写入 4KB 数据就要写入一个索引项。当已写入字节数超过了 4KB 之后，append 方法会调用索引对象的 append 方法新增索引项，同时清空已写入字节数，以备下次重新累积计算。</li>
</ul>
<h4 id="read-方法"><a href="#read-方法" class="headerlink" title="read 方法"></a>read 方法</h4><p>read 方法作用：从第一个偏移量 &gt;&#x3D; startOffset 的 Segment 开始读取消息集。如果指定了 maxOffset，则消息集将包含不超过 maxSize 字节，并将在 maxOffset 之前结束。</p>
<p>read 方法入参</p>
<ul>
<li><code>startOffset</code>：要读取的第一条消息的位移；</li>
<li><code>maxSize</code>：能读取的最大字节数；</li>
<li><code>maxPosition</code> ：能读到的最大文件位置；</li>
<li><code>minOneMessage</code>：是否允许在消息体过大时至少返回第一条消息。</li>
</ul>
<p>read 方法代码逻辑：</p>
<ol>
<li>调用 <code>translateOffset</code> 方法定位要读取的起始文件位置 （<code>startPosition</code>）。输入参数 <code>startOffset</code> 仅仅是位移值，Kafka 需要根据索引信息找到对应的物理文件位置才能开始读取消息。</li>
<li>待确定了读取起始位置，日志段代码需要根据这部分信息以及 <code>maxSize</code> 和 <code>maxPosition</code> 参数共同计算要读取的总字节数。举个例子，假设 maxSize&#x3D;100，maxPosition&#x3D;300，startPosition&#x3D;250，那么 read 方法只能读取 50 字节，因为 maxPosition - startPosition &#x3D; 50。我们把它和 maxSize 参数相比较，其中的最小值就是最终能够读取的总字节数。</li>
<li>调用 <code>FileRecords</code> 的 <code>slice</code> 方法，从指定位置读取指定大小的消息集合。</li>
</ol>
<h4 id="recover-方法"><a href="#recover-方法" class="headerlink" title="recover 方法"></a>recover 方法</h4><p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20220705064515.png"></p>
<p>recover 开始时，代码依次调用索引对象的 reset 方法清空所有的索引文件，之后会开始遍历日志段中的所有消息集合或消息批次（RecordBatch）。对于读取到的每个消息集合，日志段必须要确保它们是合法的，这主要体现在两个方面：</p>
<ul>
<li>该集合中的消息必须要符合 Kafka 定义的二进制格式；</li>
<li>该集合中最后一条消息的位移值不能越界，即它与日志段起始位移的差值必须是一个正整数值。</li>
</ul>
<p>校验完消息集合之后，代码会更新遍历过程中观测到的最大时间戳以及所属消息的位移值。同样，这两个数据用于后续构建索引项。再之后就是不断累加当前已读取的消息字节数，并根据该值有条件地写入索引项。最后是更新事务型 Producer 的状态以及 Leader Epoch 缓存。不过，这两个并不是理解 Kafka 日志结构所必需的组件，因此，我们可以忽略它们。</p>
<p>遍历执行完成后，Kafka 会将日志段当前总字节数和刚刚累加的已读取字节数进行比较，如果发现前者比后者大，说明日志段写入了一些非法消息，需要执行截断操作，将日志段大小调整回合法的数值。同时， Kafka 还必须相应地调整索引文件的大小。把这些都做完之后，日志段恢复的操作也就宣告结束了。</p>
<h2 id="日志"><a href="#日志" class="headerlink" title="日志"></a>日志</h2><p>日志是日志段的容器，里面定义了很多管理日志段的操作。</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20220705195916.png"></p>
<h3 id="Log-源码结构"><a href="#Log-源码结构" class="headerlink" title="Log 源码结构"></a>Log 源码结构</h3><ul>
<li><code>LogAppendInfo</code>（C）：保存消息元数据信息</li>
<li><code>LogAppendInfo</code>（O）：<code>LogAppendInfo</code>（C）工厂方法类</li>
<li><code>UnifiedLog</code>（C）：<code>UnifiedLog.scala</code> 中最核心的代码</li>
<li><code>UnifiedLog</code>（O）：<code>UnifiedLog</code>（C）工厂方法类</li>
<li><code>RollParams</code>（C）：用于控制日志段是否切分（Roll）的数据结构。</li>
<li><code>RollParams</code>（O）：RollParams 伴生类的工厂方法。</li>
<li><code>LogMetricNames</code>（O）：定义了 Log 对象的监控指标。</li>
<li><code>LogOffsetSnapshot</code>（C）：封装分区所有位移元数据的容器类。</li>
<li><code>LogReadInfo</code>（C）：封装读取日志返回的数据及其元数据。</li>
<li><code>CompletedTxn</code>（C）：记录已完成事务的元数据，主要用于构建事务索引。</li>
</ul>
<h3 id="Log-Class-Object"><a href="#Log-Class-Object" class="headerlink" title="Log Class &amp; Object"></a>Log Class &amp; Object</h3><p>Log Object 作用：</p>
<ul>
<li>定义了 Kafka 支持的文件类型<ul>
<li>.log：Kafka 日志文件</li>
<li>.index：Kafka 偏移量索引文件</li>
<li>.timeindex：Kafka 时间戳索引文件</li>
<li>.txnindex：Kafka 事务索引文件</li>
<li>.snapshot：Kafka 为幂等型或事务型 Producer 所做的快照文件</li>
<li>.deleted：被标记为待删除的文件</li>
<li>.cleaned：用于日志清理的临时文件</li>
<li>.swap：将文件交换到日志中时使用的临时文件</li>
<li>-delete：被标记为待删除的目录</li>
<li>-future：用于变更主题分区文件夹地址的目录</li>
</ul>
</li>
<li>定义了多种工具类方法</li>
</ul>
<p>UnifiedLog Class 定义：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// UnifiedLog 定义</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">UnifiedLog</span>(<span class="params">@volatile var logStartOffset: <span class="type">Long</span>,</span></span></span><br><span class="line"><span class="params"><span class="class">                 private val localLog: <span class="type">LocalLog</span>,</span></span></span><br><span class="line"><span class="params"><span class="class">                 brokerTopicStats: <span class="type">BrokerTopicStats</span>,</span></span></span><br><span class="line"><span class="params"><span class="class">                 val producerIdExpirationCheckIntervalMs: <span class="type">Int</span>,</span></span></span><br><span class="line"><span class="params"><span class="class">                 @volatile var leaderEpochCache: <span class="type">Option</span>[<span class="type">LeaderEpochFileCache</span>],</span></span></span><br><span class="line"><span class="params"><span class="class">                 val producerStateManager: <span class="type">ProducerStateManager</span>,</span></span></span><br><span class="line"><span class="params"><span class="class">                 @volatile private var _topicId: <span class="type">Option</span>[<span class="type">Uuid</span>],</span></span></span><br><span class="line"><span class="params"><span class="class">                 val keepPartitionMetadataFile: <span class="type">Boolean</span></span>) <span class="keyword">extends</span> <span class="title">Logging</span> <span class="keyword">with</span> <span class="title">KafkaMetricsGroup</span> </span>&#123; ... &#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// LocalLog 定义</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LocalLog</span>(<span class="params">@volatile private var _dir: <span class="type">File</span>,</span></span></span><br><span class="line"><span class="params"><span class="class">               @volatile private[log] var config: <span class="type">LogConfig</span>,</span></span></span><br><span class="line"><span class="params"><span class="class">               private[log] val segments: <span class="type">LogSegments</span>,</span></span></span><br><span class="line"><span class="params"><span class="class">               @volatile private[log] var recoveryPoint: <span class="type">Long</span>,</span></span></span><br><span class="line"><span class="params"><span class="class">               @volatile private var nextOffsetMetadata: <span class="type">LogOffsetMetadata</span>,</span></span></span><br><span class="line"><span class="params"><span class="class">               private[log] val scheduler: <span class="type">Scheduler</span>,</span></span></span><br><span class="line"><span class="params"><span class="class">               private[log] val time: <span class="type">Time</span>,</span></span></span><br><span class="line"><span class="params"><span class="class">               private[log] val topicPartition: <span class="type">TopicPartition</span>,</span></span></span><br><span class="line"><span class="params"><span class="class">               private[log] val logDirFailureChannel: <span class="type">LogDirFailureChannel</span></span>) <span class="keyword">extends</span> <span class="title">Logging</span> <span class="keyword">with</span> <span class="title">KafkaMetricsGroup</span> </span>&#123; ... &#125;</span><br></pre></td></tr></table></figure>

<p>上面属性中最重要的两个属性是：<code>_dir</code> 和 <code>logStartOffset</code>。<code>_dir</code> 就是这个日志所在的文件夹路径，也就是主题分区的路径。<code>logStartOffset</code>，表示日志的当前最早位移。<code>_dir</code> 和 <code>logStartOffset</code> 都是 <code>volatile var</code> 类型，表示它们的值是变动的，而且可能被多个线程更新。</p>
<p>Log End Offset（LEO），是表示日志下一条待插入消息的位移值，而这个 Log Start Offset 是跟它相反的，它表示日志当前对外可见的最早一条消息的位移值。</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20220705201758.png"></p>
<p>图中绿色的位移值 3 是日志的 Log Start Offset，而位移值 15 表示 LEO。另外，位移值 8 是高水位值，它是区分已提交消息和未提交消息的分水岭。</p>
<p>有意思的是，Log End Offset 可以简称为 LEO，但 Log Start Offset 却不能简称为 LSO。因为在 Kafka 中，LSO 特指 Log Stable Offset，属于 Kafka 事务的概念。</p>
<p>Log 类的其他属性你暂时不用理会，因为它们要么是很明显的工具类属性，比如 timer 和 scheduler，要么是高阶用法才会用到的高级属性，比如 producerStateManager 和 logDirFailureChannel。工具类的代码大多是做辅助用的，跳过它们也不妨碍我们理解 Kafka 的核心功能；而高阶功能代码设计复杂，学习成本高，性价比不高。</p>
<p>其他一些重要属性：</p>
<ul>
<li>nextOffsetMetadata：它封装了下一条待插入消息的位移值，你基本上可以把这个属性和 LEO 等同起来。</li>
<li>highWatermarkMetadata：是分区日志高水位值。</li>
<li>segments：我认为这是 Log 类中最重要的属性。它保存了分区日志下所有的日志段信息，只不过是用 Map 的数据结构来保存的。Map 的 Key 值是日志段的起始位移值，Value 则是日志段对象本身。Kafka 源码使用 ConcurrentNavigableMap 数据结构来保存日志段对象，就可以很轻松地利用该类提供的线程安全和各种支持排序的方法，来管理所有日志段对象。</li>
<li>Leader Epoch Cache 对象。Leader Epoch 是社区于 0.11.0.0 版本引入源码中的，主要是用来判断出现 Failure 时是否执行日志截断操作（Truncation）。之前靠高水位来判断的机制，可能会造成副本间数据不一致的情形。这里的 Leader Epoch Cache 是一个缓存类数据，里面保存了分区 Leader 的 Epoch 值与对应位移值的映射关系，我建议你查看下 LeaderEpochFileCache 类，深入地了解下它的实现原理。</li>
</ul>
<h3 id="LOG-类初始化逻辑"><a href="#LOG-类初始化逻辑" class="headerlink" title="LOG 类初始化逻辑"></a>LOG 类初始化逻辑</h3><p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20220705204919.png"></p>
<h3 id="Log-的常见操作"><a href="#Log-的常见操作" class="headerlink" title="Log 的常见操作"></a>Log 的常见操作</h3><p>Log 的常见操作可以分为 4 类：</p>
<ul>
<li>高水位管理操作：高水位的概念在 Kafka 中举足轻重，对它的管理，是 Log 最重要的功能之一。</li>
<li>日志段管理：Log 是日志段的容器。高效组织与管理其下辖的所有日志段对象，是源码要解决的核心问题。</li>
<li>关键位移值管理：日志定义了很多重要的位移值，比如 Log Start Offset 和 LEO 等。确保这些位移值的正确性，是构建消息引擎一致性的基础。</li>
<li>读写操作：所谓的操作日志，大体上就是指读写日志。读写操作的作用之大，不言而喻。</li>
</ul>
<h4 id="高水位管理操作"><a href="#高水位管理操作" class="headerlink" title="高水位管理操作"></a>高水位管理操作</h4><p>高水位定义：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@volatile</span> <span class="keyword">private</span> <span class="keyword">var</span> highWatermarkMetadata: <span class="type">LogOffsetMetadata</span> = <span class="type">LogOffsetMetadata</span>(logStartOffset)</span><br></pre></td></tr></table></figure>

<p>高水位值是 volatile（易变型）的。因为多个线程可能同时读取它，因此需要设置成 volatile，保证内存可见性。另外，由于高水位值可能被多个线程同时修改，因此源码使用 Java Monitor 锁来确保并发修改的线程安全。</p>
<p>高水位值的初始值是 Log Start Offset 值。上节课我们提到，每个 Log 对象都会维护一个 Log Start Offset 值。当首次构建高水位时，它会被赋值成 Log Start Offset 值。</p>
<p>LogOffsetMetadata 定义</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">LogOffsetMetadata</span>(<span class="params">messageOffset: <span class="type">Long</span>,</span></span></span><br><span class="line"><span class="params"><span class="class">                             segmentBaseOffset: <span class="type">Long</span> = <span class="type">Log</span>.<span class="type">UnknownOffset</span>,</span></span></span><br><span class="line"><span class="params"><span class="class">                             relativePositionInSegment: <span class="type">Int</span> = <span class="type">LogOffsetMetadata</span>.<span class="type">UnknownFilePosition</span></span>) </span>&#123;</span><br></pre></td></tr></table></figure>

<p>三个参数：</p>
<ul>
<li><code>messageOffset</code>：消息位移值，这是最重要的信息。我们总说高水位值，其实指的就是这个变量的值。</li>
<li><code>segmentBaseOffset</code>：保存该位移值所在日志段的起始位移。日志段起始位移值辅助计算两条消息在物理磁盘文件中位置的差值，即两条消息彼此隔了多少字节。这个计算有个前提条件，即两条消息必须处在同一个日志段对象上，不能跨日志段对象。否则它们就位于不同的物理文件上，计算这个值就没有意义了。这里的 segmentBaseOffset，就是用来判断两条消息是否处于同一个日志段的。</li>
<li><code>relativePositionSegment</code>：保存该位移值所在日志段的物理磁盘位置。这个字段在计算两个位移值之间的物理磁盘位置差值时非常有用。你可以想一想，Kafka 什么时候需要计算位置之间的字节数呢？答案就是在读取日志的时候。假设每次读取时只能读 1MB 的数据，那么，源码肯定需要关心两个位移之间所有消息的总字节数是否超过了 1MB。</li>
</ul>
<h5 id="获取和设置高水位值"><a href="#获取和设置高水位值" class="headerlink" title="获取和设置高水位值"></a>获取和设置高水位值</h5><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">updateHighWatermarkMetadata</span></span>(newHighWatermark: <span class="type">LogOffsetMetadata</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">  <span class="keyword">if</span> (newHighWatermark.messageOffset &lt; <span class="number">0</span>) <span class="comment">// 高水位值不能是负数</span></span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">IllegalArgumentException</span>(<span class="string">&quot;High watermark offset should be non-negative&quot;</span>)</span><br><span class="line"></span><br><span class="line">  lock synchronized &#123; <span class="comment">// 保护Log对象修改的Monitor锁</span></span><br><span class="line">    highWatermarkMetadata = newHighWatermark <span class="comment">// 赋值新的高水位值</span></span><br><span class="line">    producerStateManager.onHighWatermarkUpdated(newHighWatermark.messageOffset)</span><br><span class="line">    maybeIncrementFirstUnstableOffset() <span class="comment">// First Unstable Offset是Kafka事务机制</span></span><br><span class="line">  &#125;</span><br><span class="line">  trace(<span class="string">s&quot;Setting high watermark <span class="subst">$newHighWatermark</span>&quot;</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h5 id="更新高水位值"><a href="#更新高水位值" class="headerlink" title="更新高水位值"></a>更新高水位值</h5><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">updateHighWatermark</span></span>(hw: <span class="type">Long</span>): <span class="type">Long</span> = &#123;</span><br><span class="line">  <span class="comment">// 新高水位值一定介于[Log Start Offset，Log End Offset]之间</span></span><br><span class="line">  <span class="keyword">val</span> newHighWatermark = <span class="keyword">if</span> (hw &lt; logStartOffset)</span><br><span class="line">    logStartOffset</span><br><span class="line">  <span class="keyword">else</span> <span class="keyword">if</span> (hw &gt; logEndOffset)</span><br><span class="line">    logEndOffset</span><br><span class="line">  <span class="keyword">else</span></span><br><span class="line">    hw</span><br><span class="line">  <span class="comment">// 设置高水位值</span></span><br><span class="line">  updateHighWatermarkMetadata(<span class="type">LogOffsetMetadata</span>(newHighWatermark))</span><br><span class="line">  <span class="comment">// 最后返回新高水位值</span></span><br><span class="line">  newHighWatermark</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">maybeIncrementHighWatermark</span></span>(newHighWatermark: <span class="type">LogOffsetMetadata</span>): <span class="type">Option</span>[<span class="type">LogOffsetMetadata</span>] = &#123;</span><br><span class="line">  <span class="comment">// 新高水位值不能越过Log End Offset</span></span><br><span class="line">  <span class="keyword">if</span> (newHighWatermark.messageOffset &gt; logEndOffset)</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">IllegalArgumentException</span>(<span class="string">s&quot;High watermark <span class="subst">$newHighWatermark</span> update exceeds current &quot;</span> +</span><br><span class="line">      <span class="string">s&quot;log end offset <span class="subst">$logEndOffsetMetadata</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">  lock.synchronized &#123;</span><br><span class="line">    <span class="keyword">val</span> oldHighWatermark = fetchHighWatermarkMetadata <span class="comment">// 获取老的高水位值</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 保证高水位单调递增。当新的偏移元数据位于较新的段上时，我们还会更新高水位线，每当日志滚动到新段时就会发生这种情况。</span></span><br><span class="line">    <span class="keyword">if</span> (oldHighWatermark.messageOffset &lt; newHighWatermark.messageOffset ||</span><br><span class="line">      (oldHighWatermark.messageOffset == newHighWatermark.messageOffset &amp;&amp; oldHighWatermark.onOlderSegment(newHighWatermark))) &#123;</span><br><span class="line">      updateHighWatermarkMetadata(newHighWatermark)</span><br><span class="line">      <span class="type">Some</span>(oldHighWatermark) <span class="comment">// 返回老的高水位值</span></span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="type">None</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这两个方法有着不同的用途。updateHighWatermark 方法，主要用在 Follower 副本从 Leader 副本获取到消息后更新高水位值。一旦拿到新的消息，就必须要更新高水位值；而 maybeIncrementHighWatermark 方法，主要是用来更新 Leader 副本的高水位值。需要注意的是，Leader 副本高水位值的更新是有条件的——某些情况下会更新高水位值，某些情况下可能不会。</p>
<h5 id="读取高水位值"><a href="#读取高水位值" class="headerlink" title="读取高水位值"></a>读取高水位值</h5><figure class="highlight fsharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> def fetchHighWatermarkMetadata<span class="operator">:</span> LogOffsetMetadata <span class="operator">=</span> &#123;</span><br><span class="line">  checkIfMemoryMappedBufferClosed() <span class="comment">// 读取时确保日志不能被关闭</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> offsetMetadata <span class="operator">=</span> highWatermarkMetadata <span class="comment">// 保存当前高水位值到本地变量</span></span><br><span class="line">  <span class="keyword">if</span> (offsetMetadata.messageOffsetOnly) &#123; <span class="comment">// 没有获得到完整的高水位元数据</span></span><br><span class="line">    <span class="built_in">lock</span>.<span class="keyword">synchronized</span> &#123;</span><br><span class="line">      <span class="comment">// 给定消息偏移量，在日志中找到其对应的偏移量元数据。如果消息偏移量超出范围，则抛出异常</span></span><br><span class="line">      <span class="keyword">val</span> fullOffset <span class="operator">=</span> convertToOffsetMetadataOrThrow(highWatermark)</span><br><span class="line">      updateHighWatermarkMetadata(fullOffset) <span class="comment">// 然后再更新一下高水位对象</span></span><br><span class="line">      fullOffset</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    offsetMetadata</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="日志段管理"><a href="#日志段管理" class="headerlink" title="日志段管理"></a>日志段管理</h4><p>添加</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@threadsafe</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">addSegment</span></span>(segment: <span class="type">LogSegment</span>): <span class="type">LogSegment</span> = <span class="keyword">this</span>.segments.put(segment.baseOffset, segment)</span><br></pre></td></tr></table></figure>

<p>删除</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">deleteOldSegments</span></span>(): <span class="type">Int</span> = &#123;</span><br><span class="line">  <span class="keyword">if</span> (config.delete) &#123;</span><br><span class="line">    deleteRetentionMsBreachedSegments() + deleteRetentionSizeBreachedSegments() + deleteLogStartOffsetBreachedSegments()</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    deleteLogStartOffsetBreachedSegments()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">deleteOldSegments</span></span>(predicate: (<span class="type">LogSegment</span>, <span class="type">Option</span>[<span class="type">LogSegment</span>]) =&gt; <span class="type">Boolean</span>, reason: <span class="type">String</span>): <span class="type">Int</span> = &#123;</span><br><span class="line">  lock synchronized &#123;</span><br><span class="line">    <span class="keyword">val</span> deletable = deletableSegments(predicate)</span><br><span class="line">    <span class="keyword">if</span> (deletable.nonEmpty)</span><br><span class="line">      info(<span class="string">s&quot;Found deletable segments with base offsets [<span class="subst">$&#123;deletable.map(_.baseOffset).mkString(&quot;,&quot;)&#125;</span>] due to <span class="subst">$reason</span>&quot;</span>)</span><br><span class="line">    deleteSegments(deletable)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>修改</p>
<p>源码里面不涉及修改日志段对象，所谓的修改或更新也就是替换而已，用新的日志段对象替换老的日志段对象。举个简单的例子。segments.put(1L, newSegment) 语句在没有 Key&#x3D;1 时是添加日志段，否则就是替换已有日志段。</p>
<p>查询</p>
<p>主要都是利用了 ConcurrentSkipListMap 的现成方法。</p>
<ul>
<li>segments.firstEntry：获取第一个日志段对象；</li>
<li>segments.lastEntry：获取最后一个日志段对象，即 Active Segment；</li>
<li>segments.higherEntry：获取第一个起始位移值 ≥ 给定 Key 值的日志段对象；</li>
<li>segments.floorEntry：获取最后一个起始位移值 ≤ 给定 Key 值的日志段对象。</li>
</ul>
<h4 id="关键位移值管理"><a href="#关键位移值管理" class="headerlink" title="关键位移值管理"></a>关键位移值管理</h4><p>Log 对象维护了一些关键位移值数据，比如 Log Start Offset、LEO 等。</p>
<p>Log 对象中的 LEO 永远指向下一条待插入消息，也就是说，LEO 值上面是没有消息的</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@volatile</span> <span class="keyword">private</span> <span class="keyword">var</span> nextOffsetMetadata: LogOffsetMetadata = _</span><br></pre></td></tr></table></figure>

<p>Log End Offset 对象被更新的时机：</p>
<ul>
<li><strong>对象初始化时</strong>：当 Log 对象初始化时，我们必须要创建一个 LEO 对象，并对其进行初始化。</li>
<li><strong>写入新消息时</strong>：这个最容易理解。以上面的图为例，当不断向 Log 对象插入新消息时，LEO 值就像一个指针一样，需要不停地向右移动，也就是不断地增加。</li>
<li><strong>Log 对象发生日志切分（Log Roll）时</strong>：日志切分是啥呢？其实就是创建一个全新的日志段对象，并且关闭当前写入的日志段对象。这通常发生在当前日志段对象已满的时候。一旦发生日志切分，说明 Log 对象切换了 Active Segment，那么，LEO 中的起始位移值和段大小数据都要被更新，因此，在进行这一步操作时，我们必须要更新 LEO 对象。</li>
<li><strong>日志截断（Log Truncation）时</strong>：这个也是显而易见的。日志中的部分消息被删除了，自然可能导致 LEO 值发生变化，从而要更新 LEO 对象。</li>
</ul>
<p>Log Start Offset 被更新的时机：</p>
<ul>
<li><strong>Log 对象初始化时</strong>：和 LEO 类似，Log 对象初始化时要给 Log Start Offset 赋值，一般是将第一个日志段的起始位移值赋值给它。</li>
<li><strong>日志截断时</strong>：同理，一旦日志中的部分消息被删除，可能会导致 Log Start Offset 发生变化，因此有必要更新该值。</li>
<li><strong>Follower 副本同步时</strong>：一旦 Leader 副本的 Log 对象的 Log Start Offset 值发生变化。为了维持和 Leader 副本的一致性，Follower 副本也需要尝试去更新该值。</li>
<li><strong>删除日志段时</strong>：这个和日志截断是类似的。凡是涉及消息删除的操作都有可能导致 LogStart Offset 值的变化。</li>
<li><strong>删除消息时</strong>：严格来说，这个更新时机有点本末倒置了。在 Kafka 中，删除消息就是通过抬高 Log Start Offset 值来实现的，因此，删除消息时必须要更新该值。</li>
</ul>
<h4 id="读写操作"><a href="#读写操作" class="headerlink" title="读写操作"></a>读写操作</h4><p>写操作流程：</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20220706104752.png"></p>
<p>读操作</p>
<p>read 方法中有 4 个参数：</p>
<ul>
<li>startOffset，即从 Log 对象的哪个位移值开始读消息。</li>
<li>maxLength，即最多能读取多少字节。</li>
<li>isolation，设置读取隔离级别，主要控制能够读取的最大位移值，多用于 Kafka 事务。</li>
<li>minOneMessage，即是否允许至少读一条消息。设想如果消息很大，超过了 maxLength，正常情况下 read 方法永远不会返回任何消息。但如果设置了该参数为 true，read 方法就保证至少能够返回一条消息。</li>
</ul>
<h2 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h2><h3 id="索引类图及源文件组织架构"><a href="#索引类图及源文件组织架构" class="headerlink" title="索引类图及源文件组织架构"></a>索引类图及源文件组织架构</h3><ul>
<li>AbstractIndex.scala：它定义了最顶层的抽象类，这个类封装了所有索引类型的公共操作。</li>
<li>LazyIndex.scala：它定义了 AbstractIndex 上的一个包装类，实现索引项延迟加载。这个类主要是为了提高性能。</li>
<li>OffsetIndex.scala：定义位移索引，保存“&lt; 位移值，文件磁盘物理位置 &gt;”对。</li>
<li>TimeIndex.scala：定义时间戳索引，保存“&lt; 时间戳，位移值 &gt;”对。</li>
<li>TransactionIndex.scala：定义事务索引，为已中止事务（Aborted Transcation）保存重要的元数据信息。只有启用 Kafka 事务后，这个索引才有可能出现。</li>
</ul>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20220706142040.png"></p>
<h3 id="AbstractIndex-代码结构"><a href="#AbstractIndex-代码结构" class="headerlink" title="AbstractIndex 代码结构"></a>AbstractIndex 代码结构</h3><ul>
<li>索引文件（file）。每个索引对象在磁盘上都对应了一个索引文件。你可能注意到了，这个字段是 var 型，说明它是可以被修改的。难道索引对象还能动态更换底层的索引文件吗？是的。自 1.1.0 版本之后，Kafka 允许迁移底层的日志路径，所以，索引文件自然要是可以更换的。</li>
<li>起始位移值（baseOffset）。索引对象对应日志段对象的起始位移值。举个例子，如果你查看 Kafka 日志路径的话，就会发现，日志文件和索引文件都是成组出现的。比如说，如果日志文件是 00000000000000000123.log，正常情况下，一定还有一组索引文件 00000000000000000123.index、00000000000000000123.timeindex 等。这里的“123”就是这组文件的起始位移值，也就是 baseOffset 值。</li>
<li>索引文件最大字节数（maxIndexSize）。它控制索引文件的最大长度。Kafka 源码传入该参数的值是 Broker 端参数 segment.index.bytes 的值，即 10MB。这就是在默认情况下，所有 Kafka 索引文件大小都是 10MB 的原因。</li>
<li>索引文件打开方式（writable）。“True”表示以“读写”方式打开，“False”表示以“只读”方式打开。</li>
</ul>
<h3 id="位移索引"><a href="#位移索引" class="headerlink" title="位移索引"></a>位移索引</h3><p>位移索引也就是所谓的 OffsetIndex。Key 就是消息的相对位移，Value 是保存该消息的日志段文件中该消息第一个字节的物理文件位置。</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul>
<li><a target="_blank" rel="noopener" href="https://time.geekbang.org/column/intro/304">Kafka 核心源码解读</a></li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://dunwu.github.io/blog/pages/d0602b5b/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/blog/uploads/avatar.gif">
      <meta itemprop="name" content="钝悟 ◾ Dunwu">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Dunwu Blog">
      <meta itemprop="description" content="钝悟的个人博客">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | Dunwu Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/blog/pages/d0602b5b/" class="post-title-link" itemprop="url">《极客时间教程 - 分布式协议与算法实战》笔记</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-06-27 11:49:01" itemprop="dateCreated datePublished" datetime="2022-06-27T11:49:01+08:00">2022-06-27</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-09-13 17:56:53" itemprop="dateModified" datetime="2025-09-13T17:56:53+08:00">2025-09-13</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/blog/categories/%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index"><span itemprop="name">笔记</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/blog/categories/%E7%AC%94%E8%AE%B0/%E5%88%86%E5%B8%83%E5%BC%8F/" itemprop="url" rel="index"><span itemprop="name">分布式</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/blog/categories/%E7%AC%94%E8%AE%B0/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F%E7%BB%BC%E5%90%88/" itemprop="url" rel="index"><span itemprop="name">分布式综合</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>17k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>15 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="《极客时间教程-分布式协议与算法实战》笔记"><a href="#《极客时间教程-分布式协议与算法实战》笔记" class="headerlink" title="《极客时间教程 - 分布式协议与算法实战》笔记"></a>《极客时间教程 - 分布式协议与算法实战》笔记</h1><h2 id="拜占庭将军问题"><a href="#拜占庭将军问题" class="headerlink" title="拜占庭将军问题"></a>拜占庭将军问题</h2><blockquote>
<p>拜占庭将军问题是由<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E8%8E%B1%E6%96%AF%E5%88%A9%C2%B7%E5%85%B0%E6%B3%A2%E7%89%B9">莱斯利·兰波特</a>在其同名论文中提出的<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E5%AF%B9%E7%AD%89%E7%BD%91%E7%BB%9C">分布式对等网络</a>通信容错问题。其实是借拜占庭将军的例子，抛出了分布式共识性问题，并探讨和论证了解决的方法。</p>
<p>在<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E5%88%86%E5%B8%83%E5%BC%8F%E8%A8%88%E7%AE%97">分布式计算</a>中，不同的节点通过通讯交换信息达成共识而按照同一套协作策略行动。但有时候，系统中的节点可能出错而发送错误的信息，用于传递信息的通讯网络也可能导致信息损坏，使得网络中不同的成员关于全体协作的策略得出不同结论，从而破坏系统一致性。拜占庭将军问题被认为是容错性问题中最难的问题类型之一。</p>
</blockquote>
<h3 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h3><p>一群拜占庭将军各领一支军队共同围困一座城市。</p>
<p>为了简化问题，军队的行动策略只有两种：<strong>进攻</strong>（Attack，后面简称 A）或 <strong>撤退</strong>（Retreat，后面简称 R）。如果这些军队不是统一进攻或撤退，就可能因兵力不足导致失败。因此，<strong>将军们通过投票来达成一致策略：同进或同退</strong>。</p>
<p>因为将军们分别在城市的不同方位，所以他们只能<strong>通过信使互相联系</strong>。在投票过程中，<strong>每位将军都将自己的投票信息（A 或 R）通知其他所有将军</strong>，这样一来每位将军根据自己的投票和其他所有将军送来的信息就可以分析出共同的投票结果而决定行动策略。</p>
<p>这个抽象模型的问题在于：<strong>将军中可能存在叛徒，他们不仅会发出误导性投票，还可能选择性地发送投票信息</strong>。</p>
<p>由于将军之间需要通过信使通讯，叛变将军可能通过伪造信件来以其他将军的身份发送假投票。而即使在保证所有将军忠诚的情况下，也不能排除信使被敌人截杀，甚至被敌人间谍替换等情况。因此很难通过保证人员可靠性及通讯可靠性来解决问题。</p>
<p>假使那些忠诚（或是没有出错）的将军仍然能通过多数决定来决定他们的战略，便称达到了拜占庭容错。在此，票都会有一个默认值，若消息（票）没有被收到，则使用此默认值来投票。</p>
<p>上述的故事可以映射到分布式系统中，_将军代表分布式系统中的节点；信使代表通信系统；叛徒代表故障或异常_。</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20210704104211.png" alt="img"></p>
<h3 id="问题分析"><a href="#问题分析" class="headerlink" title="问题分析"></a>问题分析</h3><blockquote>
<p>兰伯特针对拜占庭将军问题，给出了两个解决方案：口头协议和书面协议。</p>
<p>本文介绍一下口头协议。</p>
</blockquote>
<p>在口头协议中，拜占庭将军问题被简化为<strong>将军 - 副官</strong>模型，其核心规则如下：</p>
<ul>
<li>忠诚的副官遵守同一命令。</li>
<li>若将军是忠诚的，所有忠诚的副官都执行他的命令。</li>
<li><strong>如果叛徒人数为 m，将军人数不能少于 3m + 1</strong> ，那么拜占庭将军问题就能解决了。——关于这个公式，可以不必深究，如果对推导过程感兴趣，可以参考论文。</li>
</ul>
<p><strong>示例一、叛徒人数为 1，将军人数为 3</strong></p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20210704112012.png" alt="img"></p>
<p>这个示例中，将军人数不满足 3m + 1，无法保证忠诚的副官都执行将军的命令。</p>
<p><strong>示例二、叛徒人数为 1，将军人数为 4</strong></p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20210704194815.png" alt="img"></p>
<p>这个示例中，将军人数满足 3m + 1，无论是副官中有叛徒，还是将军是叛徒，都能保证忠诚的副官执行将军的命令。</p>
<h2 id="CAP-理论"><a href="#CAP-理论" class="headerlink" title="CAP 理论"></a>CAP 理论</h2><p>CAP 是指：在一个分布式系统中， 一致性、可用性和分区容忍性，最多只能同时满足其中两项。</p>
<ul>
<li><strong>一致性（C：Consistency）</strong>：多个数据副本是否能保持一致</li>
<li><strong>可用性（A：Availability）</strong>：分布式系统在面对各种异常时可以提供正常服务的能力</li>
<li><strong>分区容忍性（P：Partition Tolerance）</strong>：分布式系统在遇到任何网络分区故障的时候，仍然需要能对外提供一致性和可用性的服务，除非是整个网络环境都发生了故障</li>
</ul>
<img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20211102191636.png" style="width: 400px" />

<p>CAP 权衡</p>
<p>在分布式系统中，分区容忍性必不可少，因为需要总是假设网络是不可靠的；CAP 理论实际在是要在可用性和一致性之间做权衡。</p>
<ul>
<li><strong>CP</strong>：需要让所有节点下线成为不可用的状态，等待同步完成。</li>
<li><strong>AP</strong>：在同步过程中允许读取所有节点的数据，但是数据可能不一致。</li>
</ul>
<h2 id="ACID-理论"><a href="#ACID-理论" class="headerlink" title="ACID 理论"></a>ACID 理论</h2><p>ACID 特性：</p>
<ul>
<li><strong>原子性（Atomicity）</strong><ul>
<li>事务被视为不可分割的最小单元，事务中的所有操作要么全部提交成功，要么全部失败回滚。</li>
<li>回滚可以用日志来实现，日志记录着事务所执行的修改操作，在回滚时反向执行这些修改操作即可。</li>
</ul>
</li>
<li><strong>一致性（Consistency）</strong><ul>
<li>数据库在事务执行前后都保持一致性状态。</li>
<li>在一致性状态下，所有事务对一个数据的读取结果都是相同的。</li>
</ul>
</li>
<li><strong>隔离性（Isolation）</strong><ul>
<li>一个事务所做的修改在最终提交以前，对其它事务是不可见的。</li>
</ul>
</li>
<li><strong>持久性（Durability）</strong><ul>
<li>一旦事务提交，则其所做的修改将会永远保存到数据库中。即使系统发生崩溃，事务执行的结果也不能丢失。</li>
<li>可以通过数据库备份和恢复来实现，在系统发生奔溃时，使用备份的数据库进行数据恢复。</li>
</ul>
</li>
</ul>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/cs/database/RDB/%E6%95%B0%E6%8D%AE%E5%BA%93ACID.png" alt="img"></p>
<p>在分布式系统中实现 ACID 比单机复杂的多。</p>
<p>在分布式系统中实现 ACID，即实现分布式事务，具体的方案有如下几种：</p>
<ul>
<li>两阶段提交（2PC）</li>
<li>三阶段提交（3PC）</li>
<li>补偿事务（TCC）</li>
<li>本地消息表（异步确保）</li>
<li>MQ 事务消息</li>
<li>Sagas 事务模型</li>
</ul>
<h2 id="BASE-理论"><a href="#BASE-理论" class="headerlink" title="BASE 理论"></a>BASE 理论</h2><p>BASE 理论是对 CAP 中一致性和可用性权衡的结果。</p>
<p>BASE 是指：即使无法做到强一致性，但每个应用都可以根据自身业务特点，采用适当的方式来使系统达到最终一致性。</p>
<p>BASE 特性</p>
<ul>
<li><strong>基本可用（Basically Available）</strong>：指分布式系统在出现故障的时候，保证核心可用，允许损失部分可用性。</li>
<li><strong>软状态（Soft State）</strong>：指允许系统中的数据存在中间状态，并认为该中间状态不会影响系统整体可用性，即允许系统不同节点的数据副本之间进行同步的过程存在延时。</li>
<li><strong>最终一致性（Eventually Consistent）</strong>：最终一致性强调的是系统中所有的数据副本，在经过一段时间的同步后，最终能达到一致的状态。</li>
</ul>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/cs/design/architecture/%E5%88%86%E5%B8%83%E5%BC%8F%E7%90%86%E8%AE%BA-BASE.png" alt="img"></p>
<h2 id="Paxos-算法"><a href="#Paxos-算法" class="headerlink" title="Paxos 算法"></a>Paxos 算法</h2><p>Paxos 是 Leslie Lamport 于 1990 年提出的一种基于消息传递且具有高度容错特性的共识（consensus）算法。</p>
<p>Paxos 算法包含 2 个部分：</p>
<ul>
<li><strong>Basic Paxos 算法</strong>：描述的多节点之间如何就某个值达成共识。</li>
<li><strong>Multi Paxos 思想</strong>：描述的是执行多个 Basic Paxos 实例，就一系列值达成共识。</li>
</ul>
<p>Paxos 算法解决的问题正是分布式共识性问题，即一个分布式系统中的各个进程如何就某个值（决议）达成一致。</p>
<p>Paxos 算法运行在允许宕机故障的异步系统中，不要求可靠的消息传递，可容忍消息丢失、延迟、乱序以及重复。它利用大多数 (Majority) 机制保证了 2N+1 的容错能力，即 2N+1 个节点的系统最多允许 N 个节点同时出现故障。</p>
<h3 id="Basic-Paxos-算法"><a href="#Basic-Paxos-算法" class="headerlink" title="Basic Paxos 算法"></a>Basic Paxos 算法</h3><h4 id="角色"><a href="#角色" class="headerlink" title="角色"></a>角色</h4><p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20210528150700.png" alt="img"></p>
<ul>
<li><strong>提议者（Proposer）</strong>：发出提案（Proposal），用于投票表决。Proposal 信息包括提案编号 (Proposal ID) 和提议的值 (Value)。在绝大多数场景中，集群中收到客户端请求的节点，才是提议者。这样做的好处是，对业务代码没有入侵性，也就是说，我们不需要在业务代码中实现算法逻辑。</li>
<li><strong>决策者（Acceptor）</strong>：对每个 Proposal 进行投票，若 Proposal 获得多数 Acceptor 的接受，则称该 Proposal 被批准。一般来说，集群中的所有节点都在扮演决策者的角色，参与共识协商，并接受和存储数据。</li>
<li><strong>学习者（Learner）</strong>：不参与决策，从 Proposers&#x2F;Acceptors 学习、记录最新达成共识的提案（Value）。一般来说，学习者是数据备份节点，比如主从架构中的从节点，被动地接受数据，容灾备份。</li>
</ul>
<p>在多副本状态机中，每个副本都同时具有 Proposer、Acceptor、Learner 三种角色。</p>
<p>这三种角色，在本质上代表的是三种功能：</p>
<ul>
<li>提议者代表的是接入和协调功能，收到客户端请求后，发起二阶段提交，进行共识协商；</li>
<li>接受者代表投票协商和存储数据，对提议的值进行投票，并接受达成共识的值，存储保存；</li>
<li>学习者代表存储数据，不参与共识协商，只接受达成共识的值，存储保存。</li>
</ul>
<h4 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h4><p>Paxos 算法通过一个决议分为两个阶段（Learn 阶段之前决议已经形成）：</p>
<ol>
<li><strong>Prepare 阶段</strong>：Proposer 向 Acceptors 发出 Prepare 请求，Acceptors 针对收到的 Prepare 请求进行 Promise 承诺。</li>
<li><strong>Accept 阶段</strong>：Proposer 收到多数 Acceptors 承诺的 Promise 后，向 Acceptors 发出 Propose 请求，Acceptors 针对收到的 Propose 请求进行 Accept 处理。</li>
<li><strong>Learn 阶段</strong>：Proposer 在收到多数 Acceptors 的 Accept 之后，标志着本次 Accept 成功，决议形成，将形成的决议发送给所有 Learners。</li>
</ol>
<p>Paxos 算法流程中的每条消息描述如下：</p>
<ul>
<li><p><strong>Prepare</strong>: Proposer 生成全局唯一且递增的 Proposal ID (可使用时间戳加 Server ID)，向所有 Acceptors 发送 Prepare 请求，这里无需携带提案内容，只携带 Proposal ID 即可。</p>
</li>
<li><p><strong>Promise</strong>: Acceptors 收到 Prepare 请求后，做出“两个承诺，一个应答”。</p>
<ul>
<li><p>两个承诺：</p>
<ul>
<li>不再接受 Proposal ID 小于等于当前请求的 Prepare 请求。</li>
<li>不再接受 Proposal ID 小于当前请求的 Propose 请求。</li>
</ul>
</li>
<li><p>一个应答：</p>
<ul>
<li>不违背以前作出的承诺下，回复已经 Accept 过的提案中 Proposal ID 最大的那个提案的 Value 和 Proposal ID，没有则返回空值。</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>Propose</strong>: Proposer 收到多数 Acceptors 的 Promise 应答后，从应答中选择 Proposal ID 最大的提案的 Value，作为本次要发起的提案。如果所有应答的提案 Value 均为空值，则可以自己随意决定提案 Value。然后携带当前 Proposal ID，向所有 Acceptors 发送 Propose 请求。</p>
</li>
<li><p><strong>Accept</strong>: Acceptor 收到 Propose 请求后，在不违背自己之前作出的承诺下，接受并持久化当前 Proposal ID 和提案 Value。</p>
</li>
<li><p><strong>Learn</strong>: Proposer 收到多数 Acceptors 的 Accept 后，决议形成，将形成的决议发送给所有 Learners。</p>
</li>
</ul>
<h3 id="Multi-Paxos-思想"><a href="#Multi-Paxos-思想" class="headerlink" title="Multi Paxos 思想"></a>Multi Paxos 思想</h3><h4 id="Basic-Paxos-的问题"><a href="#Basic-Paxos-的问题" class="headerlink" title="Basic Paxos 的问题"></a>Basic Paxos 的问题</h4><p>Basic Paxos 有以下问题，导致它不能应用于实际：</p>
<ul>
<li><strong>Basic Paxos 算法只能对一个值形成决议</strong>。</li>
<li><strong>Basic Paxos 算法会消耗大量网络带宽</strong>。Basic Paxos 中，决议的形成至少需要两次网络通信，在高并发情况下可能需要更多的网络通信，极端情况下甚至可能形成活锁。如果想连续确定多个值，Basic Paxos 搞不定了。</li>
</ul>
<h4 id="Multi-Paxos-的改进"><a href="#Multi-Paxos-的改进" class="headerlink" title="Multi Paxos 的改进"></a>Multi Paxos 的改进</h4><p>Multi Paxos 正是为解决以上问题而提出。Multi Paxos 基于 Basic Paxos 做了两点改进：</p>
<ul>
<li>针对每一个要确定的值，运行一次 Paxos 算法实例（Instance），形成决议。每一个 Paxos 实例使用唯一的 Instance ID 标识。</li>
<li>在所有 Proposer 中选举一个 Leader，由 Leader 唯一地提交 Proposal 给 Acceptor 进行表决。这样没有 Proposer 竞争，解决了活锁问题。在系统中仅有一个 Leader 进行 Value 提交的情况下，Prepare 阶段就可以跳过，从而将两阶段变为一阶段，提高效率。</li>
</ul>
<p>Multi Paxos 首先需要选举 Leader，Leader 的确定也是一次决议的形成，所以可执行一次 Basic Paxos 实例来选举出一个 Leader。选出 Leader 之后只能由 Leader 提交 Proposal，在 Leader 宕机之后服务临时不可用，需要重新选举 Leader 继续服务。在系统中仅有一个 Leader 进行 Proposal 提交的情况下，Prepare 阶段可以跳过。</p>
<p>Multi Paxos 通过改变 Prepare 阶段的作用范围至后面 Leader 提交的所有实例，从而使得 Leader 的连续提交只需要执行一次 Prepare 阶段，后续只需要执行 Accept 阶段，将两阶段变为一阶段，提高了效率。为了区分连续提交的多个实例，每个实例使用一个 Instance ID 标识，Instance ID 由 Leader 本地递增生成即可。</p>
<p>Multi Paxos 允许有多个自认为是 Leader 的节点并发提交 Proposal 而不影响其安全性，这样的场景即退化为 Basic Paxos。</p>
<p>Chubby 和 Boxwood 均使用 Multi Paxos。ZooKeeper 使用的 Zab 也是 Multi Paxos 的变形。</p>
<h2 id="Raft-算法"><a href="#Raft-算法" class="headerlink" title="Raft 算法"></a>Raft 算法</h2><h3 id="Raft-基础"><a href="#Raft-基础" class="headerlink" title="Raft 基础"></a>Raft 基础</h3><p>Raft 将一致性问题分解成了三个子问题：</p>
<ul>
<li><strong>选举 Leader</strong></li>
<li><strong>日志复制</strong></li>
<li><strong>安全性</strong></li>
</ul>
<h4 id="服务器角色"><a href="#服务器角色" class="headerlink" title="服务器角色"></a>服务器角色</h4><p>在 Raft 中，任何时刻，每个服务器都处于这三个角色之一 ：</p>
<ul>
<li><strong><code>Leader</code></strong> - 领导者，通常一个系统中是<strong>一主（Leader）多从（Follower）</strong>。Leader <strong>负责处理所有的客户端请求</strong>。</li>
<li><strong><code>Follower</code></strong> - 跟随者，<strong>不会发送任何请求</strong>，只是简单的 <strong>响应来自 Leader 或者 Candidate 的请求</strong>。</li>
<li><strong><code>Candidate</code></strong> - 参选者，选举新 Leader 时的临时角色。</li>
</ul>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20200131215742.png" alt="img"></p>
<blockquote>
<p>:bulb: 图示说明：</p>
<ul>
<li>Follower 只响应来自其他服务器的请求。在一定时限内，如果 Follower 接收不到消息，就会转变成 Candidate，并发起选举。</li>
<li>Candidate 向 Follower 发起投票请求，如果获得集群中半数以上的选票，就会转变为 Leader。</li>
<li>在一个 Term 内，Leader 始终保持不变，直到下线了。Leader 需要周期性向所有 Follower 发送心跳消息，以阻止 Follower 转变为 Candidate。</li>
</ul>
</blockquote>
<h4 id="任期"><a href="#任期" class="headerlink" title="任期"></a>任期</h4><p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20200131220742.png" alt="img"></p>
<p>Raft 把时间分割成任意长度的 <strong><em><code>任期（Term）</code></em><strong>，任期用连续的整数标记。每一段任期从一次</strong>选举</strong>开始。<strong>Raft 保证了在一个给定的任期内，最多只有一个领导者</strong>。</p>
<ul>
<li>如果选举成功，Leader 会管理整个集群直到任期结束。</li>
<li>如果选举失败，那么这个任期就会因为没有 Leader 而结束。</li>
</ul>
<p><strong>不同服务器节点观察到的任期转换状态可能不一样</strong>：</p>
<ul>
<li>服务器节点可能观察到多次的任期转换。</li>
<li>服务器节点也可能观察不到任何一次任期转换。</li>
</ul>
<p><strong>任期在 Raft 算法中充当逻辑时钟的作用，使得服务器节点可以查明一些过期的信息（比如过期的 Leader）。每个服务器节点都会存储一个当前任期号，这一编号在整个时期内单调的增长。当服务器之间通信的时候会交换当前任期号。</strong></p>
<ul>
<li>如果一个服务器的当前任期号比其他人小，那么他会更新自己的编号到较大的编号值。</li>
<li>如果一个 Candidate 或者 Leader 发现自己的任期号过期了，那么他会立即恢复成跟随者状态。</li>
<li>如果一个节点接收到一个包含过期的任期号的请求，那么他会直接拒绝这个请求。</li>
</ul>
<h4 id="RPC"><a href="#RPC" class="headerlink" title="RPC"></a>RPC</h4><p>Raft 算法中服务器节点之间的通信使用 **_<code>远程过程调用（RPC）</code>_**。</p>
<p>基本的一致性算法只需要两种 RPC：</p>
<ul>
<li><strong><code>RequestVote RPC</code></strong> - 请求投票 RPC，由 Candidate 在选举期间发起。</li>
<li><strong><code>AppendEntries RPC</code></strong> - 附加条目 RPC，由 Leader 发起，用来复制日志和提供一种心跳机制。</li>
</ul>
<h3 id="选举-Leader"><a href="#选举-Leader" class="headerlink" title="选举 Leader"></a>选举 Leader</h3><h4 id="选举规则"><a href="#选举规则" class="headerlink" title="选举规则"></a>选举规则</h4><p><strong>Raft 使用一种心跳机制来触发 Leader 选举</strong>。</p>
<p><strong>Leader 需要周期性的向所有 Follower 发送心跳消息</strong>，以此维持自己的权威并阻止新 Leader 的产生。</p>
<p>每个 Follower 都设置了一个<strong>随机的竞选超时时间</strong>，一般为 <code>150ms ~ 300ms</code>，如果在竞选超时时间内没有收到 Leader 的心跳消息，就会认为当前 Term 没有可用的 Leader，并发起选举来选出新的 Leader。开始一次选举过程，Follower 先要增加自己的当前 Term 号，并<strong>转换为 Candidate</strong>。</p>
<p>Candidate 会并行的<strong>向集群中的所有服务器节点发送投票请求（<code>RequestVote RPC</code>）</strong>，它会保持当前状态直到以下三件事情之一发生：</p>
<ul>
<li><strong>自己成为 Leader</strong></li>
<li><strong>其他的服务器成为 Leader</strong></li>
<li><strong>没有任何服务器成为 Leader</strong></li>
</ul>
<h5 id="自己成为-Leader"><a href="#自己成为-Leader" class="headerlink" title="自己成为 Leader"></a>自己成为 Leader</h5><ul>
<li>当一个 Candidate 从整个集群<strong>半数以上</strong>的服务器节点获得了针对同一个 Term 的选票，那么它就赢得了这次选举并成为 Leader。每个服务器最多会对一个 Term 投出一张选票，按照先来先服务（FIFO）的原则。_要求半数以上选票的规则确保了最多只会有一个 Candidate 赢得此次选举_。</li>
<li>一旦 Candidate 赢得选举，就立即成为 Leader。然后它会向其他的服务器发送心跳消息来建立自己的权威并且阻止新的领导人的产生。</li>
</ul>
<h5 id="其他的服务器成为-Leader"><a href="#其他的服务器成为-Leader" class="headerlink" title="其他的服务器成为 Leader"></a>其他的服务器成为 Leader</h5><p>等待投票期间，Candidate 可能会从其他的服务器接收到声明它是 Leader 的 <code>AppendEntries RPC</code>。</p>
<ul>
<li>如果这个 Leader 的 Term 号（包含在此次的 RPC 中）不小于 Candidate 当前的 Term，那么 Candidate 会承认 Leader 合法并回到 Follower 状态。</li>
<li>如果此次 RPC 中的 Term 号比自己小，那么 Candidate 就会拒绝这个消息并继续保持 Candidate 状态。</li>
</ul>
<h5 id="没有任何服务器成为-Leader"><a href="#没有任何服务器成为-Leader" class="headerlink" title="没有任何服务器成为 Leader"></a>没有任何服务器成为 Leader</h5><p>如果有多个 Follower 同时成为 Candidate，那么选票可能会被瓜分以至于没有 Candidate 可以赢得半数以上的投票。当这种情况发生的时候，每一个 Candidate 都会竞选超时，然后通过增加当前 Term 号来开始一轮新的选举。然而，没有其他机制的话，选票可能会被无限的重复瓜分。</p>
<p>Raft 算法使用随机选举超时时间的方法来确保很少会发生选票瓜分的情况，就算发生也能很快的解决。为了阻止选票起初就被瓜分，竞选超时时间是一个<strong>随机的时间</strong>，在一个固定的区间（例如 150-300 毫秒）随机选择，这样可以把选举都分散开。</p>
<ul>
<li>以至于在大多数情况下，只有一个服务器会超时，然后它赢得选举，成为 Leader，并在其他服务器超时之前发送心跳包。</li>
<li>同样的机制也被用在选票瓜分的情况下：每一个 Candidate 在开始一次选举的时候会重置一个随机的选举超时时间，然后在超时时间内等待投票的结果；这样减少了在新的选举中另外的选票瓜分的可能性。</li>
</ul>
<hr>
<p>理解了上面的选举规则后，我们通过动图来加深认识。</p>
<h3 id="日志复制"><a href="#日志复制" class="headerlink" title="日志复制"></a>日志复制</h3><h4 id="日志格式"><a href="#日志格式" class="headerlink" title="日志格式"></a>日志格式</h4><p><strong>日志由含日志索引（log index）的日志条目（log entry）组成</strong>。每个日志条目包含它被创建时的 Term 号（下图中方框中的数字），和一个复制状态机需要执行的指令。如果一个日志条目被复制到半数以上的服务器上，就被认为可以提交（Commit）了。</p>
<ul>
<li>日志条目中的 Term 号被用来检查是否出现不一致的情况。</li>
<li>日志条目中的日志索引（一个整数值）用来表明它在日志中的位置。</li>
</ul>
<p><img src="https://pic3.zhimg.com/80/v2-ee29a89e4eb63468e142bb6103dbe4de_hd.jpg" alt="img"></p>
<p>Raft 日志同步保证如下两点：</p>
<ul>
<li>如果不同日志中的两个日志条目有着相同的日志索引和 Term，则<strong>它们所存储的命令是相同的</strong>。<ul>
<li>这个特性基于这条原则：Leader 最多在一个 Term 内、在指定的一个日志索引上创建一条日志条目，同时日志条目在日志中的位置也从来不会改变。</li>
</ul>
</li>
<li>如果不同日志中的两个日志条目有着相同的日志索引和 Term，则<strong>它们之前的所有条目都是完全一样的</strong>。<ul>
<li>这个特性由 <code>AppendEntries RPC</code> 的一个简单的一致性检查所保证。在发送 <code>AppendEntries RPC</code> 时，Leader 会把新日志条目之前的日志条目的日志索引和 Term 号一起发送。如果 Follower 在它的日志中找不到包含相同日志索引和 Term 号的日志条目，它就会拒绝接收新的日志条目。</li>
</ul>
</li>
</ul>
<h4 id="日志复制流程"><a href="#日志复制流程" class="headerlink" title="日志复制流程"></a>日志复制流程</h4><p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20200201115848.png" alt="img"></p>
<ol>
<li>Leader 负责处理所有客户端的请求。</li>
<li>Leader 把请求作为日志条目加入到它的日志中，然后并行的向其他服务器发送 <code>AppendEntries RPC</code> 请求，要求 Follower 复制日志条目。</li>
<li>Follower 复制成功后，返回确认消息。</li>
<li>当这个日志条目被半数以上的服务器复制后，Leader 提交这个日志条目到它的复制状态机，并向客户端返回执行结果。</li>
</ol>
<blockquote>
<p>注意：如果 Follower 崩溃或者运行缓慢，再或者网络丢包，Leader 会不断的重复尝试发送 <code>AppendEntries RPC</code> 请求 （尽管已经回复了客户端），直到所有的跟随者都最终复制了所有的日志条目。</p>
</blockquote>
<h4 id="日志一致性"><a href="#日志一致性" class="headerlink" title="日志一致性"></a>日志一致性</h4><p>一般情况下，Leader 和 Followers 的日志保持一致，因此日志条目一致性检查通常不会失败。然而，Leader 崩溃可能会导致日志不一致：旧的 Leader 可能没有完全复制完日志中的所有条目。</p>
<h5 id="Leader-和-Follower-日志不一致的可能"><a href="#Leader-和-Follower-日志不一致的可能" class="headerlink" title="Leader 和 Follower 日志不一致的可能"></a>Leader 和 Follower 日志不一致的可能</h5><p>Leader 和 Follower 可能存在多种日志不一致的可能。</p>
<p><img src="https://pic4.zhimg.com/80/v2-d36c587901391cae50788061f568d24f_hd.jpg" alt="img"></p>
<blockquote>
<p>:bulb: 图示说明：</p>
<p>上图阐述了 Leader 和 Follower 可能存在多种日志不一致的可能，每一个方框表示一个日志条目，里面的数字表示任期号 。</p>
<p>当一个 Leader 成功当选时，Follower 可能出现以下情况（a-f）：</p>
<ul>
<li><strong>存在未更新日志条目</strong>，如（a、b）。</li>
<li><strong>存在未提交日志条目</strong>，如（c、d）。</li>
<li>或<strong>两种情况都存在</strong>，如（e、f）。</li>
</ul>
<p>_例如，场景 f 可能会这样发生，某服务器在 Term2 的时候是 Leader，已附加了一些日志条目到自己的日志中，但在提交之前就崩溃了；很快这个机器就被重启了，在 Term3 重新被选为 Leader，并且又增加了一些日志条目到自己的日志中；在 Term 2 和 Term 3 的日志被提交之前，这个服务器又宕机了，并且在接下来的几个任期里一直处于宕机状态_。</p>
</blockquote>
<h5 id="Leader-和-Follower-日志一致的保证"><a href="#Leader-和-Follower-日志一致的保证" class="headerlink" title="Leader 和 Follower 日志一致的保证"></a>Leader 和 Follower 日志一致的保证</h5><p>Leader 通过强制 Followers 复制它的日志来处理日志的不一致，<strong>Followers 上的不一致的日志会被 Leader 的日志覆盖</strong>。</p>
<ul>
<li>Leader 为了使 Followers 的日志同自己的一致，Leader 需要找到 Followers 同它的日志一致的地方，然后覆盖 Followers 在该位置之后的条目。</li>
<li>Leader 会从后往前试，每次日志条目失败后尝试前一个日志条目，直到成功找到每个 Follower 的日志一致位点，然后向后逐条覆盖 Followers 在该位置之后的条目。</li>
</ul>
<h3 id="安全性"><a href="#安全性" class="headerlink" title="安全性"></a>安全性</h3><p>前面描述了 Raft 算法是如何选举 Leader 和复制日志的。</p>
<p>Raft 还增加了一些限制来完善 Raft 算法，以保证安全性：保证了任意 Leader 对于给定的 Term，都拥有了之前 Term 的所有被提交的日志条目。</p>
<h4 id="选举限制"><a href="#选举限制" class="headerlink" title="选举限制"></a>选举限制</h4><p>拥有最新的已提交的日志条目的 Follower 才有资格成为 Leader。</p>
<p>Raft 使用投票的方式来阻止一个 Candidate 赢得选举除非这个 Candidate 包含了所有已经提交的日志条目。 Candidate 为了赢得选举必须联系集群中的大部分节点，这意味着每一个已经提交的日志条目在这些服务器节点中肯定存在于至少一个节点上。如果 Candidate 的日志至少和大多数的服务器节点一样新（这个新的定义会在下面讨论），那么他一定持有了所有已经提交的日志条目。</p>
<p><code>RequestVote RPC</code> 实现了这样的限制：<strong>RequestVote RPC 中包含了 Candidate 的日志信息， Follower 会拒绝掉那些日志没有自己新的投票请求</strong>。</p>
<p>如何判断哪个日志条目比较新？</p>
<p>Raft 通过比较两份日志中最后一条日志条目的日志索引和 Term 来判断哪个日志比较新。</p>
<ul>
<li>先判断 Term，哪个数值大即代表哪个日志比较新。</li>
<li>如果 Term 相同，再比较 日志索引，哪个数值大即代表哪个日志比较新。</li>
</ul>
<h4 id="提交旧任期的日志条目"><a href="#提交旧任期的日志条目" class="headerlink" title="提交旧任期的日志条目"></a>提交旧任期的日志条目</h4><p>一个当前 Term 的日志条目被复制到了半数以上的服务器上，Leader 就认为它是可以被提交的。如果这个 Leader 在提交日志条目前就下线了，后续的 Leader 可能会覆盖掉这个日志条目。</p>
<p><img src="https://pic4.zhimg.com/80/v2-12a5ebab63781f9ec49e14e331775537_hd.jpg" alt="img"></p>
<blockquote>
<p>💡 图示说明：</p>
<p>上图解释了为什么 Leader 无法对旧 Term 的日志条目进行提交。</p>
<ul>
<li>阶段 (a) ，S1 是 Leader，且 S1 写入日志条目为 (Term 2，日志索引 2），只有 S2 复制了这个日志条目。</li>
<li>阶段 (b)，S1 下线，S5 被选举为 Term3 的 Leader。S5 写入日志条目为 (Term 3，日志索引 2）。</li>
<li>阶段 (c)，S5 下线，S1 重新上线，并被选举为 Term4 的 Leader。此时，Term 2 的那条日志条目已经被复制到了集群中的大多数节点上，但是还没有被提交。</li>
<li>阶段 (d)，S1 再次下线，S5 重新上线，并被重新选举为 Term3 的 Leader。然后 S5 覆盖了日志索引 2 处的日志。</li>
<li>阶段 (e)，如果阶段 (d) 还未发生，即 S1 再次下线之前，S1 把自己主导的日志条目复制到了大多数节点上，那么在后续 Term 里面这些新日志条目就会被提交。这样在同一时刻就同时保证了，之前的所有旧日志条目就会被提交。</li>
</ul>
</blockquote>
<p><strong>Raft 永远不会通过计算副本数目的方式去提交一个之前 Term 内的日志条目</strong>。只有 Leader 当前 Term 里的日志条目通过计算副本数目可以被提交；一旦当前 Term 的日志条目以这种方式被提交，那么由于日志匹配特性，之前的日志条目也都会被间接的提交。</p>
<p>当 Leader 复制之前任期里的日志时，Raft 会为所有日志保留原始的 Term，这在提交规则上产生了额外的复杂性。在其他的一致性算法中，如果一个新的领导人要重新复制之前的任期里的日志时，它必须使用当前新的任期号。Raft 使用的方法更加容易辨别出日志，因为它可以随着时间和日志的变化对日志维护着同一个任期编号。另外，和其他的算法相比，Raft 中的新领导人只需要发送更少日志条目（其他算法中必须在他们被提交之前发送更多的冗余日志条目来为他们重新编号）。</p>
<h3 id="日志压缩"><a href="#日志压缩" class="headerlink" title="日志压缩"></a>日志压缩</h3><p>在实际的系统中，不能让日志无限膨胀，否则系统重启时需要花很长的时间进行恢复，从而影响可用性。Raft 采用对整个系统进行快照来解决，快照之前的日志都可以丢弃。</p>
<p>每个副本独立的对自己的系统状态生成快照，并且只能对已经提交的日志条目生成快照。</p>
<p>快照包含以下内容：</p>
<ul>
<li>日志元数据。最后一条已提交的日志条目的日志索引和 Term。这两个值在快照之后的第一条日志条目的 <code>AppendEntries RPC</code> 的完整性检查的时候会被用上。</li>
<li>系统当前状态。</li>
</ul>
<p>当 Leader 要发送某个日志条目，落后太多的 Follower 的日志条目会被丢弃，Leader 会将快照发给 Follower。或者新上线一台机器时，也会发送快照给它。</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20200201220628.png" alt="img"></p>
<p><strong>生成快照的频率要适中</strong>，频率过高会消耗大量 I&#x2F;O 带宽；频率过低，一旦需要执行恢复操作，会丢失大量数据，影响可用性。推荐当日志达到某个固定的大小时生成快照。</p>
<p>生成一次快照可能耗时过长，影响正常日志同步。可以通过使用 copy-on-write 技术避免快照过程影响正常日志同步。</p>
<blockquote>
<p>说明：本文仅阐述 Raft 算法的核心内容，不包括算法论证、评估等</p>
</blockquote>
<h2 id="一致性哈希算法"><a href="#一致性哈希算法" class="headerlink" title="一致性哈希算法"></a>一致性哈希算法</h2><p><strong><code>一致性哈希（Consistent Hash）</code><strong>算法的目标是：</strong>相同的请求尽可能落到同一个服务器上</strong>。</p>
<p><strong>一致性哈希</strong> 可以很好的解决 <strong>稳定性问题</strong>，可以将所有的 <strong>存储节点</strong> 排列在 <strong>首尾相接</strong> 的 <code>Hash</code> 环上，每个 <code>key</code> 在计算 <code>Hash</code> 后会 <strong>顺时针</strong> 找到 <strong>临接</strong> 的 <strong>存储节点</strong> 存放。而当有节点 <strong>加入</strong> 或 <strong>退出</strong> 时，仅影响该节点在 <code>Hash</code> 环上 <strong>顺时针相邻</strong> 的 <strong>后续节点</strong>。</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/cs/design/architecture/partition-consistent-hash.png" alt="img"></p>
<ul>
<li><strong>相同的请求</strong>是指：一般在使用一致性哈希时，需要指定一个 key 用于 hash 计算，可能是：<ul>
<li>用户 ID</li>
<li>请求方 IP</li>
<li>请求服务名称，参数列表构成的串</li>
</ul>
</li>
<li><strong>尽可能</strong>是指：服务器可能发生上下线，少数服务器的变化不应该影响大多数的请求。</li>
</ul>
<p>当某台候选服务器宕机时，原本发往该服务器的请求，会基于虚拟节点，平摊到其它候选服务器，不会引起剧烈变动。</p>
<ul>
<li><strong>优点</strong></li>
</ul>
<p><strong>加入</strong> 和 <strong>删除</strong> 节点只影响 <strong>哈希环</strong> 中 <strong>顺时针方向</strong> 的 <strong>相邻的节点</strong>，对其他节点无影响。</p>
<ul>
<li><strong>缺点</strong></li>
</ul>
<p><strong>加减节点</strong> 会造成 <strong>哈希环</strong> 中部分数据 <strong>无法命中</strong>。当使用 <strong>少量节点</strong> 时，<strong>节点变化</strong> 将大范围影响 <strong>哈希环</strong> 中 <strong>数据映射</strong>，不适合 <strong>少量数据节点</strong> 的分布式方案。<strong>普通</strong> 的 <strong>一致性哈希分区</strong> 在增减节点时需要 <strong>增加一倍</strong> 或 <strong>减去一半</strong> 节点才能保证 <strong>数据</strong> 和 <strong>负载的均衡</strong>。</p>
<blockquote>
<p><strong>注意</strong>：因为 <strong>一致性哈希分区</strong> 的这些缺点，一些分布式系统采用 <strong>虚拟槽</strong> 对 <strong>一致性哈希</strong> 进行改进，比如 <code>Dynamo</code> 系统。</p>
</blockquote>
<h2 id="Gossip-协议"><a href="#Gossip-协议" class="headerlink" title="Gossip 协议"></a>Gossip 协议</h2><p>Gossip 协议是集群中节点相互通信的内部通信技术。 Gossip 是一种高效、轻量级、可靠的节点间广播协议，用于传播数据。它是去中心化的、“流行病”的、容错的和点对点通信协议。</p>
<p>Goosip 协议的信息传播和扩散通常需要由种子节点发起。整个传播过程可能需要一定的时间，由于不能保证某个时刻所有节点都收到消息，但是理论上最终所有节点都会收到消息，因此它是一个<strong>最终一致性</strong>协议。</p>
<h3 id="Gossip-的执行过程"><a href="#Gossip-的执行过程" class="headerlink" title="Gossip 的执行过程"></a>Gossip 的执行过程</h3><p>Gossip 协议的执行过程：Gossip 过程是由种子节点发起，当一个种子节点有状态需要更新到网络中的其他节点时，它会随机的选择周围几个节点散播消息，收到消息的节点也会重复该过程，直至最终网络中所有的节点都收到了消息。这个过程可能需要一定的时间，由于不能保证某个时刻所有节点都收到消息，但是理论上最终所有节点都会收到消息，因此它是一个最终一致性协议。</p>
<h3 id="Gossip-类型"><a href="#Gossip-类型" class="headerlink" title="Gossip 类型"></a>Gossip 类型</h3><p>Gossip 有两种类型：</p>
<ul>
<li>**Anti-Entropy(反熵)**：以固定的概率传播所有的数据。Anti-Entropy 是 SI model，节点只有两种状态，Suspective 和 Infective，叫做 simple epidemics。</li>
<li>**Rumor-Mongering(谣言传播)**：仅传播新到达的数据。Rumor-Mongering 是 SIR model，节点有三种状态，Suspective，Infective 和 Removed，叫做 complex epidemics。</li>
</ul>
<p>熵是物理学上的一个概念，代表杂乱无章，而反熵就是在杂乱无章中寻求一致。本质上，<strong>反熵是一种通过异步修复实现最终一致性的方法</strong>。反熵指的是集群中的节点，每隔段时间就随机选择某个其他节点，然后通过互相交换自己的所有数据来消除两者之间的差异，实现数据的最终一致性。由于消息会不断反复的交换，因此消息数量是非常庞大的，无限制的（unbounded），这对一个系统来说是一个巨大的开销。所以，<strong>反熵不适合动态变化或节点数比较多的分布式环境</strong>。</p>
<p>谣言传播模型指的是当一个节点有了新数据后，这个节点变成活跃状态，并周期性地联系其他节点向其发送新数据，直到所有的节点都存储了该新数据。在谣言传播模型下，消息可以发送得更频繁，因为消息只包含最新 update，体积更小。而且，一个谣言消息在某个时间点之后会被标记为 removed，并且不再被传播，因此，谣言传播模型下，系统有一定的概率会不一致。而由于，谣言传播模型下某个时间点之后消息不再传播，因此消息是有限的，系统开销小。</p>
<p>一般来说，为了在通信代价和可靠性之间取得折中，需要将这两种方法结合使用。</p>
<p><strong>Gossip 中的通信模式</strong></p>
<p>在 Gossip 协议下，网络中两个节点之间有三种通信方式:</p>
<ul>
<li>Push: 节点 A 将数据 (key,value,version) 及对应的版本号推送给 B 节点，B 节点更新 A 中比自己新的数据</li>
<li>Pull：A 仅将数据 key, version 推送给 B，B 将本地比 A 新的数据（Key, value, version）推送给 A，A 更新本地</li>
<li>Push&#x2F;Pull：与 Pull 类似，只是多了一步，A 再将本地比 B 新的数据推送给 B，B 则更新本地</li>
</ul>
<p>如果把两个节点数据同步一次定义为一个周期，则在一个周期内，Push 需通信 1 次，Pull 需 2 次，Push&#x2F;Pull 则需 3 次。虽然消息数增加了，但从效果上来讲，Push&#x2F;Pull 最好，理论上一个周期内可以使两个节点完全一致。直观上，Push&#x2F;Pull 的收敛速度也是最快的。</p>
<h3 id="Gossip-的优点"><a href="#Gossip-的优点" class="headerlink" title="Gossip 的优点"></a>Gossip 的优点</h3><ul>
<li><strong>扩展性</strong>：网络可以允许节点的任意增加和减少，新增加的节点的状态最终会与其他节点一致。</li>
<li><strong>容错</strong>：网络中任何节点的宕机和重启都不会影响 Gossip 消息的传播，Gossip 协议具有天然的分布式系统容错特性。</li>
<li><strong>去中心化</strong>：Gossip 协议不要求任何中心节点，所有节点都可以是对等的，任何一个节点无需知道整个网络状况，只要网络是连通的，任意一个节点就可以把消息散播到全网。</li>
<li><strong>一致性收敛</strong>：Gossip 协议中的消息会以一传十、十传百一样的指数级速度在网络中快速传播，因此系统状态的不一致可以在很快的时间内收敛到一致。消息传播速度达到了 logN。</li>
<li><strong>简单</strong>：Gossip 协议的过程极其简单，实现起来几乎没有太多复杂性。</li>
</ul>
<h3 id="Gossip-的缺陷"><a href="#Gossip-的缺陷" class="headerlink" title="Gossip 的缺陷"></a>Gossip 的缺陷</h3><p>分布式网络中，没有一种完美的解决方案，Gossip 协议跟其他协议一样，也有一些不可避免的缺陷，主要是两个：</p>
<ul>
<li><strong>消息的延迟</strong>：由于 Gossip 协议中，节点只会随机向少数几个节点发送消息，消息最终是通过多个轮次的散播而到达全网的，因此使用 Gossip 协议会造成不可避免的消息延迟。不适合用在对实时性要求较高的场景下。</li>
<li><strong>消息冗余</strong>：Gossip 协议规定，节点会定期随机选择周围节点发送消息，而收到消息的节点也会重复该步骤，因此就不可避免的存在消息重复发送给同一节点的情况，造成了消息的冗余，同时也增加了收到消息的节点的处理压力。而且，由于是定期发送，因此，即使收到了消息的节点还会反复收到重复消息，加重了消息的冗余。</li>
</ul>
<h2 id="QuorumNWR-算法"><a href="#QuorumNWR-算法" class="headerlink" title="QuorumNWR 算法"></a>QuorumNWR 算法</h2><p>通过 Quorum NWR，你可以自定义一致性级别，通过临时调整写入或者查询的方式，当 <code>W + R &gt; N</code> 时，就可以实现强一致性了。</p>
<h3 id="Quorum-NWR-的三要素"><a href="#Quorum-NWR-的三要素" class="headerlink" title="Quorum NWR 的三要素"></a>Quorum NWR 的三要素</h3><ul>
<li>**<code>N</code>**：表示副本数，又叫做复制因子（Replication Factor）。也就是说，N 表示集群中同一份数据有多少个副本。在实现 Quorum NWR 的时候，你需要实现自定义副本的功能。也就是说，用户可以自定义指定数据的副本数。</li>
<li>**<code>W</code>**：又称写一致性级别（Write Consistency Level），表示成功完成 W 个副本更新，才完成写操作</li>
<li>**<code>R</code>**：又称读一致性级别（Read Consistency Level），表示读取一个数据对象时需要读 R 个副本。你可以这么理解，读取指定数据时，要读 R 副本，然后返回 R 个副本中最新的那份数据。</li>
</ul>
<p>N、W、R 值的不同组合，会产生不同的一致性效果：</p>
<ul>
<li>当 <code>W + R &gt; N</code> 的时候，对于客户端来讲，整个系统能保证强一致性，一定能返回更新后的那份数据。</li>
<li>当 <code>W + R &lt; N</code> 的时候，对于客户端来讲，整个系统只能保证最终一致性，可能会返回旧数据。</li>
</ul>
<p>需要注意的是，副本数不能超过节点数：多副本的意义在于冗余备份，如果副本数超过节点数，就意味着在一个节点上会存在多个副本，那么冗余备份的意义就不大了。</p>
<h2 id="PBFT-算法"><a href="#PBFT-算法" class="headerlink" title="PBFT 算法"></a>PBFT 算法</h2><p>略</p>
<h2 id="PoW-算法"><a href="#PoW-算法" class="headerlink" title="PoW 算法"></a>PoW 算法</h2><p>略</p>
<h2 id="ZAB-协议"><a href="#ZAB-协议" class="headerlink" title="ZAB 协议"></a>ZAB 协议</h2><blockquote>
<p>ZooKeeper 并没有直接采用 Paxos 算法，而是采用了名为 ZAB 的一致性协议。**<em>ZAB 协议不是 Paxos 算法</em>**，只是比较类似，二者在操作上并不相同。</p>
<p>ZAB 协议是 Zookeeper 专门设计的一种<strong>支持崩溃恢复的原子广播协议</strong>。</p>
<p>ZAB 协议是 ZooKeeper 的数据一致性和高可用解决方案。</p>
</blockquote>
<p>ZAB 协议定义了两个可以<strong>无限循环</strong>的流程：</p>
<ul>
<li><strong><code>选举 Leader</code></strong> - 用于故障恢复，从而保证高可用。</li>
<li><strong><code>原子广播</code></strong> - 用于主从同步，从而保证数据一致性。</li>
</ul>
<h3 id="选举-Leader-1"><a href="#选举-Leader-1" class="headerlink" title="选举 Leader"></a>选举 Leader</h3><blockquote>
<p><strong>ZooKeeper 的故障恢复</strong></p>
<p>ZooKeeper 集群采用一主（称为 Leader）多从（称为 Follower）模式，主从节点通过副本机制保证数据一致。</p>
<ul>
<li><strong>如果 Follower 节点挂了</strong> - ZooKeeper 集群中的每个节点都会单独在内存中维护自身的状态，并且各节点之间都保持着通讯，<strong>只要集群中有半数机器能够正常工作，那么整个集群就可以正常提供服务</strong>。</li>
<li><strong>如果 Leader 节点挂了</strong> - 如果 Leader 节点挂了，系统就不能正常工作了。此时，需要通过 ZAB 协议的选举 Leader 机制来进行故障恢复。</li>
</ul>
<p>ZAB 协议的选举 Leader 机制简单来说，就是：基于过半选举机制产生新的 Leader，之后其他机器将从新的 Leader 上同步状态，当有过半机器完成状态同步后，就退出选举 Leader 模式，进入原子广播模式。</p>
</blockquote>
<h4 id="术语"><a href="#术语" class="headerlink" title="术语"></a>术语</h4><ul>
<li><strong>myid</strong> - 每个 Zookeeper 服务器，都需要在数据文件夹下创建一个名为 myid 的文件，该文件包含整个 Zookeeper 集群唯一的 ID（整数）。</li>
<li><strong>zxid</strong> - 类似于 RDBMS 中的事务 ID，用于标识一次更新操作的 Proposal ID。为了保证顺序性，该 zkid 必须单调递增。因此 Zookeeper 使用一个 64 位的数来表示，高 32 位是 Leader 的 epoch，从 1 开始，每次选出新的 Leader，epoch 加一。低 32 位为该 epoch 内的序号，每次 epoch 变化，都将低 32 位的序号重置。这样保证了 zkid 的全局递增性。</li>
</ul>
<h4 id="服务器状态"><a href="#服务器状态" class="headerlink" title="服务器状态"></a>服务器状态</h4><ul>
<li><strong><em>LOOKING</em></strong> - 不确定 Leader 状态。该状态下的服务器认为当前集群中没有 Leader，会发起 Leader 选举</li>
<li><strong><em>FOLLOWING</em></strong> - 跟随者状态。表明当前服务器角色是 Follower，并且它知道 Leader 是谁</li>
<li><strong><em>LEADING</em></strong> - 领导者状态。表明当前服务器角色是 Leader，它会维护与 Follower 间的心跳</li>
<li><strong><em>OBSERVING</em></strong> - 观察者状态。表明当前服务器角色是 Observer，与 Folower 唯一的不同在于不参与选举，也不参与集群写操作时的投票</li>
</ul>
<h4 id="选票数据结构"><a href="#选票数据结构" class="headerlink" title="选票数据结构"></a>选票数据结构</h4><p>每个服务器在进行领导选举时，会发送如下关键信息</p>
<ul>
<li><strong><em>logicClock</em></strong> - 每个服务器会维护一个自增的整数，名为 logicClock，它表示这是该服务器发起的第多少轮投票</li>
<li><strong><em>state</em></strong> - 当前服务器的状态</li>
<li><strong><em>self_id</em></strong> - 当前服务器的 myid</li>
<li><strong><em>self_zxid</em></strong> - 当前服务器上所保存的数据的最大 zxid</li>
<li><strong><em>vote_id</em></strong> - 被推举的服务器的 myid</li>
<li><strong><em>vote_zxid</em></strong> - 被推举的服务器上所保存的数据的最大 zxid</li>
</ul>
<h4 id="投票流程"><a href="#投票流程" class="headerlink" title="投票流程"></a>投票流程</h4><p>（1）<strong>自增选举轮次</strong> - Zookeeper 规定所有有效的投票都必须在同一轮次中。每个服务器在开始新一轮投票时，会先对自己维护的 logicClock 进行自增操作。</p>
<p>（2）<strong>初始化选票</strong> - 每个服务器在广播自己的选票前，会将自己的投票箱清空。该投票箱记录了所收到的选票。例：服务器 2 投票给服务器 3，服务器 3 投票给服务器 1，则服务器 1 的投票箱为(2, 3), (3, 1), (1, 1)。票箱中只会记录每一投票者的最后一票，如投票者更新自己的选票，则其它服务器收到该新选票后会在自己票箱中更新该服务器的选票。</p>
<p>（3）<strong>发送初始化选票</strong> - 每个服务器最开始都是通过广播把票投给自己。</p>
<p>（4）<strong>接收外部投票</strong> - 服务器会尝试从其它服务器获取投票，并记入自己的投票箱内。如果无法获取任何外部投票，则会确认自己是否与集群中其它服务器保持着有效连接。如果是，则再次发送自己的投票；如果否，则马上与之建立连接。</p>
<p>（5）<strong>判断选举轮次</strong> - 收到外部投票后，首先会根据投票信息中所包含的 logicClock 来进行不同处理</p>
<ul>
<li>外部投票的 logicClock 大于自己的 logicClock。说明该服务器的选举轮次落后于其它服务器的选举轮次，立即清空自己的投票箱并将自己的 logicClock 更新为收到的 logicClock，然后再对比自己之前的投票与收到的投票以确定是否需要变更自己的投票，最终再次将自己的投票广播出去。</li>
<li>外部投票的 logicClock 小于自己的 logicClock。当前服务器直接忽略该投票，继续处理下一个投票。</li>
<li>外部投票的 logickClock 与自己的相等。当时进行选票 PK。</li>
</ul>
<p>（6）<strong>选票 PK</strong> - 选票 PK 是基于<code>(self_id, self_zxid)</code> 与 <code>(vote_id, vote_zxid)</code> 的对比</p>
<ul>
<li>外部投票的 logicClock 大于自己的 logicClock，则将自己的 logicClock 及自己的选票的 logicClock 变更为收到的 logicClock</li>
<li>若 logicClock 一致，则对比二者的 vote_zxid，若外部投票的 vote_zxid 比较大，则将自己的票中的 vote_zxid 与 vote_myid 更新为收到的票中的 vote_zxid 与 vote_myid 并广播出去，另外将收到的票及自己更新后的票放入自己的票箱。如果票箱内已存在(self_myid, self_zxid)相同的选票，则直接覆盖</li>
<li>若二者 vote_zxid 一致，则比较二者的 vote_myid，若外部投票的 vote_myid 比较大，则将自己的票中的 vote_myid 更新为收到的票中的 vote_myid 并广播出去，另外将收到的票及自己更新后的票放入自己的票箱</li>
</ul>
<p>（7）<strong>统计选票</strong> - 如果已经确定有过半服务器认可了自己的投票（可能是更新后的投票），则终止投票。否则继续接收其它服务器的投票。</p>
<p>（8）<strong>更新服务器状态</strong> - 投票终止后，服务器开始更新自身状态。若过半的票投给了自己，则将自己的服务器状态更新为 LEADING，否则将自己的状态更新为 FOLLOWING</p>
<p>通过以上流程分析，我们不难看出：要使 Leader 获得多数 Server 的支持，则 <strong>ZooKeeper 集群节点数必须是奇数。且存活的节点数目不得少于 <code>N + 1</code></strong> 。</p>
<p>每个 Server 启动后都会重复以上流程。在恢复模式下，如果是刚从崩溃状态恢复的或者刚启动的 server 还会从磁盘快照中恢复数据和会话信息，zk 会记录事务日志并定期进行快照，方便在恢复时进行状态恢复。</p>
<h3 id="原子广播（Atomic-Broadcast）"><a href="#原子广播（Atomic-Broadcast）" class="headerlink" title="原子广播（Atomic Broadcast）"></a>原子广播（Atomic Broadcast）</h3><p><strong>ZooKeeper 通过副本机制来实现高可用</strong>。</p>
<p>那么，ZooKeeper 是如何实现副本机制的呢？答案是：ZAB 协议的原子广播。</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/cs/java/javaweb/distributed/rpc/zookeeper/zookeeper_3.png" alt="img"></p>
<p>ZAB 协议的原子广播要求：</p>
<p>**<em>所有的写请求都会被转发给 Leader，Leader 会以原子广播的方式通知 Follow。当半数以上的 Follow 已经更新状态持久化后，Leader 才会提交这个更新，然后客户端才会收到一个更新成功的响应</em>**。这有些类似数据库中的两阶段提交协议。</p>
<p>在整个消息的广播过程中，Leader 服务器会每个事务请求生成对应的 Proposal，并为其分配一个全局唯一的递增的事务 ID(ZXID)，之后再对其进行广播。</p>
<h2 id="InfluxDB-企业版一致性实现剖析"><a href="#InfluxDB-企业版一致性实现剖析" class="headerlink" title="InfluxDB 企业版一致性实现剖析"></a>InfluxDB 企业版一致性实现剖析</h2><p>略</p>
<h2 id="Hashicorp-Raft"><a href="#Hashicorp-Raft" class="headerlink" title="Hashicorp Raft"></a>Hashicorp Raft</h2><p>略</p>
<h2 id="基于-Raft-的分布式-KV-系统开发实战"><a href="#基于-Raft-的分布式-KV-系统开发实战" class="headerlink" title="基于 Raft 的分布式 KV 系统开发实战"></a>基于 Raft 的分布式 KV 系统开发实战</h2><p>略</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul>
<li><a target="_blank" rel="noopener" href="https://time.geekbang.org/column/intro/100046101">分布式协议与算法实战</a></li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://dunwu.github.io/blog/pages/996032a2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/blog/uploads/avatar.gif">
      <meta itemprop="name" content="钝悟 ◾ Dunwu">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Dunwu Blog">
      <meta itemprop="description" content="钝悟的个人博客">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | Dunwu Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/blog/pages/996032a2/" class="post-title-link" itemprop="url">《极客时间教程 - 微服务架构核心 20 讲》笔记</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-06-26 18:09:46" itemprop="dateCreated datePublished" datetime="2022-06-26T18:09:46+08:00">2022-06-26</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-09-13 17:56:53" itemprop="dateModified" datetime="2025-09-13T17:56:53+08:00">2025-09-13</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/blog/categories/%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index"><span itemprop="name">笔记</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/blog/categories/%E7%AC%94%E8%AE%B0/%E8%AE%BE%E8%AE%A1/" itemprop="url" rel="index"><span itemprop="name">设计</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>2.8k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>3 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="《极客时间教程-微服务架构核心-20-讲》笔记"><a href="#《极客时间教程-微服务架构核心-20-讲》笔记" class="headerlink" title="《极客时间教程 - 微服务架构核心 20 讲》笔记"></a>《极客时间教程 - 微服务架构核心 20 讲》笔记</h1><h2 id="什么是微服务架构"><a href="#什么是微服务架构" class="headerlink" title="什么是微服务架构"></a>什么是微服务架构</h2><p>微服务是一种架构模式。</p>
<p>微服务的六个特点：</p>
<ul>
<li>一组小的服务</li>
<li>独立的进程</li>
<li>独立部署</li>
<li>轻量级通信</li>
<li>基于业务能力</li>
<li>无集中式管理——这里指的是可以用不同的技术栈，不同的存储</li>
</ul>
<p><strong>微服务定义</strong>：基于有界上下文的、松散耦合的、面向服务的架构。</p>
<h2 id="架构师如何权衡微服务的利弊"><a href="#架构师如何权衡微服务的利弊" class="headerlink" title="架构师如何权衡微服务的利弊"></a>架构师如何权衡微服务的利弊</h2><p>架构之道在于权衡利弊。</p>
<p>微服务架构的优点</p>
<ul>
<li>强模块化边界</li>
<li>可独立部署</li>
<li>技术多样性</li>
</ul>
<p>微服务架构的缺点</p>
<ul>
<li>分布式系统复杂性</li>
<li>最终一致性</li>
<li>运维复杂性</li>
<li>测试复杂性</li>
</ul>
<p>分布式系统带来的一个挑战就是取终一致性。</p>
<h2 id="康威法则和微服务给架构师怎样的启示"><a href="#康威法则和微服务给架构师怎样的启示" class="headerlink" title="康威法则和微服务给架构师怎样的启示"></a>康威法则和微服务给架构师怎样的启示</h2><p><strong>康威法则</strong>：设计系统的架构受制于产生这些设计的组织的沟通结构。</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20220627061813.png" alt="img"></p>
<p>康威的原文中提出的各定律</p>
<ul>
<li>第一定律 组织沟通方式会通过系统设计表达出来</li>
<li>第二定律 时间再多一件事情也不可能做的完美，但总有时间做完一件事情</li>
<li>第三定律 线型系统和线型组织架构间有潜在的异质同态特性</li>
<li>第四定律 大的系统组织总是比小系统更倾向于分解</li>
</ul>
<p>其中心思想实际就是<strong>分而治之</strong>。</p>
<h2 id="企业应该在什么时候开始考虑引入微服务"><a href="#企业应该在什么时候开始考虑引入微服务" class="headerlink" title="企业应该在什么时候开始考虑引入微服务"></a>企业应该在什么时候开始考虑引入微服务</h2><p>微服务的适用性:</p>
<p><img src="http://blog.xyecho.com/assets/time-geekbang-microservice-core20/micro_server_4.png" alt="img"></p>
<p>微服务重在服务治理，其对于平台基础设施有较高要求，所以企业刚开始应用微服务并不一定能提高生产力。简单来说：单体服务适用于小团队；微服务适用于大团队。</p>
<p>何时选择微服务，在于度的把控。当研发团队人员增长到一定程度，沟通成本不断增长时，就可以考虑微服务架构了。一个经验数据是，当团队达到 100 人规模时，就可以考虑使用微服务架构了。</p>
<p><strong>罗马不是一天建成的</strong>：架构是一个演进的过程，不应该一开始就将系统设计的过于复杂。</p>
<h2 id="什么样组织架构更适合微服务"><a href="#什么样组织架构更适合微服务" class="headerlink" title="什么样组织架构更适合微服务"></a>什么样组织架构更适合微服务</h2><p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20220627063405.png" alt="img"></p>
<ul>
<li><p>左边是比较传统的组织架构。产品从左到右流程走，可能出现的问题，反馈比较慢，对业务支持比较慢。沟通成本比较大。</p>
</li>
<li><p>右边是比较合适微服务的组织架构， 每一个团队（基于微服务的跨职能的团队），有开发，有产品，有测试，团队都支持自己的微服务。交付的产口是平台，对外提供 API 接口支持多样的业务。</p>
</li>
</ul>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20220627064331.png" alt="img"></p>
<p>DevOps 理念：谁开发的，谁构建，谁支持。</p>
<h2 id="如何理解阿里巴巴提出的微服务"><a href="#如何理解阿里巴巴提出的微服务" class="headerlink" title="如何理解阿里巴巴提出的微服务"></a>如何理解阿里巴巴提出的微服务</h2><p>中台战略和微服务的关系</p>
<p><img src="http://blog.xyecho.com/assets/time-geekbang-microservice-core20/micro_server_6.png" alt="img"></p>
<p>业务中台和技术中台统称为大中台，支撑业务前台。正所谓，万丈高楼平地起，中台基础越扎实，前台发展就越快。</p>
<p>PaaS 和 核心业务层是和微服务相关的。这一些基本都可以用微服务来实现。</p>
<ul>
<li><p>IaaS：Infrastructure-as-a-Service（基础设施即服务）</p>
</li>
<li><p>PaaS：Platform-as-a-Service（平台即服务）</p>
</li>
</ul>
<h2 id="如何给出一个清晰简洁的服务分层方式"><a href="#如何给出一个清晰简洁的服务分层方式" class="headerlink" title="如何给出一个清晰简洁的服务分层方式"></a>如何给出一个清晰简洁的服务分层方式</h2><p>大致的服务分层图：</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20220627064948.png" alt="img"></p>
<p>SOA（Service-Oriented Architecture）或微服务大致可分为</p>
<ul>
<li><strong>基础服务</strong>：也被称为：核心领域服务、中间层服务、公共服务</li>
<li><strong>聚合服务</strong>：对基础服务的聚合，以满足业务需求，提供给外部调用。</li>
</ul>
<h2 id="微服务总体技术架构体系是怎么设计的"><a href="#微服务总体技术架构体系是怎么设计的" class="headerlink" title="微服务总体技术架构体系是怎么设计的"></a>微服务总体技术架构体系是怎么设计的</h2><p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20220627065252.png" alt="img"></p>
<ul>
<li>接入层：接入外部流量，内部做负载均衡</li>
<li>网关层：反向路由，限流，安全，跨横切面的功能。</li>
<li>业务服务层：可分为：聚合服务，基础服务</li>
<li>支撑服务：各种公共性的后台服务</li>
<li>平台服务：可以是一些管理系统</li>
<li>基础设施：由运维团队运维</li>
</ul>
<p>其中，与微服务相关的主要有：网关层、业务服务层、支撑服务、平台服务</p>
<h2 id="微服务最经典的三种服务发现机制"><a href="#微服务最经典的三种服务发现机制" class="headerlink" title="微服务最经典的三种服务发现机制"></a>微服务最经典的三种服务发现机制</h2><p>消费者（客户端）如何发现生产者（服务端），有三种模式：</p>
<p>（1）通过 DNS 访问 LB（负载均衡），LB 分发</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20220627070054.png" alt="img"></p>
<p>（2）消费者内置 LB， 生产者将自身信息注册到注册中心上，并通过发送定时心跳来确认自身服务可用。消费者定期从注册中心拉取生产者信息</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20220627070105.png" alt="img"></p>
<p>（3）结全前面两种方式， 在 Consumer 的主机上也布置一个 LB。 LB 会定期同步注册中心的信息。 运维成本比较高一点。</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20220627070117.png" alt="img"></p>
<h2 id="微服务-API-服务网关（一）原理"><a href="#微服务-API-服务网关（一）原理" class="headerlink" title="微服务 API 服务网关（一）原理"></a>微服务 API 服务网关（一）原理</h2><p>网关用于屏蔽服务内部的逻辑，希望外部访问看到是统一的接口。</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20220628070638.png" alt="img"></p>
<p>网关主要的功能：</p>
<ul>
<li><strong>反向代理</strong>：将外部的请求换成内部调用。</li>
<li><strong>安全认证</strong>：防刷、防爬虫。</li>
<li><strong>限流熔断</strong>：处理可能会突发流量。</li>
<li><strong>日志监控</strong>：进行访问访问审计，监控流量。</li>
</ul>
<p>一般不要把过多的业务逻辑写在网关当中。</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20220628070651.png" alt="img"></p>
<h2 id="服务-API-服务网关（二）开源网关-Zuul"><a href="#服务-API-服务网关（二）开源网关-Zuul" class="headerlink" title="服务 API 服务网关（二）开源网关 Zuul"></a>服务 API 服务网关（二）开源网关 Zuul</h2><p>Servlet 和 Filter Runner 过滤器：前置路由过滤器， 路由过滤器，后置路由过滤器</p>
<p>过滤器开发，可以通过脚本开发。开发完后上传到过滤器目录中， 被扫描后加到 Filter Runner 中。</p>
<p>各个 Filter 共享数据通过 Request Context 来实现。</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20220628070702.png" alt="img"></p>
<p>过滤链的流程：</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20220628070712.png" alt="img"></p>
<h2 id="跟-Netflix-学习微服务路由发现体系"><a href="#跟-Netflix-学习微服务路由发现体系" class="headerlink" title="跟 Netflix 学习微服务路由发现体系"></a>跟 Netflix 学习微服务路由发现体系</h2><p>netflix 有两个比较重要的支撑服务</p>
<ul>
<li>服务注册中心 Eureka</li>
<li>网关 zuul</li>
</ul>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20220628070723.png" alt="img"></p>
<h2 id="集中式配置中心的作用和原理是什么"><a href="#集中式配置中心的作用和原理是什么" class="headerlink" title="集中式配置中心的作用和原理是什么"></a>集中式配置中心的作用和原理是什么</h2><p>为什么要引入配置中心呢？</p>
<p>配置文件中的属性不方便管理，无法动态更新，无法审计。配置中心可以解决这些问题。</p>
<p>什么可做配置呢？</p>
<ul>
<li>业务开关</li>
<li>调用&#x2F;响应超时</li>
<li>限流</li>
<li>连接字符串</li>
<li>动态参数</li>
</ul>
<p>Svr 更新配置有两种方式：推和拉。</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20220628070748.png" alt="img"></p>
<p>携程的 Apollo 配置中心:</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20220628070805.png" alt="img"></p>
<p>github : <a target="_blank" rel="noopener" href="https://github.com/ctripcorp/apollo">https://github.com/ctripcorp/apollo</a></p>
<h2 id="微服务通讯方式-RPC-vs-REST"><a href="#微服务通讯方式-RPC-vs-REST" class="headerlink" title="微服务通讯方式 RPC vs REST"></a>微服务通讯方式 RPC vs REST</h2><p>RPC：远程过程调用</p>
<p>REST：Restful</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20220628070816.png" alt="img"></p>
<h2 id="微服务框架需要考虑哪些治理环节"><a href="#微服务框架需要考虑哪些治理环节" class="headerlink" title="微服务框架需要考虑哪些治理环节"></a>微服务框架需要考虑哪些治理环节</h2><p>一个公司的微服务多了，就要需要考虑服务治理：</p>
<ul>
<li><p>软负载：蓝绿发布，灰度发布</p>
</li>
<li><p>指标（Metrics）：服务的调用量，耗时监控</p>
</li>
<li><p>调用链埋点：方便快速定位问题</p>
</li>
</ul>
<p>契约生成代码： 定义结构体可自动生成 json 格式， vscode 有插件。</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20220628070827.png" alt="img"></p>
<p>阿里巴巴微服务治理生态：Dubbo <a target="_blank" rel="noopener" href="http://dubbo.apache.org/en-us/">http://dubbo.apache.org/en-us/</a></p>
<h2 id="微服务监控系统分层和监控架构"><a href="#微服务监控系统分层和监控架构" class="headerlink" title="微服务监控系统分层和监控架构"></a>微服务监控系统分层和监控架构</h2><p>五个层次的监控：</p>
<ul>
<li>基础层施监控</li>
<li>系统层监控</li>
<li>应用层监控<ul>
<li>url</li>
<li>sevice</li>
<li>mysql</li>
<li>cache 可用率</li>
<li>性能</li>
<li>qps</li>
</ul>
</li>
<li>业务层监控<ul>
<li>核心指标监控</li>
<li>登录注册</li>
</ul>
</li>
<li>端用户体验监控</li>
</ul>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20220628070913.png" alt="img"></p>
<ul>
<li>日志监控：Elasticsearch</li>
<li>metrics 监控</li>
<li>健康检查</li>
<li>调用链监控</li>
<li>告警系统</li>
</ul>
<p>比较典型的监控架构，大部分公司的流程</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20220628070950.png" alt="img"></p>
<p>数据量比较大一般用 Kafka 作为缓冲队列。</p>
<p>Nagios 健康检测工具。</p>
<p>ELK：ELK 是 Elasticsearch、Logstash、Kibana 三大开源框架首字母大写简称。</p>
<h2 id="微服务的调用链监控该如何选型"><a href="#微服务的调用链监控该如何选型" class="headerlink" title="微服务的调用链监控该如何选型"></a>微服务的调用链监控该如何选型</h2><p>调用链的监控　谷歌 2010 年提出来的。</p>
<p>通过 Span 来跟踪， RootSpan ChildSpan 跨进程时 会有 Trace di + parant span id</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20220628071003.png" alt="img"></p>
<p>三个主流调用链监控系统的比较：</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20220628071013.png" alt="img"></p>
<h2 id="微服务的容错限流是如何工作的"><a href="#微服务的容错限流是如何工作的" class="headerlink" title="微服务的容错限流是如何工作的"></a>微服务的容错限流是如何工作的</h2><p>Netfiix Hystrix 具有熔断、隔离、限流、降级的功能 。</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20220628071025.png" alt="img"></p>
<p>说明：</p>
<ul>
<li>3 Cirult OPen 判断是否可以熔断， 是则执行 getFAllBack() 降级处理函数</li>
<li>5 run() 超时 也执行降级处理函数。</li>
<li>6 不成功也 执行处理函数 。</li>
<li>Calculate Cirult Health 就是在正常执行成功后计算是否需要熔断。</li>
</ul>
<h2 id="Docker-容器部署技术-持续交付流水线"><a href="#Docker-容器部署技术-持续交付流水线" class="headerlink" title="Docker 容器部署技术 &amp; 持续交付流水线"></a>Docker 容器部署技术 &amp; 持续交付流水线</h2><p>docker 容器治理就是解决：环境不一致的问题。把依赖的所有包都打在镜像中。</p>
<p>统一、标准化的交付流水线。</p>
<p>UAT 环境： User Acceptance Test （用户验收测试）</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20220628071059.png" alt="img"></p>
<p>发布模式： 蓝绿布置，灰度发布（金丝雀发布）。</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20220628071111.png" alt="img"></p>
<h2 id="容器集群调度和基于容器的发布体系"><a href="#容器集群调度和基于容器的发布体系" class="headerlink" title="容器集群调度和基于容器的发布体系"></a>容器集群调度和基于容器的发布体系</h2><p>资源调度框架 Mesos 架构</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20220628071127.png" alt="img"></p>
<p>基于容器的云发布体系</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20220628071152.png" alt="img"></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://dunwu.github.io/blog/pages/4bd36ecb/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/blog/uploads/avatar.gif">
      <meta itemprop="name" content="钝悟 ◾ Dunwu">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Dunwu Blog">
      <meta itemprop="description" content="钝悟的个人博客">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | Dunwu Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/blog/pages/4bd36ecb/" class="post-title-link" itemprop="url">《RPC 实战与核心原理》笔记</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-06-19 09:48:17" itemprop="dateCreated datePublished" datetime="2022-06-19T09:48:17+08:00">2022-06-19</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-09-13 17:56:53" itemprop="dateModified" datetime="2025-09-13T17:56:53+08:00">2025-09-13</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/blog/categories/%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index"><span itemprop="name">笔记</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/blog/categories/%E7%AC%94%E8%AE%B0/%E5%88%86%E5%B8%83%E5%BC%8F/" itemprop="url" rel="index"><span itemprop="name">分布式</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/blog/categories/%E7%AC%94%E8%AE%B0/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F%E9%80%9A%E4%BF%A1/" itemprop="url" rel="index"><span itemprop="name">分布式通信</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>15k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>14 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="《RPC-实战与核心原理》笔记"><a href="#《RPC-实战与核心原理》笔记" class="headerlink" title="《RPC 实战与核心原理》笔记"></a>《RPC 实战与核心原理》笔记</h1><h2 id="别老想着怎么用好-RPC-框架，你得多花时间琢磨原理"><a href="#别老想着怎么用好-RPC-框架，你得多花时间琢磨原理" class="headerlink" title="别老想着怎么用好 RPC 框架，你得多花时间琢磨原理"></a>别老想着怎么用好 RPC 框架，你得多花时间琢磨原理</h2><p>为什么要学习 RPC</p>
<p>RPC 不仅是微服务的架构基础，实际上，只要涉及网络通信，就可能用到 RPC。</p>
<ul>
<li><p>例 1：大型分布式应用系统可能会依赖消息队列、分布式缓存、分布式数据库以及统一配置中心等，应用程序与依赖的这些中间件之间都可以通过 RPC 进行通信。比如 etcd，它作为一个统一的配置服务，客户端就是通过 gRPC 框架与服务端进行通信的。</p>
</li>
<li><p>例 2：我们经常会谈到的容器编排引擎 Kubernetes，它本身就是分布式的，Kubernetes 的 kube-apiserver 与整个分布式集群中的每个组件间的通讯，都是通过 gRPC 框架进行的。</p>
</li>
</ul>
<p><strong>RPC 是解决分布式系统通信问题的一大利器</strong>。</p>
<h2 id="核心原理：能否画张图解释下-RPC-的通信流程？"><a href="#核心原理：能否画张图解释下-RPC-的通信流程？" class="headerlink" title="核心原理：能否画张图解释下 RPC 的通信流程？"></a>核心原理：能否画张图解释下 RPC 的通信流程？</h2><h3 id="什么是-RPC？"><a href="#什么是-RPC？" class="headerlink" title="什么是 RPC？"></a>什么是 RPC？</h3><p>RPC 的全称是 Remote Procedure Call，即<strong>远程过程调用</strong>。</p>
<p>RPC 的作用体现在两个方面：</p>
<ul>
<li>屏蔽远程调用跟本地调用的差异，让用户像调用本地一样去调用远程方法。</li>
<li>隐藏底层网络通信的复杂性，让用户更专注于业务逻辑。</li>
</ul>
<h3 id="RPC-通信流程"><a href="#RPC-通信流程" class="headerlink" title="RPC 通信流程"></a>RPC 通信流程</h3><p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20220619100051.png"></p>
<p>RPC 是一个远程调用，因此必然需要通过网络传输数据，且 RPC 常用于业务系统之间的数据交互，需要保证其可靠性，所以 RPC 一般默认采用 <strong>TCP 协议</strong>来传输。</p>
<p>网络传输数据是二进制数据，因此请求方需要将请求参数转为二进制数据，即<strong>序列化</strong>。</p>
<p>响应方接受到请求，要将二进制数据转换为请求参数，需要<strong>反序列化</strong>。</p>
<p>请求方和响应方识别彼此的信息，需要约定好彼此数据的格式，即<strong>协议</strong>。<strong>大多数的协议会分成两部分，分别是数据头和消息体</strong>。数据头一般用于身份识别，包括协议标识、数据大小、请求类型、序列化类型等信息；消息体主要是请求的业务参数信息和扩展属性等。</p>
<p>为了屏蔽底层通信细节，使用户聚焦自身业务，因此 RPC 框架一般引入了动态代理，通过依赖注入等技术，拦截方法调用，完成远程调用的通信逻辑。</p>
<h3 id="RPC-在架构中的位置"><a href="#RPC-在架构中的位置" class="headerlink" title="RPC 在架构中的位置"></a>RPC 在架构中的位置</h3><p>RPC 框架能够帮助我们解决系统拆分后的通信问题，并且能让我们像调用本地一样去调用<br>远程方法。</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20220619101023.png"></p>
<h2 id="协议：怎么设计可扩展且向后兼容的协议？"><a href="#协议：怎么设计可扩展且向后兼容的协议？" class="headerlink" title="协议：怎么设计可扩展且向后兼容的协议？"></a>协议：怎么设计可扩展且向后兼容的协议？</h2><h3 id="协议的作用"><a href="#协议的作用" class="headerlink" title="协议的作用"></a>协议的作用</h3><p>在传输过程中，RPC 并不会把请求参数的所有二进制数据整体一下子发送到对端机器上，中间可能会拆分成好几个数据包，也可能会合并其他请求的数据包（合并的前提是同一个 TCP 连接上的数据），至于怎么拆分合并，这其中的细节会涉及到系统参数配置和 TCP 窗口大小。对于服务提供方应用来说，他会从 TCP 通道里面收到很多的二进制数据，那这时候怎么识别出哪些二进制是第一个请求的呢？</p>
<p>个人理解：为了避免语义不一致的事情发生，需要为数据报文设定边界，请求方和接收方都按照设定的边界去读写数据。这类似于文章使用标点符号去断句。</p>
<h3 id="为何需要设计-RPC-协议"><a href="#为何需要设计-RPC-协议" class="headerlink" title="为何需要设计 RPC 协议"></a>为何需要设计 RPC 协议</h3><p>RPC 协议对性能要求高，而公有网络协议往往数据报文较大，内容不够紧凑。</p>
<h3 id="如何设计-RPC-协议？"><a href="#如何设计-RPC-协议？" class="headerlink" title="如何设计 RPC 协议？"></a>如何设计 RPC 协议？</h3><p>首先，必须先明确消息的边界，即确定消息的长度。因此，至少要分为：消息长度+消息内容两部分。</p>
<p>接下来，我们会发现，在使用过程中，仅消息长度，不足以明确通信中的很多细节：如序列化方式是怎样的？是否消息压缩？压缩格式是怎样的？如果协议发生变化，需要明确协议版本等等。</p>
<p>综上，一个 RPC 协议大概会由下图中的这些参数组成：</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20220619102052.png"></p>
<h3 id="可扩展的协议"><a href="#可扩展的协议" class="headerlink" title="可扩展的协议"></a>可扩展的协议</h3><p>前面所述的协议属于定长协议头，那也就是说往后就不能再往协议头里加新参数了，如果加参<br>数就会导致线上兼容问题。</p>
<p>为了保证能平滑地升级改造前后的协议，我们有必要设计一种支持可扩展的协议。其关键在于让协议头支持可扩展，扩展后协议头的长度就不能定长了。那要实现读取不定长的协议头里面的内容，在这之前肯定需要一个固定的地方读取长度，所以我们需要一个固定的写入协议头的长度。整体协议就变成了三部分内容：固定部分、协议头内容、协议体内容。</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20220619102833.png"></p>
<h2 id="序列化：对象怎么在网络中传输？"><a href="#序列化：对象怎么在网络中传输？" class="headerlink" title="序列化：对象怎么在网络中传输？"></a>序列化：对象怎么在网络中传输？</h2><h3 id="为什么需要序列化"><a href="#为什么需要序列化" class="headerlink" title="为什么需要序列化"></a>为什么需要序列化</h3><p>调用方和被调用方的数据原本是对象，无法在网络中传输，必须转换为二进制数据。因此，需要一种方式来实现此过程：将对象转为二进制数据，即<strong>序列化</strong>；同时，需要根据二进制数据逆向转化为对象，即<strong>反序列化</strong>。</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20220619101617.png"></p>
<p>从 RPC 的实现角度来看，序列化的作用如下图所示：</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20220619104420.png"></p>
<p>常用序列化方式</p>
<ul>
<li>JDK 序列化：<code>ObjectInputStream</code> 和 <code>ObjectOutputStream</code></li>
<li>JSON</li>
<li>二进制<ul>
<li>Hessian</li>
<li>Protobuf</li>
<li>Thirft</li>
</ul>
</li>
</ul>
<h3 id="RPC-协议选型"><a href="#RPC-协议选型" class="headerlink" title="RPC 协议选型"></a>RPC 协议选型</h3><p><strong>优先级依次从高到低：安全性、通用性、兼容性、性能、效率、空间开销</strong>。</p>
<p>在序列化的选择上，与序列化协议的效率、性能、序列化协议后的体积相比，其通用性和兼容性的优先级会更高，因为他是会直接关系到服务调用的稳定性和可用率的，对于服务的性能来说，服务的可靠性显然更加重要。我们更加看重这种序列化协议在版本升级后的兼容性是否很好，是否支持更多的对象类型，是否是跨平台、跨语言的，是否有很多人已经用过并且踩过了很多的坑，其次我们才会去考虑性能、效率和空间开销。</p>
<h3 id="使用-RPC-需要注意哪些问题"><a href="#使用-RPC-需要注意哪些问题" class="headerlink" title="使用 RPC 需要注意哪些问题"></a>使用 RPC 需要注意哪些问题</h3><ul>
<li><strong>对象构造得过于复杂</strong> - 对象要尽量简单，没有太多的依赖关系，属性不要太多，尽量高内聚；</li>
<li><strong>对象过于复杂、庞大</strong> - 入参对象与返回值对象体积不要太大，更不要传太大的集合；</li>
<li><strong>使用序列化框架不支持的类作为入参类</strong> - 尽量使用简单的、常用的、开发语言原生的对象，尤其是集合类；</li>
<li><strong>对象有复杂的继承关系</strong> - 对象不要有复杂的继承关系，最好不要有父子类的情况。</li>
</ul>
<h2 id="网络通信：RPC-框架在网络通信上更倾向于哪种网络-IO-模型？"><a href="#网络通信：RPC-框架在网络通信上更倾向于哪种网络-IO-模型？" class="headerlink" title="网络通信：RPC 框架在网络通信上更倾向于哪种网络 IO 模型？"></a>网络通信：RPC 框架在网络通信上更倾向于哪种网络 IO 模型？</h2><h3 id="常见的网络-IO-模型"><a href="#常见的网络-IO-模型" class="headerlink" title="常见的网络 IO 模型"></a>常见的网络 IO 模型</h3><p>常见的网络 IO 模型分为四种：同步阻塞 IO（BIO）、同步非阻塞 IO（NIO）、IO 多路复用和异步非阻塞 IO（AIO）。在这四种 IO 模型中，只有 AIO 为异步 IO，其他都是同步 IO。</p>
<p>IO 多路复用（Reactor 模式）在高并发场景下使用最为广泛，很多知名软件都应用了这一技术，如：Netty、Redis、Nginx 等。</p>
<p>IO 多路复用分为 select，poll 和 epoll。</p>
<p>什么是 IO 多路复用？字面上的理解，多路就是指多个通道，也就是多个网络连接的 IO，而复用就是指多个通道复用在一个复用器上。</p>
<h3 id="零拷贝"><a href="#零拷贝" class="headerlink" title="零拷贝"></a>零拷贝</h3><p>系统内核处理 IO 操作分为两个阶段——等待数据和拷贝数据。等待数据，就是系统内核在等待网卡接收到数据后，把数据写到内核中；而拷贝数据，就是系统内核在获取到数据后，将数据拷贝到用户进程的空间中。</p>
<p>网络 IO 读写流程</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20220619174154.png"></p>
<p>应用进程的每一次写操作，都会把数据写到用户空间的缓冲区中，再由 CPU 将数据拷贝到系统内核的缓冲区中，之后再由 DMA 将这份数据拷贝到网卡中，最后由网卡发送出去。这里我们可以看到，一次写操作数据要拷贝两次才能通过网卡发送出去，而用户进程的读操作则是将整个流程反过来，数据同样会拷贝两次才能让应用程序读取到数据。</p>
<p>应用进程的一次完整的读写操作，都需要在用户空间与内核空间中来回拷贝，并且每一次拷贝，都需要 CPU 进行一次上下文切换（由用户进程切换到系统内核，或由系统内核切换到用户进程），这样很浪费 CPU 和性能。</p>
<p>所谓的零拷贝，就是取消用户空间与内核空间之间的数据拷贝操作，应用进程每一次的读写操作，可以通过一种方式，直接将数据写入内核或从内核中读取数据，再通过 DMA 将内核中的数据拷贝到网卡，或将网卡中的数据 copy 到内核。</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20220619174335.png"></p>
<p>Netty 的零拷贝偏向于用户空间中对数据操作的优化，这对处理 TCP 传输中的拆包粘包问题有着重要的意义，对应用程序处理请求数据与返回数据也有重要的意义。</p>
<p>Netty 框架中很多内部的 ChannelHandler 实现类，都是通过 CompositeByteBuf、slice、wrap 操作来处理 TCP 传输中的拆包与粘包问题的。</p>
<p>Netty 的 ByteBuffer 可以采用 Direct Buffers，使用堆外直接内存进行 Socketd 的读写<br>操作，最终的效果与我刚才讲解的虚拟内存所实现的效果是一样的。</p>
<p>Netty 还提供 FileRegion 中包装 NIO 的 FileChannel.transferTo() 方法实现了零拷<br>贝，这与 Linux 中的 sendfile 方式在原理上也是一样的。</p>
<h2 id="动态代理：面向接口编程，屏蔽-RPC-处理流程"><a href="#动态代理：面向接口编程，屏蔽-RPC-处理流程" class="headerlink" title="动态代理：面向接口编程，屏蔽 RPC 处理流程"></a>动态代理：面向接口编程，屏蔽 RPC 处理流程</h2><p>动态代理可以帮用户屏蔽远程调用的细节，实现像调用本地一样地调用远程的体验。</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20220619204255.png"></p>
<p>JDK 支持的动态代理方式是通过实现 InvocationHandler 接口。这种方式有一定的局限性——它要求被代理的类只能是接口。原因是因为生成的代理类会继承 Proxy 类，但 Java 是不支持多重继承的。此外，它还有性能问题。它生成后的代理类是使用反射来完成方法调用的，而这种方式相对直接用编码调用来说，性能会降低。</p>
<p>除 JDK 以外，还有其他第三方框架可以实现动态代理，如像 Javassist、Byte Buddy。</p>
<p>Javassist 的是通过控制底层字节码来实现动态代理，不需要反射完成调用，所以性能肯定比 JDK 的动态代理方式性能要好。</p>
<p>Byte Buddy 则属于后起之秀，在很多优秀的项目中，像 Spring、Jackson 都用到了 Byte Buddy 来完成底层代理。相比 Javassist，Byte Buddy 提供了更容易操作的 API，编写的代码可读性更高。更重要的是，生成的代理类执行速度比 Javassist 更快。</p>
<h2 id="RPC-实战：剖析-gRPC-源码，动手实现一个完整的-RPC"><a href="#RPC-实战：剖析-gRPC-源码，动手实现一个完整的-RPC" class="headerlink" title="RPC 实战：剖析 gRPC 源码，动手实现一个完整的 RPC"></a>RPC 实战：剖析 gRPC 源码，动手实现一个完整的 RPC</h2><p>略</p>
<h2 id="架构设计：设计一个灵活的-RPC-框架"><a href="#架构设计：设计一个灵活的-RPC-框架" class="headerlink" title="架构设计：设计一个灵活的 RPC 框架"></a>架构设计：设计一个灵活的 RPC 框架</h2><h3 id="RPC-架构"><a href="#RPC-架构" class="headerlink" title="RPC 架构"></a>RPC 架构</h3><p><strong>其实 RPC 就是把拦截到的方法参数，转成可以在网络中传输的二进制，并保证在服务提供方能正确地还原出语义，最终实现像调用本地一样地调用远程的目的</strong>。</p>
<p>RPC 本质上就是一个远程调用，必然需要通过网络来传输数据，为了屏蔽网络传输的复杂性，需要封装一个单独的<strong>数据传输模块</strong>用来收发二进制数据。</p>
<p>用户请求的时候是基于方法调用，方法出入参数都是对象数据，对象是肯定没法直接在网络中传输的，我们需要提前把它转成可传输的二进制，这就是我们说的序列化过程。但只是把方法调用参数的二进制数据传输到服务提供方是不够的，我们需要在方法调用参数的二进制数据后面增加“断句”符号来分隔出不同的请求，在两个“断句”符号中间放的内容就是我们请求的二进制数据，这个过程我们叫做协议封装。可以把这两个处理过程放在同一个模块，统称为<strong>协议模块</strong>。除此之外，我们还可以在协议模块中加入压缩功能，这是因为压缩过程也是对传输的二进制数据进行操作。</p>
<p>RPC 还需要为调用方找到所有的服务提供方，并需要在 RPC 里面维护好接口跟服务提供者地址的关系，这样调用方在发起请求的时候才能快速地找到对应的接收地址，这个过程即为“服务发现”。</p>
<p>但服务发现只是解决了接口和服务提供方地址映射关系的查找问题。但是，对于 RPC 来说，每次发送请求的时候都是需要用 TCP 连接的，相对服务提供方 IP 地址，TCP 连接状态是瞬息万变的，所以我们的 RPC 框架里面要有连接管理器去维护 TCP 连接的状态。</p>
<p>有了集群之后，提供方可能就需要管理好这些服务了，那我们的 RPC 就需要内置一些服务治理的功能，比如服务提供方权重的设置、调用授权等一些常规治理手段。而服务调用方需要额外做哪些事情呢？每次调用前，我们都需要根据服务提供方设置的规则，从集群中选择可用的连接用于发送请求。</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20220620112739.png"></p>
<h3 id="RPC-可扩展架构"><a href="#RPC-可扩展架构" class="headerlink" title="RPC 可扩展架构"></a>RPC 可扩展架构</h3><p>在 RPC 框架中，如何支持插件化架构呢？</p>
<p>可以使用 SPI 技术来实现。注意：由于 JDK SPI 性能不高，并且不支持自动注入，所以，一般会选择其他的 SPI 实现。</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20220620113147.png"></p>
<p>有了 SPI 支持插件式加载后，RPC 框架就变成了一个微内核架构。</p>
<h2 id="服务发现：到底是要-CP-还是-AP？"><a href="#服务发现：到底是要-CP-还是-AP？" class="headerlink" title="服务发现：到底是要 CP 还是 AP？"></a>服务发现：到底是要 CP 还是 AP？</h2><p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20220620144009.png"></p>
<p>RPC 框架必须要有服务注册和发现机制，这样，集群中的节点才能知道通信方的请求地址。</p>
<ul>
<li><strong>服务注册</strong>：在服务提供方启动的时候，将对外暴露的接口注册到注册中心之中，注册中心将这个服务节点的 IP 和接口保存下来。</li>
<li><strong>服务订阅</strong>：在服务调用方启动的时候，去注册中心查找并订阅服务提供方的 IP，然后缓存到本地，并用于后续的远程调用。</li>
</ul>
<h3 id="基于-ZooKeeper-的服务发现"><a href="#基于-ZooKeeper-的服务发现" class="headerlink" title="基于 ZooKeeper 的服务发现"></a>基于 ZooKeeper 的服务发现</h3><p>使用 ZooKeeper 作为服务注册中心，是 Java 分布式系统的经典方案。</p>
<p>搭建一个 ZooKeeper 集群作为注册中心集群，服务注册的时候只需要服务节点向 ZooKeeper 节点写入注册信息即可，利用 ZooKeeper 的 Watcher 机制完成服务订阅与服务下发功能</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20200610180056.png" alt="img"></p>
<p>通常我们可以使用 ZooKeeper、etcd 或者分布式缓存（如 Hazelcast）来解决事件通知问题，但当集群达到一定规模之后，依赖的 ZooKeeper 集群、etcd 集群可能就不稳定了，无法满足我们的需求。</p>
<p>在超大规模的服务集群下，注册中心所面临的挑战就是超大批量服务节点同时上下线，注册中心集群接受到大量服务变更请求，集群间各节点间需要同步大量服务节点数据，最终导致如下问题：</p>
<ul>
<li>注册中心负载过高；</li>
<li>各节点数据不一致；</li>
<li>服务下发不及时或下发错误的服务节点列表。</li>
</ul>
<p>RPC 框架依赖的注册中心的服务数据的一致性其实并不需要满足 CP，只要满足 AP 即可。</p>
<h3 id="基于消息总线的最终一致性的注册中心"><a href="#基于消息总线的最终一致性的注册中心" class="headerlink" title="基于消息总线的最终一致性的注册中心"></a>基于消息总线的最终一致性的注册中心</h3><p>ZooKeeper 的一大特点就是强一致性，ZooKeeper 集群的每个节点的数据每次发生更新操作，都会通知其它 ZooKeeper 节点同时执行更新。它要求保证每个节点的数据能够实时的完全一致，这也就直接导致了 ZooKeeper 集群性能上的下降。</p>
<p>而 RPC 框架的服务发现，在服务节点刚上线时，服务调用方是可以容忍在一段时间之后（比如几秒钟之后）发现这个新上线的节点的。毕竟服务节点刚上线之后的几秒内，甚至更长的一段时间内没有接收到请求流量，对整个服务集群是没有什么影响的，所以我们可以牺牲掉 CP（强制一致性），而选择 AP（最终一致），来换取整个注册中心集群的性能和稳定性。</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20200717162006.png" alt="img"></p>
<h2 id="健康检测：这个节点都挂了，为啥还要疯狂发请求？"><a href="#健康检测：这个节点都挂了，为啥还要疯狂发请求？" class="headerlink" title="健康检测：这个节点都挂了，为啥还要疯狂发请求？"></a>健康检测：这个节点都挂了，为啥还要疯狂发请求？</h2><p>健康检测，它能帮助我们从连接列表里面过滤掉一些存在问题的节点，避免在发请求的时候选择出有问题的节点而影响业务。</p>
<p>服务方状态一般有三种情况：</p>
<ol>
<li><strong>健康状态</strong> - 建立连接成功，并且心跳探活也一直成功；</li>
<li><strong>亚健康状态</strong> - 建立连接成功，但是心跳请求连续失败；</li>
<li><strong>死亡状态</strong> - 建立连接失败。</li>
</ol>
<p>设计健康检测方案的时候，不能简单地从 TCP 连接是否健康、心跳是否正常等简单维度考虑，因为健康检测的目的就是要保证“业务无损”，因此，可以加入业务请求可用率因素，这样能最大化地提升 RPC 接口可用率。</p>
<p>正常情况下，我们大概 30S 会发一次心跳请求，这个间隔一般不会太短，如果太短会给服务节点造成很大的压力。但是如果太长的话，又不能及时摘除有问题的节点。</p>
<h2 id="路由策略：怎么让请求按照设定的规则发到不同的节点上？"><a href="#路由策略：怎么让请求按照设定的规则发到不同的节点上？" class="headerlink" title="路由策略：怎么让请求按照设定的规则发到不同的节点上？"></a>路由策略：怎么让请求按照设定的规则发到不同的节点上？</h2><p>服务路由是指通过一定的规则从集群中选择合适的节点。</p>
<h3 id="为什么需要路由策略"><a href="#为什么需要路由策略" class="headerlink" title="为什么需要路由策略"></a>为什么需要路由策略</h3><p>服务路由通常用于以下场景，目的在于实现流量隔离：</p>
<ul>
<li><p>分组调用</p>
</li>
<li><p>蓝绿发布</p>
</li>
<li><p>灰度发布</p>
</li>
<li><p>流量切换</p>
</li>
<li><p>线下测试联调</p>
</li>
<li><p>读写分离</p>
</li>
</ul>
<h3 id="路由规则"><a href="#路由规则" class="headerlink" title="路由规则"></a>路由规则</h3><ul>
<li>条件路由：基于条件表达式的路由规则</li>
<li>脚本路由：基于脚本语言的路由规则</li>
<li>标签路由：将服务分组的路由规则</li>
</ul>
<h2 id="负载均衡：节点负载差距这么大，为什么收到的流量还一样？"><a href="#负载均衡：节点负载差距这么大，为什么收到的流量还一样？" class="headerlink" title="负载均衡：节点负载差距这么大，为什么收到的流量还一样？"></a>负载均衡：节点负载差距这么大，为什么收到的流量还一样？</h2><h3 id="负载均衡算法"><a href="#负载均衡算法" class="headerlink" title="负载均衡算法"></a>负载均衡算法</h3><ul>
<li>随机算法<ul>
<li>加权随机算法</li>
</ul>
</li>
<li>轮询算法<ul>
<li>加权轮询算法</li>
</ul>
</li>
<li>最小活跃数算法<ul>
<li>加权最小活跃数算法</li>
</ul>
</li>
<li>哈希算法</li>
<li>一致性哈希算法</li>
</ul>
<h3 id="RPC-框架中的负载均衡"><a href="#RPC-框架中的负载均衡" class="headerlink" title="RPC 框架中的负载均衡"></a>RPC 框架中的负载均衡</h3><p>RPC 负载均衡所采用的策略与传统的 Web 服务负载均衡所采用策略的不同之处：</p>
<ol>
<li>搭建负载均衡设备或 TCP&#x2F;IP 四层代理，需要额外成本；</li>
<li>请求流量都经过负载均衡设备，多经过一次网络传输，会额外浪费一些性能；</li>
<li>负载均衡添加节点和摘除节点，一般都要手动添加，当大批量扩容和下线时，会有大量的人工操作，“服务发现”在操作上是个问题；</li>
<li>我们在服务治理的时候，针对不同接口服务、服务的不同分组，我们的负载均衡策略是需要可配的，如果大家都经过这一个负载均衡设备，就不容易根据不同的场景来配置不同的负载均衡策略了。</li>
</ol>
<p>RPC 的负载均衡完全由 RPC 框架自身实现，RPC 的服务调用者会与“注册中心”下发的所有服务节点建立长连接，在每次发起 RPC 调用时，服务调用者都会通过配置的负载均衡插件，自主选择一个服务节点，发起 RPC 调用请求。</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20220622175324.png"></p>
<h3 id="如何设计自适应的负载均衡"><a href="#如何设计自适应的负载均衡" class="headerlink" title="如何设计自适应的负载均衡"></a>如何设计自适应的负载均衡</h3><p>那服务调用者节点又该如何判定一个服务节点的处理能力呢？</p>
<p>可以采用一种打分制的策略，服务调用者收集与之建立长连接的每个服务节点的指标数据，如服务节点的负载指标、CPU 核数、内存大小、请求处理的耗时指标（如请求平均耗时、TP99、TP999）、服务节点的状态指标（如正常、亚健康）。通过这些指标，计算出一个分数，比如总分 10 分，如果 CPU 负载达到 70%，就减它 3 分，当然了，减 3 分只是个类比，需要减多少分是需要一个计算策略的。</p>
<p>然后，根据不同指标的重要程度设置权重，然后累加，计算公式：</p>
<figure class="highlight erlang"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">健康值 = 指标值<span class="number">1</span> * 权重<span class="number">1</span> + 指标值<span class="number">2</span> * 权重<span class="number">2</span> + ...</span><br></pre></td></tr></table></figure>

<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20220622180243.png"></p>
<p>服务调用者给每个服务节点都打完分之后，会发送请求，那这时候我们又该如何根据分数去控制给每个服务节点发送多少流量呢？</p>
<p>关键步骤</p>
<ol>
<li>添加服务指标收集器，并将其作为插件，默认有运行时状态指标收集器、请求耗时指标收集器。</li>
<li>运行时状态指标收集器收集服务节点 CPU 核数、CPU 负载以及内存等指标，在服务调用者与服务提供者的心跳数据中获取。</li>
<li>请求耗时指标收集器收集请求耗时数据，如平均耗时、TP99、TP999 等。</li>
<li>可以配置开启哪些指标收集器，并设置这些参考指标的指标权重，再根据指标数据和指标权重来综合打分。</li>
<li>通过服务节点的综合打分与节点的权重，最终计算出节点的最终权重，之后服务调用者会根据随机权重的策略，来选择服务节点。</li>
</ol>
<h2 id="异常重试：在约定时间内安全可靠地重试"><a href="#异常重试：在约定时间内安全可靠地重试" class="headerlink" title="异常重试：在约定时间内安全可靠地重试"></a>异常重试：在约定时间内安全可靠地重试</h2><h3 id="异常重试"><a href="#异常重试" class="headerlink" title="异常重试"></a>异常重试</h3><p>就是当调用端发起的请求失败时，RPC 框架自身可以进行重试，再重新发送请求，用户可以自行设置是否开启重试以及重试的次数。</p>
<p>当然，不是所有的异常都要触发重试，只有符合重试条件的异常才能触发重试，比如网络超时异常、网络连接异常等等（这个需要 RPC 去判定）。</p>
<blockquote>
<p>注意：有时网络可能发生抖动，导致请求超时，这时如果 RPC 触发超时重试，会触发业务逻辑重复执行，如果接口没有幂等性设计，就可能引发问题。如：重发写表。</p>
</blockquote>
<h3 id="重试超时时间"><a href="#重试超时时间" class="headerlink" title="重试超时时间"></a>重试超时时间</h3><p>连续的异常重试可能会出现一种不可靠的情况，那就是连续的异常重试并且每次处理的请求时间比较长，最终会导致请求处理的时间过长，超出用户设置的超时时间。</p>
<p>解决这个问题最直接的方式就是，在每次重试后都重置一下请求的超时时间。</p>
<p>当调用端发起 RPC 请求时，如果发送请求发生异常并触发了异常重试，我们可以先判定下这个请求是否已经超时，如果已经超时了就直接返回超时异常，否则就先重置下这个请求的超时时间，之后再发起重试。</p>
<p>在所有发起重试、负载均衡选择节点的时候，去掉重试之前出现过问题的那个节点，以保证重试的成功率。</p>
<h3 id="业务异常"><a href="#业务异常" class="headerlink" title="业务异常"></a>业务异常</h3><p>RPC 框架是不会知道哪些业务异常能够去进行异常重试的，我们可以加个重试异常的白名单，用户可以将允许重试的异常加入到这个白名单中。当调用端发起调用，并且配置了异常重试策略，捕获到异常之后，我们就可以采用这样的异常处理策略。如果这个异常是 RPC 框架允许重试的异常，或者这个异常类型存在于可重试异常的白名单中，我们就允许对这个请求进行重试。</p>
<hr>
<p>综上，一个可靠的 RPC 容错处理机制如下：</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20200717163921.png" alt="img"></p>
<h2 id="优雅关闭：如何避免服务停机带来的业务损失？"><a href="#优雅关闭：如何避免服务停机带来的业务损失？" class="headerlink" title="优雅关闭：如何避免服务停机带来的业务损失？"></a>优雅关闭：如何避免服务停机带来的业务损失？</h2><blockquote>
<p>优雅关闭：如何避免服务停机带来的业务损失？</p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20220623102847.png"></p>
<p>在服务重启的时候，对于调用方来说，可能会存在以下几种情况：</p>
<ul>
<li><strong>调用方发请求前，目标服务已经下线</strong>。对于调用方来说，跟目标节点的连接会断开，这时候调用方可以立马感知到，并且在其健康列表里面会把这个节点挪掉，自然也就不会被负载均衡选中。</li>
<li><strong>调用方发请求的时候，目标服务正在关闭</strong>。但调用方并不知道它正在关闭，而且两者之间的连接也没断开，所以这个节点还会存在健康列表里面，因此该节点就有一定概率会被负载均衡选中。</li>
</ul>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20220623110010.png"></p>
<p>当服务提供方正在关闭，如果这之后还收到了新的业务请求，服务提供方直接返回一个特定的异常给调用方（比如 ShutdownException）。这个异常就是告诉调用方“我已经收到这个请求了，但是我正在关闭，并没有处理这个请求”，然后调用方收到这个异常响应后，RPC 框架把这个节点从健康列表挪出，并把请求自动重试到其他节点，因为这个请求是没有被服务提供方处理过，所以可以安全地重试到其他节点，这样就可以实现对业务无损。</p>
<p>但如果只是靠等待被动调用，就会让这个关闭过程整体有点漫长。因为有的调用方那个时刻没有业务请求，就不能及时地通知调用方了，所以我们可以加上主动通知流程，这样既可以保证实时性，也可以避免通知失败的情况。</p>
<p>如何捕获到关闭事件呢？在 Java 语言里面，对应的是 Runtime.addShutdownHook 方法，可以注册关闭的钩子。在 RPC 启动的时候，我们提前注册关闭钩子，并在里面添加了两个处理程序，一个负责开启关闭标识，一个负责安全关闭服务对象，服务对象在关闭的时候会通知调用方下线节点。同时需要在我们调用链里面加上挡板处理器，当新的请求来的时候，会判断关闭标识，如果正在关闭，则抛出特定异常。</p>
<h2 id="优雅启动：如何避免流量打到没有启动完成的节点？"><a href="#优雅启动：如何避免流量打到没有启动完成的节点？" class="headerlink" title="优雅启动：如何避免流量打到没有启动完成的节点？"></a>优雅启动：如何避免流量打到没有启动完成的节点？</h2><blockquote>
<p>优雅启动：如何避免流量打到没有启动完成的节点？</p>
</blockquote>
<p>运行了一段时间后的应用，执行速度会比刚启动的应用更快。这是因为在 Java 里面，在运行过程中，JVM 虚拟机会把高频的代码编译成机器码，被加载过的类也会被缓存到 JVM 缓存中，再次使用的时候不会触发临时加载，这样就使得“热点”代码的执行不用每次都通过解释，从而提升执行速度。</p>
<p>但是这些“临时数据”，都在应用重启后就消失了。如果让刚启动的应用就承担像停机前一样的流量，这会使应用在启动之初就处于高负载状态，从而导致调用方过来的请求可能出现大面积超时，进而对线上业务产生损害行为。</p>
<h3 id="启动预热"><a href="#启动预热" class="headerlink" title="启动预热"></a>启动预热</h3><p>启动预热，就是让刚启动的服务提供方应用不承担全部的流量，而是让它被调用的次数随着时间的移动慢慢增加，最终让流量缓和地增加到跟已经运行一段时间后的水平一样。</p>
<p>首先，对于调用方来说，我们要知道服务提供方启动的时间。有两种方法：</p>
<ul>
<li>一种是服务提供方在启动的时候，把自己启动的时间告诉注册中心；</li>
<li>另外一种就是注册中心收到的服务提供方的请求注册时间。</li>
</ul>
<p>怎么确保所有机器的日期时间是一样的？在真实环境中机器都会默认开启 NTP 时间同步功能，来保证所有机器时间的一致性。</p>
<p>最终的结果就是，调用方通过服务发现，除了可以拿到 IP 列表，还可以拿到对应的启动时间。我们需要把这个时间作用在负载均衡上。</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20220623114858.png"></p>
<p>通过这个小逻辑的改动，我们就可以保证当服务提供方运行时长小于预热时间时，对服务提供方进行降权，减少被负载均衡选择的概率，避免让应用在启动之初就处于高负载状态，从而实现服务提供方在启动后有一个预热的过程。</p>
<h3 id="延迟暴露"><a href="#延迟暴露" class="headerlink" title="延迟暴露"></a>延迟暴露</h3><p>服务提供方应用在没有启动完成的时候，调用方的请求就过来了，而调用方请求过来的原因是，服务提供方应用在启动过程中把解析到的 RPC 服务注册到了注册中心，这就导致在后续加载没有完成的情况下服务提供方的地址就被服务调用方感知到了。</p>
<p>为了解决这个问题，需要在应用启动加载、解析 Bean 的时候，如果遇到了 RPC 服务的 Bean，只先把这个<br>Bean 注册到 Spring-BeanFactory 里面去，而并不把这个 Bean 对应的接口注册到注册中心，只有等应用启动完成后，才把接口注册到注册中心用于服务发现，从而实现让服务调用方延迟获取到服务提供方地址。</p>
<p>具体如何实现呢？</p>
<p>我们可以在服务提供方应用启动后，接口注册到注册中心前，预留一个 Hook 过程，让用户可以实现可扩展的<br>Hook 逻辑。用户可以在 Hook 里面模拟调用逻辑，从而使 JVM 指令能够预热起来，并且用户也可以在 Hook 里面事先预加载一些资源，只有等所有的资源都加载完成后，最后才把接口注册到注册中心。</p>
<h2 id="熔断限流：业务如何实现自我保护"><a href="#熔断限流：业务如何实现自我保护" class="headerlink" title="熔断限流：业务如何实现自我保护"></a>熔断限流：业务如何实现自我保护</h2><h3 id="限流"><a href="#限流" class="headerlink" title="限流"></a>限流</h3><h4 id="限流算法"><a href="#限流算法" class="headerlink" title="限流算法"></a>限流算法</h4><ul>
<li>计数器</li>
<li>滑动窗口</li>
<li>漏桶</li>
<li>令牌桶</li>
</ul>
<h4 id="限流要点"><a href="#限流要点" class="headerlink" title="限流要点"></a>限流要点</h4><p>服务端主要是通过限流来进行自我保护，我们在实现限流时要考虑到应用和 IP 级别，方便我们在服务治理的时候，对部分访问量特别大的应用进行合理的限流。</p>
<ul>
<li>服务端的限流阈值配置都是作用于单机的，而在有些场景下，例如对整个服务设置限流阈值，服务进行扩容时，<br>限流的配置并不方便。</li>
<li>我们可以在注册中心或配置中心下发限流阈值配置的时候，将总服务节点数也下发给服务节点，让 RPC 框架自己去计算限流阈值；</li>
<li>我们还可以让 RPC 框架的限流模块依赖一个专门的限流服务，对服务设置限流阈值进行精准地控制，但是这种方式依赖了限流服务，相比单机的限流方式，在性能和耗时上有劣势。</li>
</ul>
<p>服务提供方主要通过限流来进行自我保护，我们在实现限流时要考虑到应用和 IP 级别，方便我们在服务治理的时，对部分访问量特别大的应用进行合理的限流。</p>
<p>服务端的限流阈值配置都是作用于单机的，而在有些场景下，例如对整个服务设置限流阈值，服务进行扩容时，<br>限流的配置并不方便。我们可以在注册中心或配置中心下发限流阈值配置的时候，将总服务节点数也下发给服务节点，让 RPC 框架自己去计算限流阈值。</p>
<p>我们还可以让 RPC 框架的限流模块依赖一个专门的限流服务，对服务设置限流阈值进行精准地控制，但是这种方式依赖了限流服务，相比单机的限流方式，在性能和耗时上有劣势。</p>
<h3 id="熔断"><a href="#熔断" class="headerlink" title="熔断"></a>熔断</h3><p>调用端可以通过熔断机制进行自我保护，防止调用下游服务出现异常，或者耗时过长影响调用端的业务逻辑，RPC 框架可以在动态代理的逻辑中去整合熔断器，实现 RPC 框架的熔断功能。</p>
<p>熔断器的工作机制主要是关闭、打开和半打开这三个状态之间的切换。在正常情况下，熔断器是关闭的；当调用端调用下游服务出现异常时，熔断器会收集异常指标信息进行计算，当达到熔断条件时熔断器打开，这时调用端再发起请求是会直接被熔断器拦截，并快速地执行失败逻辑；当熔断器打开一段时间后，会转为半打开状态，这时熔断器允许调用端发送一个请求给服务端，如果这次请求能够正常地得到服务端的响应，则将状态置为关闭状态，否则<br>设置为打开。</p>
<h2 id="业务分组：如何隔离流量？"><a href="#业务分组：如何隔离流量？" class="headerlink" title="业务分组：如何隔离流量？"></a>业务分组：如何隔离流量？</h2><p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20200718204407.png" alt="img"></p>
<p>在 RPC 里面我们可以通过分组的方式人为地给不同的调用方划分出不同的小集群，从而实现调用方流量隔离的效果，保障我们的核心业务不受非核心业务的干扰。但我们在考虑问题的时候，不能顾此失彼，不能因为新加一个的功能而影响到原有系统的稳定性。</p>
<p>其实我们不仅可以通过分组把服务提供方划分成不同规模的小集群，我们还可以利用分组完成一个接口多种实现的功能。正常情况下，为了方便我们自己管理服务，我一般都会建议每个接口完成的功能尽量保证唯一。但在有些特殊场景下，两个接口也会完全一样，只是具体实现上有那么一点不同，那么我们就可以在服务提供方应用里面同时暴露两个相同接口，但只是接口分组不一样罢了。</p>
<h3 id="动态分组"><a href="#动态分组" class="headerlink" title="动态分组"></a>动态分组</h3><p>分组可以帮助服务提供方实现调用方的隔离。但是因为调用方流量并不是一成不变的，而且还可能会因为突发事件导致某个分组的流量溢出，而在整个大集群还有富余能力的时候，又因为分组隔离不能为出问题的集群提供帮助。</p>
<p>为了解决这种突发流量的问题，我们提供了一种更高效的方案，可以实现分组的快速伸缩。事实上我们还可以利用动态分组解决分组后给每个分组预留机器冗余的问题，我们没有必要把所有冗余的机器都分配到分组里面，我们可以把这些预留的机器做成一个共享的池子，从而减少整体预留的实例数量。</p>
<h2 id="异步-RPC：压榨单机吞吐量"><a href="#异步-RPC：压榨单机吞吐量" class="headerlink" title="异步 RPC：压榨单机吞吐量"></a>异步 RPC：压榨单机吞吐量</h2><blockquote>
<p>异步 RPC：压榨单机吞吐量</p>
</blockquote>
<p>影响到 RPC 调用的吞吐量的主要原因就是服务端的业务逻辑比较耗时，并且 CPU 大部分时间都在等待而没有去计算，导致 CPU 利用率不够，而提升单机吞吐量的最好办法就是使用异步 RPC。</p>
<p>RPC 框架的异步策略主要是调用端异步与服务端异步。调用端的异步就是通过 Future 方式实现异步，调用端发起一次异步请求并且从请求上下文中拿到一个 Future，之后通过 Future 的 get 方法获取结果，如果业务逻辑中同时调用多个其它的服务，则可以通过 Future 的方式减少业务逻辑的耗时，提升吞吐量。服务端异步则需要一种回调方式，让业务逻辑可以异步处理，之后调用 RPC 框架提供的回调接口，将最终结果异步通知给调用端。</p>
<p>另外，我们可以通过对 CompletableFuture 的支持，实现 RPC 调用在调用端与服务端之间的完全异步，同时提升两端的单机吞吐量。</p>
<p>此外，RPC 框架也可以有其它的异步策略，比如集成 RxJava，再比如 gRPC 的 StreamObserver 入参对象，但 CompletableFuture 是 Java8 原生提供的，无代码入侵性，并且在使用上更加方便。</p>
<h2 id="安全体系：如何建立可靠的安全体系？"><a href="#安全体系：如何建立可靠的安全体系？" class="headerlink" title="安全体系：如何建立可靠的安全体系？"></a>安全体系：如何建立可靠的安全体系？</h2><p>RPC 是解决应用间互相通信的框架，而应用之间的远程调用过程一般不会暴露在公网，换句话讲就是说 RPC 一般用于解决内部应用之间的通信，而这个“内部”是指应用都部署在同一个大局域网内。相对于公网环境，局域网的隔离性更好，也就相对更安全，所以在 RPC 里面我们很少考虑像数据包篡改、请求伪造等恶意行为。</p>
<p>对于 RPC 来说，需要关心的安全问题不会有公网应用那么复杂，我们只要保证让服务调用方能拿到真实的服务提供方 IP 地址集合，且服务提供方可以管控调用自己的应用就够了（比如颁发数字签名）。</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20220623194151.png"></p>
<h2 id="分布式环境下如何快速定位问题？"><a href="#分布式环境下如何快速定位问题？" class="headerlink" title="分布式环境下如何快速定位问题？"></a>分布式环境下如何快速定位问题？</h2><blockquote>
<p>问题定位：链路追踪</p>
</blockquote>
<p><strong>链路追踪要点</strong></p>
<ul>
<li>traceId：用于表示一次完整的请求</li>
<li>spanId：用于标识一次 RPC 调用在分布式请求中的位置</li>
<li>annonation：业务自定义埋点数据</li>
</ul>
<p><strong>链路追踪理论</strong></p>
<ul>
<li><a target="_blank" rel="noopener" href="http://bigbully.github.io/Dapper-translation/">Dapper, a Large-Scale Distributed Systems Tracing Infrastructure</a></li>
</ul>
<p><strong>链路追踪代表产品</strong></p>
<ul>
<li><a target="_blank" rel="noopener" href="https://zipkin.io/"><strong>Zipkin</strong></a>：Zipkin 是 Twitter 开源的调用链分析工具，目前基于 <strong><a target="_blank" rel="noopener" href="https://github.com/spring-cloud/spring-cloud-sleuth">spring-cloud-sleuth</a></strong> 得到了广泛的使用，特点是轻量，使用、部署简单。</li>
<li><a target="_blank" rel="noopener" href="https://pinpoint-apm.gitbook.io/pinpoint/"><strong>Pinpoint</strong></a>：是韩国人开源的基于字节码注入的调用链分析，以及应用监控分析工具。特点是支持多种插件，UI 功能强大，接入端无代码侵入。</li>
<li><a target="_blank" rel="noopener" href="https://skywalking.apache.org/"><strong>SkyWalking</strong></a>：是本土开源的基于字节码注入的调用链分析，以及应用监控分析工具。特点是支持多种插件，UI 功能较强，接入端无代码侵入。目前已加入 Apache 孵化器。</li>
<li><a target="_blank" rel="noopener" href="https://github.com/dianping/cat"><strong>CAT</strong></a>：CAT 是美团点评开源的基于编码和配置的调用链分析，应用监控分析，日志采集，监控报警等一系列的监控平台工具。</li>
</ul>
<h2 id="详解时钟轮在-RPC-中的应用"><a href="#详解时钟轮在-RPC-中的应用" class="headerlink" title="详解时钟轮在 RPC 中的应用"></a>详解时钟轮在 RPC 中的应用</h2><p>无论是同步调用还是异步调用，调用端内部实行的都是异步，而调用端在向服务端发送消息之前会创建一个 Future，并存储这个消息标识与这个 Future 的映射，当服务端收到消息并且处理完毕后向调用端发送响应消息，调用端在接收到消息后会根据消息的唯一标识找到这个 Future，并将结果注入给这个 Future。</p>
<h3 id="一般定时任务方案的缺点"><a href="#一般定时任务方案的缺点" class="headerlink" title="一般定时任务方案的缺点"></a>一般定时任务方案的缺点</h3><ol>
<li>方案一：每创建一个 Future 都启动一个线程，之后 sleep，到达超时时间就触发请求超时的处理逻辑。</li>
</ol>
<ul>
<li>缺点：需要创建大量线程。例如：高并发场景下，单机可能每秒要发送数万次请求，请求超时时间设置的是 5 秒，那我们要创建多少个线程用来执行超时任务呢？超过 10 万个线程！</li>
</ul>
<ol start="2">
<li>方案二：用一个线程来处理所有的定时任务，不断轮询定时任务。假设一个线程每隔 100 毫秒会扫描一遍所有的处理 Future 超时的任务，当发现一个 Future 超时了，我们就执行这个任务，对这个 Future 执行超时逻辑。</li>
</ol>
<ul>
<li>缺点：很浪费 CPU。高并发场景下，如果调用端刚好在 1 秒内发送了 1 万次请求，这 1 万次请求要在 5 秒后才会超时，那么那个扫描的线程在这个 5 秒内就会不停地对这 1 万个任务进行扫描遍历，要额外扫描 40 多次（每 100 毫秒扫描一次，5 秒内要扫描近 50 次），很浪费 CPU。</li>
</ul>
<h3 id="时钟轮方案"><a href="#时钟轮方案" class="headerlink" title="时钟轮方案"></a>时钟轮方案</h3><p>在时钟轮机制中，有时间槽和时钟轮的概念，时间槽就相当于时钟的刻度，而时钟轮就相当于秒针与分针等跳动的一个周期，我们会将每个任务放到对应的时间槽位上。</p>
<p>时钟轮的运行机制和生活中的时钟也是一样的，每隔固定的单位时间，就会从一个时间槽位跳到下一个时间槽位，这就相当于我们的秒针跳动了一次；时钟轮可以分为多层，下一层时钟轮中每个槽位的单位时间是当前时间轮整个周期的时间，这就相当于 1 分钟等于 60 秒钟；当时钟轮将一个周期的所有槽位都跳动完之后，就会从下一层时钟轮中取出一个槽位的任务，重新分布到当前的时钟轮中，当前时钟轮则从第 0 槽位从新开始跳动，这就相当于<br>下一分钟的第 1 秒。</p>
<p><strong>时钟轮在 RPC 中的应用</strong></p>
<ul>
<li><strong>调用端请求超时处理</strong>：每发一次请求，都创建一个处理请求超时的定时任务放到时钟轮里，在高并发、高访问量的情况下，时钟轮每次只轮询一个时间槽位中的任务，这样会节省大量的 CPU。</li>
<li><strong>调用端与服务端启动超时也可以应用到时钟轮</strong>：以调用端为例，假设我们想要让应用可以快速地部署，例如 1 分钟内启动，如果超过 1 分钟则启动失败。我们可以在调用端启动时创建一个处理启动超时的定时任务，放到时钟轮里。</li>
<li><strong>定时心跳</strong>：RPC 框架调用端定时向服务端发送心跳，来维护连接状态，我们可以将心跳的逻辑封装为一个心跳任务，放到时钟轮里。</li>
</ul>
<h2 id="流量回放：保障业务技术升级的神器"><a href="#流量回放：保障业务技术升级的神器" class="headerlink" title="流量回放：保障业务技术升级的神器"></a>流量回放：保障业务技术升级的神器</h2><p>实际情况就是我们不仅要保障已有业务的稳定，还需要快速去完成各种新业务的需求，这期间我们的应用代码就会经常发生变化，而发生变化后就可能会引入新的不稳定因素，而且这个过程会一直持续不断发生。</p>
<p>为了保障应用升级后，我们的业务行为还能保持和升级前一样，我们在大多数情况下都是依靠已有的 TestCase 去验证，但这种方式在一定程度上并不是完全可靠的。最可靠的方式就是引入线上 Case 去验证改造后的应用，把线上的真实流量在改造后的应用里面进行回放，这样不仅节省整个上线时间，还能弥补手动维护 Case 存在的缺陷。</p>
<p>应用引入了 RPC 后，所有的请求流量都会被 RPC 接管，所以我们可以很自然地在 RPC 里面支持流量回放功能。虽然这个功能本身并不是 RPC 的核心功能，但对于使用 RPC 的人来说，他们有了这个功能之后，就可以更放心地升级自己的应用了。</p>
<h2 id="动态分组：超高效实现秒级扩缩容"><a href="#动态分组：超高效实现秒级扩缩容" class="headerlink" title="动态分组：超高效实现秒级扩缩容"></a>动态分组：超高效实现秒级扩缩容</h2><p>分组后带来的收益，它可以帮助服务提供方实现调用方的隔离。但是因为调用方流量并不是一成不变的，而且还可能会因为突发事件导致某个分组的流量溢出，而在整个大集群还有富余能力的时候，又因为分组隔离不能为出问题的集群提供帮助。</p>
<p>为了解决这种突发流量的问题，我们提供了一种更高效的方案，可以实现分组的快速扩缩容。事实上我们还可以利用动态分组解决分组后给每个分组预留机器冗余的问题，我们没有必要把所有冗余的机器都分配到分组里面，我们可以把这些预留的机器做成一个共享的池子，从而减少整体预留的实例数量。</p>
<h2 id="如何在没有接口的情况下进行-RPC-调用？"><a href="#如何在没有接口的情况下进行-RPC-调用？" class="headerlink" title="如何在没有接口的情况下进行 RPC 调用？"></a>如何在没有接口的情况下进行 RPC 调用？</h2><h3 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h3><p>（1）<strong>测试平台</strong>：各个业务方在测试平台中通过输入接口、分组名、方法名以及参数值，在线测试自己发布的 RPC 服务。</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20220624110324.png"></p>
<p>（2）<strong>轻量级的服务网关</strong>：可以让各个业务方用 HTTP 的方式，通过服务网关调用其它服务。服务网关要作为所有 RPC 服务的调用端，是不能依赖所有服务提供方的接口 API 的，也需要调用端在没有服务提供方提供接口的情况下，仍然可以正常地发起 RPC 调用。</p>
<h3 id="如何泛化调用"><a href="#如何泛化调用" class="headerlink" title="如何泛化调用"></a>如何泛化调用</h3><p>所谓的 RPC 调用，本质上就是调用端向服务端发送一条请求消息，服务端接收并处理，之后向调用端发送一条响应消息，调用端处理完响应消息之后，一次 RPC 调用就完成了。只要调用端将服务端需要知道的信息，如接口名、业务分组名、方法名以及参数信息等封装成请求消息发送给服务端，服务端就能够解析并处理这条请求消息，这样问题就解决了。</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20220624110611.png"></p>
<p>泛化调用接口示例：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">GenericService</span> &#123;</span><br><span class="line">	Object $invoke(String methodName, String[] paramTypes, Object[] params);</span><br><span class="line">	CompletableFuture&lt;Object&gt; $asyncInvoke(String methodName, String[] paramTypes</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="如何在线上环境里兼容多种-RPC-协议？"><a href="#如何在线上环境里兼容多种-RPC-协议？" class="headerlink" title="如何在线上环境里兼容多种 RPC 协议？"></a>如何在线上环境里兼容多种 RPC 协议？</h2><p>业界有很多 RPC 框架，如：Dubbo、Hessian、gRPC 等，它们随着技术发展逐渐涌现出来。不同时期、不同项目为了解决自身的通信问题，可能会选择不同的 RPC 框架。</p>
<p>对于一个公司来说，不同的 RPC 框架，会使得维护成本变高。所以，如果想缩减维护成本，自然会想到统一 RPC 框架。</p>
<p>但这面临的重要问题是：如果直接切换 RPC 框架，会导致新旧 RPC 框架的服务无法通信，从而造成业务损失。为此，一个折中的方案就是：先不移除原有的 RPC 框架，但同时接入新的 RPC 框架，让两种 RPC 同时提供服务，然后等所有的应用都接入完新的 RPC 以后，再让所有的应用逐步接入到新的 RPC 上。</p>
<p>在保持原有 RPC 使用方式不变的情况下，同时引入新的 RPC 框架的思路，是可以让所有的应用最终都能升级到我们想要升级的 RPC 上，但对于开发人员来说，这样切换成本还是有点儿高，整个过程最少需要两次上线才能彻底地把应用里面的旧 RPC 都切换成新 RPC。还有一种方案：要让新的 RPC 能同时支持多种 RPC 调用，当一个调用方切换到新的 RPC 之后，调用方和服务提供方之间就可以用新的协议完成调用；当调用方还是用老的 RPC 进行调用的话，调用方和服务提供方之间就继续沿用老的协议完成调用。</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20220624112147.png"></p>
<h3 id="如何优雅处理多协议"><a href="#如何优雅处理多协议" class="headerlink" title="如何优雅处理多协议"></a>如何优雅处理多协议</h3><p>每种协议约定的数据包格式是不一样的，而且每种协议开头都有一个协议编码，我们一般叫做 magic number。</p>
<p>当 RPC 收到了数据包后，我们可以先解析出 magic number 来。获取到 magic number 后，我们就很容易地找到对应协议的数据格式，然后用对应协议的数据格式去解析收到的二进制数据包。</p>
<p>协议解析过程就是把一连串的二进制数据变成一个 RPC 内部对象，但这个对象一般是跟协议相关的，所以为了能让 RPC 内部处理起来更加方便，我们一般都会把这个协议相关的对象转成一个跟协议无关的 RPC 对象。这是因为在 RPC 流程中，当服务提供方收到反序列化后的请求的时候，我们需要根据当前请求的参数找到对应接口的实现类去完成真正的方法调用。如果这个请求参数是跟协议相关的话，那后续 RPC 的整个处理逻辑就会变得很复杂。</p>
<p>当完成了真正的方法调用以后，RPC 返回的也是一个跟协议无关的通用对象，所以在真正往调用方写回数据的时候，我们同样需要完成一个对象转换的逻辑，只不过这时候是把通用对象转成协议相关的对象。</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20220624112208.png"></p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul>
<li><a target="_blank" rel="noopener" href="https://time.geekbang.org/column/intro/100046201">RPC 实战与核心原理</a></li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://dunwu.github.io/blog/pages/892679dd/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/blog/uploads/avatar.gif">
      <meta itemprop="name" content="钝悟 ◾ Dunwu">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Dunwu Blog">
      <meta itemprop="description" content="钝悟的个人博客">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | Dunwu Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/blog/pages/892679dd/" class="post-title-link" itemprop="url">SpringBoot Actuator 快速入门</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-06-14 20:51:22" itemprop="dateCreated datePublished" datetime="2022-06-14T20:51:22+08:00">2022-06-14</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-09-13 17:56:53" itemprop="dateModified" datetime="2025-09-13T17:56:53+08:00">2025-09-13</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/blog/categories/Java/" itemprop="url" rel="index"><span itemprop="name">Java</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/blog/categories/Java/%E6%A1%86%E6%9E%B6/" itemprop="url" rel="index"><span itemprop="name">框架</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/blog/categories/Java/%E6%A1%86%E6%9E%B6/Spring/" itemprop="url" rel="index"><span itemprop="name">Spring</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/blog/categories/Java/%E6%A1%86%E6%9E%B6/Spring/Spring%E5%85%B6%E4%BB%96/" itemprop="url" rel="index"><span itemprop="name">Spring其他</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>8.3k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>8 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="SpringBoot-Actuator-快速入门"><a href="#SpringBoot-Actuator-快速入门" class="headerlink" title="SpringBoot Actuator 快速入门"></a>SpringBoot Actuator 快速入门</h1><p><a target="_blank" rel="noopener" href="https://github.com/spring-projects/spring-boot/tree/v2.7.0/spring-boot-project/spring-boot-actuator"><code>spring-boot-actuator</code></a> 模块提供了 Spring Boot 的所有生产就绪功能。启用这些功能的推荐方法是添加 <code>spring-boot-starter-actuator</code> 依赖。</p>
<p>如果是 Maven 项目，添加以下依赖：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-actuator<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>如果是 Gradle 项目，添加以下声明：</p>
<figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">dependencies &#123;</span><br><span class="line">    implementation <span class="string">&#x27;org.springframework.boot:spring-boot-starter-actuator&#x27;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="端点（Endpoint）"><a href="#端点（Endpoint）" class="headerlink" title="端点（Endpoint）"></a>端点（Endpoint）</h2><p>Actuator Endpoint 使 Spring Boot 用户可以监控应用，并和应用进行交互。Spring Boot 内置了许多 端点，并允许用户自定义端点。例如，<code>health</code> 端点提供基本的应用健康信息。</p>
<p>用户可以启用或禁用每个单独的端点并通过 HTTP 或 JMX 暴露它们（使它们可远程访问）。当端点被启用和公开时，它被认为是可用的。内置端点仅在可用时才会自动配置。大多数应用程序选择通过 HTTP 公开。例如，默认情况下，<code>health</code> 端点映射到 <code>/actuator/health</code>。</p>
<h3 id="启用端点"><a href="#启用端点" class="headerlink" title="启用端点"></a>启用端点</h3><p>默认情况下，除了 <code>shutdown</code> 之外的所有端点都已启用。要配置端点的启用，请使用 <code>management.endpoint.&lt;id&gt;.enabled</code> 属性。以下示例启用 <code>shutdown</code> 端点：</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">management.endpoint.shutdown.enabled</span>=<span class="string">true</span></span><br></pre></td></tr></table></figure>

<p>如果您希望端点是明确指定才启用，请将 <code>management.endpoints.enabled-by-default</code> 属性设置为 false 并根据需要明确指定启用的端点，以下为示例：</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">management.endpoints.enabled-by-default</span>=<span class="string">false</span></span><br><span class="line"><span class="attr">management.endpoint.info.enabled</span>=<span class="string">true</span></span><br></pre></td></tr></table></figure>

<h3 id="暴露端点"><a href="#暴露端点" class="headerlink" title="暴露端点"></a>暴露端点</h3><p>由于端点可能包含敏感信息，您应该仔细考虑何时暴露它们。下表显示了内置端点的默认曝光：</p>
<table>
<thead>
<tr>
<th align="left">ID</th>
<th align="left">JMX</th>
<th align="left">Web</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><code>auditevents</code></td>
<td align="left">Yes</td>
<td align="left">No</td>
</tr>
<tr>
<td align="left"><code>beans</code></td>
<td align="left">Yes</td>
<td align="left">No</td>
</tr>
<tr>
<td align="left"><code>caches</code></td>
<td align="left">Yes</td>
<td align="left">No</td>
</tr>
<tr>
<td align="left"><code>conditions</code></td>
<td align="left">Yes</td>
<td align="left">No</td>
</tr>
<tr>
<td align="left"><code>configprops</code></td>
<td align="left">Yes</td>
<td align="left">No</td>
</tr>
<tr>
<td align="left"><code>env</code></td>
<td align="left">Yes</td>
<td align="left">No</td>
</tr>
<tr>
<td align="left"><code>flyway</code></td>
<td align="left">Yes</td>
<td align="left">No</td>
</tr>
<tr>
<td align="left"><code>health</code></td>
<td align="left">Yes</td>
<td align="left">Yes</td>
</tr>
<tr>
<td align="left"><code>heapdump</code></td>
<td align="left">N&#x2F;A</td>
<td align="left">No</td>
</tr>
<tr>
<td align="left"><code>httptrace</code></td>
<td align="left">Yes</td>
<td align="left">No</td>
</tr>
<tr>
<td align="left"><code>info</code></td>
<td align="left">Yes</td>
<td align="left">No</td>
</tr>
<tr>
<td align="left"><code>integrationgraph</code></td>
<td align="left">Yes</td>
<td align="left">No</td>
</tr>
<tr>
<td align="left"><code>jolokia</code></td>
<td align="left">N&#x2F;A</td>
<td align="left">No</td>
</tr>
<tr>
<td align="left"><code>logfile</code></td>
<td align="left">N&#x2F;A</td>
<td align="left">No</td>
</tr>
<tr>
<td align="left"><code>loggers</code></td>
<td align="left">Yes</td>
<td align="left">No</td>
</tr>
<tr>
<td align="left"><code>liquibase</code></td>
<td align="left">Yes</td>
<td align="left">No</td>
</tr>
<tr>
<td align="left"><code>metrics</code></td>
<td align="left">Yes</td>
<td align="left">No</td>
</tr>
<tr>
<td align="left"><code>mappings</code></td>
<td align="left">Yes</td>
<td align="left">No</td>
</tr>
<tr>
<td align="left"><code>prometheus</code></td>
<td align="left">N&#x2F;A</td>
<td align="left">No</td>
</tr>
<tr>
<td align="left"><code>quartz</code></td>
<td align="left">Yes</td>
<td align="left">No</td>
</tr>
<tr>
<td align="left"><code>scheduledtasks</code></td>
<td align="left">Yes</td>
<td align="left">No</td>
</tr>
<tr>
<td align="left"><code>sessions</code></td>
<td align="left">Yes</td>
<td align="left">No</td>
</tr>
<tr>
<td align="left"><code>shutdown</code></td>
<td align="left">Yes</td>
<td align="left">No</td>
</tr>
<tr>
<td align="left"><code>startup</code></td>
<td align="left">Yes</td>
<td align="left">No</td>
</tr>
<tr>
<td align="left"><code>threaddump</code></td>
<td align="left">Yes</td>
<td align="left">No</td>
</tr>
</tbody></table>
<p>要更改暴露的端点，请使用以下特定于技术的包含和排除属性：</p>
<table>
<thead>
<tr>
<th align="left">Property</th>
<th align="left">Default</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><code>management.endpoints.jmx.exposure.exclude</code></td>
<td align="left"></td>
</tr>
<tr>
<td align="left"><code>management.endpoints.jmx.exposure.include</code></td>
<td align="left"><code>*</code></td>
</tr>
<tr>
<td align="left"><code>management.endpoints.web.exposure.exclude</code></td>
<td align="left"></td>
</tr>
<tr>
<td align="left"><code>management.endpoints.web.exposure.include</code></td>
<td align="left"><code>health</code></td>
</tr>
</tbody></table>
<p><code>include</code> 属性列出了暴露的端点的 ID。 <code>exclude</code> 属性列出了不应暴露的端点的 ID。 <code>exclude</code> 属性优先于 <code>include</code> 属性。您可以使用端点 ID 列表配置包含和排除属性。</p>
<p>例如，仅暴露 <code>health</code> 和 info 端点，其他端点都不通过 JMX 暴露，可以按如下配置：</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">management.endpoints.jmx.exposure.include</span>=<span class="string">health,info</span></span><br></pre></td></tr></table></figure>

<p>注意：<code>*</code> 可用于选择所有端点。</p>
<h3 id="安全"><a href="#安全" class="headerlink" title="安全"></a>安全</h3><p>出于安全考虑，只有 <code>/health</code> 端点会通过 HTTP 方式暴露。用户可以通过 <code>management.endpoints.web.exposure.include</code> 决定哪些端点可以通过 HTTP 方式暴露。</p>
<p>如果 Spring Security 在类路径上并且不存在其他 <code>WebSecurityConfigurerAdapter</code> 或 <code>SecurityFilterChain</code> bean，则除 <code>/health</code> 之外的所有 actuator 都由 Spring Boot 自动启用安全控制。如果用户自定义了 <code>WebSecurityConfigurerAdapter</code> 或 <code>SecurityFilterChain</code> bean，Spring Boot 不再启用安全控制，由用户自行控制访问规则。</p>
<p>如果您希望为 HTTP 端点定义安全控制（例如，只允许具有特定角色的用户访问它们），Spring Boot 提供了一些方便的 <code>RequestMatcher</code> 对象，您可以将它们与 Spring Security 结合使用。</p>
<p>下面是一个典型的 Spring Security 配置示例：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Configuration(proxyBeanMethods = false)</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MySecurityConfiguration</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="keyword">public</span> SecurityFilterChain <span class="title function_">securityFilterChain</span><span class="params">(HttpSecurity http)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        http.requestMatcher(EndpointRequest.toAnyEndpoint())</span><br><span class="line">                .authorizeRequests((requests) -&gt; requests.anyRequest().hasRole(<span class="string">&quot;ENDPOINT_ADMIN&quot;</span>));</span><br><span class="line">        http.httpBasic();</span><br><span class="line">        <span class="keyword">return</span> http.build();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>前面的示例使用 EndpointRequest.toAnyEndpoint() 将请求匹配到任何端点，然后确保所有端点都具有 ENDPOINT_ADMIN 角色。 EndpointRequest 上还提供了其他几种匹配器方法。</p>
<p>如果希望无需身份验证即可访问所有执行器端点。可以通过更改 management.endpoints.web.exposure.include 属性来做到这一点，如下所示：</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">management.endpoints.web.exposure.include</span>=<span class="string">*</span></span><br></pre></td></tr></table></figure>

<p>此外，如果存在 Spring Security，您将需要添加自定义安全配置，以允许未经身份验证的访问端点，如以下示例所示：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Configuration(proxyBeanMethods = false)</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MySecurityConfiguration</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="keyword">public</span> SecurityFilterChain <span class="title function_">securityFilterChain</span><span class="params">(HttpSecurity http)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        http.requestMatcher(EndpointRequest.toAnyEndpoint())</span><br><span class="line">                .authorizeRequests((requests) -&gt; requests.anyRequest().permitAll());</span><br><span class="line">        <span class="keyword">return</span> http.build();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>由于 Spring Boot 依赖于 Spring Security 的默认设置，因此 CSRF 保护默认开启。这意味着在使用默认安全配置时，需要 POST（关闭和记录器端点）、PUT 或 DELETE 的执行器端点会收到 403（禁止）错误。</p>
<blockquote>
<p>建议仅在创建非浏览器客户端使用的服务时完全禁用 CSRF 保护。</p>
</blockquote>
<h3 id="配置端点"><a href="#配置端点" class="headerlink" title="配置端点"></a>配置端点</h3><p>端点会自动缓存对不带任何参数的读操作的响应数据。要配置端点缓存响应的时间量，请使用其 <code>cache.time-to-live</code> 属性。以下示例将 bean 端点缓存的生存时间设置为 10 秒：</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">management.endpoint.beans.cache.time-to-live</span>=<span class="string">10s</span></span><br></pre></td></tr></table></figure>

<h3 id="Actuator-Web-端点的超媒体"><a href="#Actuator-Web-端点的超媒体" class="headerlink" title="Actuator Web 端点的超媒体"></a>Actuator Web 端点的超媒体</h3><p>Spring Boot Actuator 中内置了一个“发现页面”端点，其中包含了所有端点的链接。默认情况下，“发现页面”在 <code>/actuator</code> 上可用。</p>
<p>要禁用“发现页面”，请将以下属性添加到您的应用程序属性中：</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">management.endpoints.web.discovery.enabled</span>=<span class="string">false</span></span><br></pre></td></tr></table></figure>

<p>配置自定义管理上下文路径后，“发现页面”会自动从 <code>/actuator</code> 移动到应用管理上下文的根目录。例如，如果管理上下文路径是 <code>/management</code>，则发现页面可从 <code>/management</code> 获得。当管理上下文路径设置为 &#x2F; 时，发现页面被禁用以防止与其他映射发生冲突的可能性。</p>
<h3 id="跨域支持"><a href="#跨域支持" class="headerlink" title="跨域支持"></a>跨域支持</h3><p>CORS 是一种 W3C 规范，可让用户以灵活的方式指定授权哪种跨域请求。如果使用 Spring MVC 或 Spring WebFlux，则可以配置 Actuator 的 Web 端点以支持此类场景。</p>
<p>CORS 支持默认是禁用的，只有在设置 <code>management.endpoints.web.cors.allowed-origins</code> 属性后才会启用。以下配置允许来自 example.com 域的 GET 和 POST 调用：</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">management.endpoints.web.cors.allowed-origins</span>=<span class="string">https://example.com</span></span><br><span class="line"><span class="attr">management.endpoints.web.cors.allowed-methods</span>=<span class="string">GET,POST</span></span><br></pre></td></tr></table></figure>

<h3 id="自定义端点"><a href="#自定义端点" class="headerlink" title="自定义端点"></a>自定义端点</h3><p>如果添加带有 <code>@Endpoint</code> 注释的 <code>@Bean</code>，则任何带有 <code>@ReadOperation</code>、<code>@WriteOperation</code> 或 <code>@DeleteOperation</code> 注释的方法都会自动通过 JMX 公开，并且在 Web 应用程序中，也可以通过 HTTP 公开。可以使用 Jersey、Spring MVC 或 Spring WebFlux 通过 HTTP 公开端点。如果 Jersey 和 Spring MVC 都可用，则使用 Spring MVC。</p>
<p>以下示例公开了一个返回自定义对象的读取操作：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@ReadOperation</span></span><br><span class="line"><span class="keyword">public</span> CustomData <span class="title function_">getData</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">CustomData</span>(<span class="string">&quot;test&quot;</span>, <span class="number">5</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>您还可以使用 <code>@JmxEndpoint</code> 或 <code>@WebEndpoint</code> 编写特定技术的端点。这些端点仅限于各自的技术。例如，<code>@WebEndpoint</code> 仅通过 HTTP 而不是通过 JMX 公开。</p>
<p>您可以使用 <code>@EndpointWebExtension</code> 和 <code>@EndpointJmxExtension</code> 编写特定技术的扩展。这些注释让您可以提供特定技术的操作来扩充现有端点。</p>
<p>最后，如果您需要访问 Web 框架的功能，您可以实现 servlet 或 Spring <code>@Controller</code> 和 <code>@RestController</code> 端点，但代价是它们无法通过 JMX 或使用不同的 Web 框架获得。</p>
<h2 id="通过-HTTP-进行监控和管理"><a href="#通过-HTTP-进行监控和管理" class="headerlink" title="通过 HTTP 进行监控和管理"></a>通过 HTTP 进行监控和管理</h2><h3 id="自定义管理端点路径"><a href="#自定义管理端点路径" class="headerlink" title="自定义管理端点路径"></a>自定义管理端点路径</h3><p>如果是 Web 应用，Spring Boot Actuator 会自动将所有启用的端点通过 HTTP 方式暴露。默认约定是使用前缀为 <code>/actuator</code> 的端点的 id 作为 URL 路径。例如，健康被暴露为 <code>/actuator/health</code>。</p>
<p>有时，自定义管理端点的前缀很有用。例如，您的应用程序可能已经将 <code>/actuator</code> 用于其他目的。您可以使用 <code>management.endpoints.web.base-path</code> 属性更改管理端点的前缀，如以下示例所示：</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">management.endpoints.web.base-path</span>=<span class="string">/manage</span></span><br></pre></td></tr></table></figure>

<p>该示例将端点从 <code>/actuator/&#123;id&#125;</code> 更改为 <code>/manage/&#123;id&#125;</code>（例如，<code>/manage/info</code>）。</p>
<h3 id="自定义管理服务器端口"><a href="#自定义管理服务器端口" class="headerlink" title="自定义管理服务器端口"></a>自定义管理服务器端口</h3><figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">management.server.port</span>=<span class="string">8081</span></span><br></pre></td></tr></table></figure>

<h3 id="配置-SSL"><a href="#配置-SSL" class="headerlink" title="配置 SSL"></a>配置 SSL</h3><p>当配置为使用自定义端口时，还可以使用各种 <code>management.server.ssl.*</code> 属性为管理服务器配置自己的 SSL。例如，这样做可以让管理服务器在主应用程序使用 HTTPS 时通过 HTTP 可用，如以下属性设置所示：</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">server.port</span>=<span class="string">8443</span></span><br><span class="line"><span class="attr">server.ssl.enabled</span>=<span class="string">true</span></span><br><span class="line"><span class="attr">server.ssl.key-store</span>=<span class="string">classpath:store.jks</span></span><br><span class="line"><span class="attr">server.ssl.key-password</span>=<span class="string">secret</span></span><br><span class="line"><span class="attr">management.server.port</span>=<span class="string">8080</span></span><br><span class="line"><span class="attr">management.server.ssl.enabled</span>=<span class="string">false</span></span><br></pre></td></tr></table></figure>

<p>或者，主服务器和管理服务器都可以使用 SSL，但使用不同的密钥存储，如下所示：</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">server.port</span>=<span class="string">8443</span></span><br><span class="line"><span class="attr">server.ssl.enabled</span>=<span class="string">true</span></span><br><span class="line"><span class="attr">server.ssl.key-store</span>=<span class="string">classpath:main.jks</span></span><br><span class="line"><span class="attr">server.ssl.key-password</span>=<span class="string">secret</span></span><br><span class="line"><span class="attr">management.server.port</span>=<span class="string">8080</span></span><br><span class="line"><span class="attr">management.server.ssl.enabled</span>=<span class="string">true</span></span><br><span class="line"><span class="attr">management.server.ssl.key-store</span>=<span class="string">classpath:management.jks</span></span><br><span class="line"><span class="attr">management.server.ssl.key-password</span>=<span class="string">secret</span></span><br></pre></td></tr></table></figure>

<h3 id="自定义管理服务器地址"><a href="#自定义管理服务器地址" class="headerlink" title="自定义管理服务器地址"></a>自定义管理服务器地址</h3><figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">management.server.port</span>=<span class="string">8081</span></span><br><span class="line"><span class="attr">management.server.address</span>=<span class="string">127.0.0.1</span></span><br></pre></td></tr></table></figure>

<h3 id="禁用-HTTP-端点"><a href="#禁用-HTTP-端点" class="headerlink" title="禁用 HTTP 端点"></a>禁用 HTTP 端点</h3><p>如果您不想通过 HTTP 方式暴露端点，可以将管理端口设置为 -1，如以下示例所示：</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">management.server.port</span>=<span class="string">-1</span></span><br></pre></td></tr></table></figure>

<p>也可以通过使用 management.endpoints.web.exposure.exclude 属性来实现这一点，如以下示例所示：</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">management.endpoints.web.exposure.exclude</span>=<span class="string">*</span></span><br></pre></td></tr></table></figure>

<h2 id="通过-JMX-进行监控和管理"><a href="#通过-JMX-进行监控和管理" class="headerlink" title="通过 JMX 进行监控和管理"></a>通过 JMX 进行监控和管理</h2><p>Java 管理扩展 (JMX) 提供了一种标准机制来监视和管理应用程序。默认情况下，此功能未启用。您可以通过将 <code>spring.jmx.enabled</code> 配置属性设置为 true 来打开它。 Spring Boot 将最合适的 <code>MBeanServer</code> 暴露为 ID 为 <code>mbeanServer</code> 的 bean。使用 Spring JMX 注释（<code>@ManagedResource</code>、<code>@ManagedAttribute</code> 或 <code>@ManagedOperation</code>）注释的任何 bean 都会暴露给它。</p>
<p>如果您的平台提供标准 <code>MBeanServer</code>，则 Spring Boot 会使用该标准并在必要时默认使用 VM <code>MBeanServer</code>。如果一切都失败了，则创建一个新的 <code>MBeanServer</code>。</p>
<p>有关更多详细信息，请参阅 <a target="_blank" rel="noopener" href="https://github.com/spring-projects/spring-boot/tree/v2.7.0/spring-boot-project/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/jmx/JmxAutoConfiguration.java"><code>JmxAutoConfiguration</code></a> 类。</p>
<p>默认情况下，Spring Boot 还将管理端点公开为 <code>org.springframework.boot</code> 域下的 JMX MBean。要完全控制 JMX 域中的端点注册，请考虑注册您自己的 <code>EndpointObjectNameFactory</code> 实现。</p>
<h3 id="定制化-MBean-Names"><a href="#定制化-MBean-Names" class="headerlink" title="定制化 MBean Names"></a>定制化 MBean Names</h3><p>MBean 的名称通常由端点的 id 生成。例如，健康端点公开为 <code>org.springframework.boot:type=Endpoint,name=Health</code>。</p>
<p>如果您的应用程序包含多个 Spring <code>ApplicationContext</code>，您可能会发现名称冲突。要解决此问题，您可以将 <code>spring.jmx.unique-names</code> 属性设置为 true，以便 MBean 名称始终是唯一的。</p>
<p>如果需要定制，跨域按如下配置：</p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">spring.jmx.unique-names</span>=<span class="string">true</span></span><br><span class="line"><span class="attr">management.endpoints.jmx.domain</span>=<span class="string">com.example.myapp</span></span><br></pre></td></tr></table></figure>

<h3 id="禁用-JMX-端点"><a href="#禁用-JMX-端点" class="headerlink" title="禁用 JMX 端点"></a>禁用 JMX 端点</h3><p>想禁用 JMX 端点，可以按如下配置：</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">management<span class="selector-class">.endpoints</span><span class="selector-class">.jmx</span><span class="selector-class">.exposure</span>.exclude=*</span><br></pre></td></tr></table></figure>

<h3 id="将-Jolokia-用于基于-HTTP-的-JMX"><a href="#将-Jolokia-用于基于-HTTP-的-JMX" class="headerlink" title="将 Jolokia 用于基于 HTTP 的 JMX"></a>将 Jolokia 用于基于 HTTP 的 JMX</h3><p>Jolokia 是一个 JMX-HTTP 的桥接工具，它提供了另一种访问 JMX bean 的方法。要使用 Jolokia，需要先添加依赖：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.jolokia<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>jolokia-core<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">&lt;/dependency</span><br></pre></td></tr></table></figure>

<p>然后，您可以通过将 <code>jolokia</code> 或 <code>*</code> 添加到 <code>Management.Endpoints.web.exposure.include</code> 属性来暴露 Jolokia 端点。然后，您可以在管理 HTTP 服务器上使用 <code>/actuator/jolokia</code> 访问它。</p>
<h2 id="日志"><a href="#日志" class="headerlink" title="日志"></a>日志</h2><p>Spring Boot Actuator 支持查看和配置应用日志级别。</p>
<p>日志级别的可选值如下：</p>
<ul>
<li><code>TRACE</code></li>
<li><code>DEBUG</code></li>
<li><code>INFO</code></li>
<li><code>WARN</code></li>
<li><code>ERROR</code></li>
<li><code>FATAL</code></li>
<li><code>OFF</code></li>
<li><code>null</code></li>
</ul>
<p><code>null</code> 表示没有显式配置。</p>
<h2 id="指标"><a href="#指标" class="headerlink" title="指标"></a>指标</h2><h2 id="审计"><a href="#审计" class="headerlink" title="审计"></a>审计</h2><p>Spring Boot Actuator 支持简单的审计功能。如果应用中启用了 Spring Security，Spring Boot Actuator 就会发布安全事件（如：“身份验证成功”、“失败”和“访问被拒绝”异常）。</p>
<p>可以通过在应用的配置中提供 <code>AuditEventRepository</code> 类型的 bean 来启用审计。为方便起见，Spring Boot 提供了一个 <code>InMemoryAuditEventRepository</code>。 <code>InMemoryAuditEventRepository</code> 的功能有限，建议仅将其用于开发环境。</p>
<p>如果要自定义安全事件，可以提供 <code>AbstractAuthenticationAuditListener</code> 和 <code>AbstractAuthorizationAuditListener</code> 实现。</p>
<p>此外，还可以将审计服务用于业务活动。为此，要么将 <code>AuditEventRepository</code> bean 注入组件并直接使用它，要么使用 Spring <code>ApplicationEventPublisher</code> 发布 <code>AuditApplicationEvent</code>（通过实现 <code>ApplicationEventPublisherAware</code>）。</p>
<h2 id="HTTP-追踪"><a href="#HTTP-追踪" class="headerlink" title="HTTP 追踪"></a>HTTP 追踪</h2><p>用户可以通过在应用中提供 <code>HttpTraceRepository</code> 类型的 bean 来启用 HTTP 跟踪。Spring Boot 提供了内置的 <code>InMemoryHttpTraceRepository</code>，它可以存储最近 100 次（默认）请求-响应的追踪数据。与其他 HTTP 追踪解决方案相比，<code>InMemoryHttpTraceRepository</code> 比较受限，建议仅用于开发环境。对于生产环境，建议使用 Zipkin 或 Spring Cloud Sleuth。</p>
<p>或者，可以自定义 <code>HttpTraceRepository</code>。</p>
<h2 id="处理监控"><a href="#处理监控" class="headerlink" title="处理监控"></a>处理监控</h2><p>在 spring-boot 模块中，您可以找到两个类来创建对进程监控有用的文件：</p>
<ul>
<li><code>ApplicationPidFileWriter</code> 创建一个包含应用程序 PID 的文件（默认情况下，在应用程序目录中，文件名为 <code>application.pid</code>）。</li>
<li><code>WebServerPortFileWriter</code> 创建一个文件（或多个文件），其中包含正在运行的 Web 服务器的端口（默认情况下，在应用程序目录中，文件名为 <code>application.port</code>）。</li>
</ul>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul>
<li><a target="_blank" rel="noopener" href="https://docs.spring.io/spring-boot/docs/current/reference/html/actuator.html#actuator">Spring Boot 官方文档之 Production-ready Features</a></li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://dunwu.github.io/blog/pages/08d9df23/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/blog/uploads/avatar.gif">
      <meta itemprop="name" content="钝悟 ◾ Dunwu">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Dunwu Blog">
      <meta itemprop="description" content="钝悟的个人博客">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | Dunwu Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/blog/pages/08d9df23/" class="post-title-link" itemprop="url">分布式分区</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-06-14 08:49:21" itemprop="dateCreated datePublished" datetime="2022-06-14T08:49:21+08:00">2022-06-14</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-09-13 17:56:53" itemprop="dateModified" datetime="2025-09-13T17:56:53+08:00">2025-09-13</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/blog/categories/%E5%88%86%E5%B8%83%E5%BC%8F/" itemprop="url" rel="index"><span itemprop="name">分布式</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/blog/categories/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F%E5%8D%8F%E5%90%8C/" itemprop="url" rel="index"><span itemprop="name">分布式协同</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/blog/categories/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F%E5%8D%8F%E5%90%8C/%E5%88%86%E5%B8%83%E5%BC%8F%E5%8D%8F%E5%90%8C%E7%BB%BC%E5%90%88/" itemprop="url" rel="index"><span itemprop="name">分布式协同综合</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>7.6k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>7 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="分布式分区"><a href="#分布式分区" class="headerlink" title="分布式分区"></a>分布式分区</h1><h2 id="什么是分区"><a href="#什么是分区" class="headerlink" title="什么是分区"></a>什么是分区</h2><p>分区通常是这样定义的，即每一条数据（或者每条记录，每行或每个文档）只属于某个特定分区。实际上，每个分区都可以视为一个完整的小型数据库，虽然数据库可能存在一些跨分区的操作。</p>
<p>在不同系统中，分区有着不同的称呼，例如它对应于 MongoDB, Elasticsearch 和 SolrCloud 中的 shard, HBase 的 region, Bigtable 中的 tablet, Cassandra 和 Riak 中的 vnode ，以及 Couch base 中的 vBucket。总体而言，分区是最普遍的术语。</p>
<h2 id="为什么需要分区"><a href="#为什么需要分区" class="headerlink" title="为什么需要分区"></a>为什么需要分区</h2><p>数据量如果太大，单台机器进行存储和处理就会成为瓶颈，因此需要引入数据分区机制。</p>
<p>分区的目地是通过多台机器均匀分布数据和查询负载，避免出现热点。这需要选择合适的数据分区方案，在节点添加或删除时重新动态平衡分区。</p>
<h2 id="数据分区与数据复制"><a href="#数据分区与数据复制" class="headerlink" title="数据分区与数据复制"></a>数据分区与数据复制</h2><p>分区通常与复制结合使用，即每个分区在多个节点都存有副本。这意味着某条记录属于特定的分区，而同样的内容会保存在不同的节点上以提高系统的容错性。</p>
<p>一个节点上可能存储了多个分区。每个分区都有自己的主副本，例如被分配给某节点，而从副本则分配在其他一些节点。一个节点可能既是某些分区的主副本，同时又是其他分区的从副本。</p>
<h2 id="键－值数据的分区"><a href="#键－值数据的分区" class="headerlink" title="键－值数据的分区"></a>键－值数据的分区</h2><p>分区的主要目标是将数据和查询负载均匀分布在所有节点上。如果节点平均分担负载，那么理论上 10 个节点应该能够处理 10 倍的数据量和 10 倍于单个节点的读写吞吐量（忽略复制） 。</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/202405122230559.png"></p>
<p>而如果分区不均匀，则会出现某些分区节点比其他分区承担更多的数据量或查询负载，称之为<strong>倾斜</strong>。倾斜会导致分区效率严重下降，在极端情况下，所有的负载可能会集中在一个分区节点上，这就意味着 10 个节点 9 个空闲，系统的瓶颈在最繁忙的那个节点上。这种负载严重不成比例的分区即成为系统<strong>热点</strong>。</p>
<p>避免热点最简单的方法是将记录随机分配给所有节点。这种方法可以比较均匀地分布数据，但是有一个很大的缺点：当视图读取特定的数据时，没有办法知道数据保存在哪个节点上，所以不得不并行查询所有节点。</p>
<p>可以改进上述方法。现在我们假设数据是简单的键-值数据模型，这意味着总是可以通过关键字来访问记录。</p>
<h3 id="基于关键字区间分区"><a href="#基于关键字区间分区" class="headerlink" title="基于关键字区间分区"></a>基于关键字区间分区</h3><p>一种分区方式是为每个分区分配一段连续的关键字或者关键宇区间范围（以最小值和最大值来指示）。</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/202405122230081.png"></p>
<p>关键字的区间段不一定非要均匀分布，这主要是因为数据本身可能就不均匀。</p>
<p>分区边界可以由管理员手动确定，或由数据库自动选择。采用这种分区策略的系统包括 Bigtable、HBase、RethinkDB、2.4 版本前的 MongoDB。</p>
<p>每个分区内可以按照关键字排序保存（参阅第 3 章的“ SSTables 和 LSM Trees ”）。这样可以轻松支持区间查询，即将关键字作为一个拼接起来的索引项从而一次查询得到多个相关记录。</p>
<p>然而，基于关键字的区间分区的缺点是某些访问模式会导致热点。如果关键字是时间戳，则分区对应于一个时间范围，所有的写入操作都集中在同一个分区（即当天的分区），这会导致该分区在写入时负载过高，而其他分区始终处于空闲状态。为了避免上述问题，需要使用时间戳以外的其他内容作为关键字的第一项。</p>
<h3 id="基于关键字晗希值分区"><a href="#基于关键字晗希值分区" class="headerlink" title="基于关键字晗希值分区"></a>基于关键字晗希值分区</h3><p>对于上述数据倾斜和热点问题，许多分布式系统采用了基于关键字哈希函数的方式来分区。</p>
<p>一个好的哈希函数可以处理数据倾斜并使其均匀分布。用于数据分区目的的哈希函数不需要再加密方面很强：例如 ：Cassandra 和 MongoDB 使用 MD5，Voldemort 使用 Fowler-Noll-Vo。许多编程语言也有内置的简单哈希函数，但是要注意这些内置的哈希函数可能并不适合分区，例如，Java 的 Object.hashCode 和 Object#hash，同一个键在不同的进程中可能返回不同的哈希值。</p>
<p>一且找到合适的关键宇哈希函数，就可以为每个分区分配一个哈希范围（而不是直接作用于关键宇范围），关键字根据其哈希值的范围划分到不同的分区中。</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20220303105925.png" alt="img"></p>
<p>这种方法可以很好地将关键字均匀地分配到多个分区中。分区边界可以是均匀间隔，也可以是伪随机选择（ 在这种情况下，该技术有时被称为一致性哈希） 。</p>
<p>然而，通过关键宇哈希进行分区，我们丧失了良好的区间查询特性。即使关键字相邻，但经过哈希之后会分散在不同的分区中，区间查询就失去了原有的有序相邻的特性。在 MongoDB 中，如果启用了基于哈希的分片模式，则区间查询会发送到所有的分区上，而 Riak、Couchbase 和 Voldemort 干脆就不支持关键字上的区间查询。</p>
<p>Cassandra 则在两种分区策略之间做了一个折中。Cassandra 中的表可以声明为由多个列组成的复合主键。复合主键只有第一部分可用于哈希分区，而其他列则用作组合索引来对 Cassandra SSTable 中的数据进行排序。因此，它不支持在第一列上进行区间查询，但如果为第一列指定好了固定值，可以对其他列执行高效的区间查询。</p>
<p>组合索引为一对多的关系提供了一个优雅的数据模型。</p>
<h3 id="负载倾斜与热点"><a href="#负载倾斜与热点" class="headerlink" title="负载倾斜与热点"></a>负载倾斜与热点</h3><p>基于哈希的分区方法可以减轻热点，但无住做到完全避免。一个极端情况是，所有的读／写操作都是针对同一个关键字，则最终所有请求都将被路由到同一个分区。</p>
<p>一个简单的技术就是在关键字的开头或结尾处添加一个随机数。只需一个两位数的十进制随机数就可以将关键字的写操作分布到 100 个不同的关键字上，从而分配到不同的分区上。但是，随之而来的问题是，之后的任何读取都需要些额外的工作，必须从所有 100 个关键字中读取数据然后进行合井。因此通常只对少量的热点关键字附加随机数才有意义；而对于写入吞吐量低的绝大多数关键字，这些都意味着不必要的开销。此外，还需要额外的元数据来标记哪些关键字进行了特殊处理。</p>
<h2 id="分区与二级索引"><a href="#分区与二级索引" class="headerlink" title="分区与二级索引"></a>分区与二级索引</h2><p>二级索引通常不能唯一标识一条记录，而是用来加速特定值的查询。</p>
<p>二级索引是关系数据库的必要特性，在文档数据库中应用也非常普遍。但考虑到其复杂性，许多键-值存储（如 HBase 和 Voldemort）并不支持二级索引；但其他一些如 Riak 则开始增加对二级索引的支持。此外，二级索引技术也是 Solr 和 Elasticsearch 等全文索引服务器存在之根本。</p>
<p>二级索引带来的主要挑战是它们不能规整的地映射到分区中。有两种主要的方法来支持对二级索引进行分区：基于文档的分区和基于词条的分区。</p>
<h3 id="基于文档分区的二级索引"><a href="#基于文档分区的二级索引" class="headerlink" title="基于文档分区的二级索引"></a>基于文档分区的二级索引</h3><p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20220303111528.png" alt="img"></p>
<p>在这种索引方法中，每个分区完全独立，各自维护自己的二级索引，且只负责自己分区内的文档而不关心其他分区中数据。每当需要写数据库时，包括添加，删除或更新文档等，只需要处理包含目标文档 ID 的那一个分区。因此文档分区索引也被称为本地索引，而不是全局索引。</p>
<p>这种查询分区数据库的方法有时也称为分散&#x2F;聚集，显然这种二级索引的查询代价高昂。即使采用了并行查询，也容易导致读延迟显著放大。尽管如此，它还是广泛用于实践： MongoDB 、Riak、Cassandra、Elasticsearch 、SolrCloud 和 VoltDB 都支持基于文档分区二级索引。大多数数据库供应商都建议用户自己来构建合适的分区方案，尽量由单个分区满足二级索引查询，但现实往往难以如愿，尤其是当查询中可能引用多个二级索引时。</p>
<h3 id="基于词条的二级索引分区"><a href="#基于词条的二级索引分区" class="headerlink" title="基于词条的二级索引分区"></a>基于词条的二级索引分区</h3><p>另一种方法，可以对所有的数据构建全局索引，而不是每个分区维护自己的本地索引。而且，为避免成为瓶颈，不能将全局索引存储在一个节点上，否则就破坏了设计分区均衡的目标。所以，全局索引也必须进行分区，且可以与数据关键字采用不同的分区策略。</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20220303112708.png" alt="img"></p>
<p>词条分区以待查找的关键字本身作为索引。名字词条源于全文索引，term 指的是文档中出现的所有单词的集合。</p>
<p>可以直接通过关键词来全局划分索引，或者对其取哈希值。直接分区的好处是可以支持高效的区间查询；而采用哈希的方式则可以更均句的划分分区。</p>
<p>这种全局的词条分区相比于文档分区索引的主要优点是，它的读取更为高效，即它不需要采用 scatter&#x2F;gather 对所有的分区都执行一遍查询，客户端只需要想包含词条的那一个分区发出读请求。然而全局索引的不利之处在于， 写入速度较慢且非常复杂，主要因为单个文档的更新时，里面可能会涉及多个二级索引，而二级索引的分区又可能完全不同甚至在不同的节点上，由此势必引人显著的写放大。</p>
<p>理想情况下，索引应该时刻保持最新，即写入的数据要立即反映在最新的索引上。但是，对于词条分区来讲，这需要一个跨多个相关分区的分布式事务支持，写入速度会受到极大的影响，所以现有的数据库都不支持同步更新二级索引。</p>
<h2 id="分区再均衡"><a href="#分区再均衡" class="headerlink" title="分区再均衡"></a>分区再均衡</h2><p>集群节点数变化，数据规模增长等情况，都会导致分区的分布不均。要保持分区的均衡，势必要将数据和请求进行迁移，这样一个迁移负载的过程称为<strong>分区再均衡</strong>。</p>
<p>无论对于哪种分区方案， 分区再平衡通常至少要满足：</p>
<ul>
<li>平衡之后，负载、数据存储、读写请求等应该在集群范围更均匀地分布。</li>
<li>再平衡执行过程中，数据库应该可以继续正常提供读写服务。</li>
<li>避免不必要的负载迁移，以加快动态再平衡，井尽量减少网络和磁盘 I&#x2F;O 影响。</li>
</ul>
<h3 id="动态再平衡的策略"><a href="#动态再平衡的策略" class="headerlink" title="动态再平衡的策略"></a>动态再平衡的策略</h3><h4 id="为什么不用取模？"><a href="#为什么不用取模？" class="headerlink" title="为什么不用取模？"></a>为什么不用取模？</h4><p>最好将哈希值划分为不同的区间范围，然后将每个区间分配给一个分区。</p>
<p>为什么不直接使用 mod？对节点数取模方法的问题是，如果节点数 N 发生了变化，会导致很多关键字需要从现有的节点迁移到另一个节点。</p>
<h4 id="固定数量的分区"><a href="#固定数量的分区" class="headerlink" title="固定数量的分区"></a>固定数量的分区</h4><p>创建远超实际节点数的分区数，然后为每个节点分配多个分区。</p>
<p>接下来， 如果集群中添加了一个新节点，该新节点可以从每个现有的节点上匀走几个分区，直到分区再次达到全局平衡。</p>
<p>选中的整个分区会在节点之间迁移，但分区的总数量仍维持不变，也不会改变关键字到分区的映射关系。这里唯一要调整的是分区与节点的对应关系。考虑到节点间通过网络传输数据总是需要些时间，这样调整可以逐步完成，在此期间，旧分区仍然可以接收读写请求。</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/202405122231579.png"></p>
<p>原则上，也可以将集群中的不同的硬件配置因素考虑进来，即性能更强大的节点将分配更多的分区，从而分担更多的负载。</p>
<p>目前，Riak、Elasticsearch、Couchbase 和 Voldemort 都支持这种动态平衡方法。</p>
<p>使用该策略时，分区的数量往往在数据库创建时就确定好，之后不会改变。原则上也可以拆分和合并分区（稍后介绍），但固定数量的分区使得相关操作非常简单，因此许多采用固定分区策略的数据库决定不支持分区拆分功能。所以，在初始化时，已经充分考虑将来扩容增长的需求（未来可能拥有的最大节点数），设置一个足够大的分区数。而每个分区也有些额外的管理开销，选择过高的数字可能会有副作用。</p>
<h4 id="动态分区"><a href="#动态分区" class="headerlink" title="动态分区"></a>动态分区</h4><p>对于采用关键宇区间分区的数据库，如果边界设置有问题，最终可能会出现所有数据都挤在一个分区而其他分区基本为空，那么设定固定边界、固定数量的分区将非常不便：而手动去重新配置分区边界又非常繁琐。</p>
<p>因此， 一些数据库如 HBase 和 RethinkDB 等采用了动态创建分区。当分区的数据增长超过一个可配的参数阔值（HBase 上默认值是 10GB），它就拆分为两个分区，每个承担一半的数据量。相反，如果大量数据被删除，并且分区缩小到某个阈值以下，则将其与相邻分区进行合井。该过程类似于 B 树的分裂操作。</p>
<p>每个分区总是分配给一个节点，而每个节点可以承载多个分区，这点与固定数量的分区一样。当一个大的分区发生分裂之后，可以将其中的一半转移到其他某节点以平衡负载。对于 HBase，分区文件的传输需要借助 HDFS。</p>
<p>动态分区的一个优点是分区数量可以自动适配数据总量。如果只有少量的数据，少量的分区就足够了，这样系统开销很小；如果有大量的数据，每个分区的大小则被限制在一个可配的最大值。</p>
<p>但是，需要注意的是，对于一个空的数据库， 因为没有任何先验知识可以帮助确定分区的边界，所以会从一个分区开始。可能数据集很小，但直到达到第一个分裂点之前，所有的写入操作都必须由单个节点来处理， 而其他节点则处于空闲状态。为了缓解这个问题，HBase 和 MongoDB 允许在一个空的数据库上配置一组初始分区（这被称为预分裂）。对于关键字区间分区，预分裂要求已经知道一些关键字的分布情况。</p>
<p>动态分区不仅适用于关键字区间分区，也适用于基于哈希的分区策略。MongoDB 从版本 2.4 开始，同时支持二者，井且都可以动态分裂分区。</p>
<h4 id="按节点比例分区"><a href="#按节点比例分区" class="headerlink" title="按节点比例分区"></a>按节点比例分区</h4><p>采用动态分区策略，拆分和合并操作使每个分区的大小维持在设定的最小值和最大值之间，因此分区的数量与数据集的大小成正比关系。另一方面，对于固定数量的分区方式，其每个分区的大小也与数据集的大小成正比。两种情况，分区的数量都与节点数无关。</p>
<p>Cassandra 和 Ketama 则采用了第三种方式，使分区数与集群节点数成正比关系。换句话说，每个节点具有固定数量的分区。此时， 当节点数不变时，每个分区的大小与数据集大小保持正比的增长关系； 当节点数增加时，分区则会调整变得更小。较大的数据量通常需要大量的节点来存储，因此这种方法也使每个分区大小保持稳定。</p>
<p>当一个新节点加入集群时，它随机选择固定数量的现有分区进行分裂，然后拿走这些分区的一半数据量，将另一半数据留在原节点。随机选择可能会带来不太公平的分区分裂，但是当平均分区数量较大时（Cassandra 默认情况下，每个节点有 256 个分区），新节点最终会从现有节点中拿走相当数量的负载。Cassandra 在 3.0 时推出了改进算洁，可以避免上述不公平的分裂。</p>
<p>随机选择分区边界的前提要求采用基于哈希分区（可以从哈希函数产生的数字范围里设置边界）。这种方法也最符合本章开头所定义一致性哈希。一些新设计的哈希函数也可以以较低的元数据开销达到类似的效果。</p>
<h3 id="自动与手动再平衡操作"><a href="#自动与手动再平衡操作" class="headerlink" title="自动与手动再平衡操作"></a>自动与手动再平衡操作</h3><p>动态平衡另一个重要问题我们还没有考虑：它是自动执行还是手动方式执行？</p>
<p>全自动式再平衡会更加方便，它在正常维护之外所增加的操作很少。但是，也有可能出现结果难以预测的情况。再平衡总体讲是个比较昂贵的操作，它需要重新路由请求井将大量数据从一个节点迁移到另一个节点。万一执行过程中间出现异常，会使网络或节点的负载过重，井影响其他请求的性能。</p>
<p>将自动平衡与自动故障检测相结合也可能存在一些风险。例如，假设某个节点负载过重，对请求的响应暂时受到影响，而其他节点可能会得到结论：该节点已经失效；接下来激活自动平衡来转移其负载。客观上这会加重该节点、其他节点以及网络的负荷，可能会使总体情况变得更槽，甚至导致级联式的失效扩散。</p>
<h2 id="请求路由"><a href="#请求路由" class="headerlink" title="请求路由"></a>请求路由</h2><p>当数据集分布到多个节点上，需要解决一个问题：当客户端发起请求时，如何知道应该连接哪个节点？如果发生了分区再平衡，分区与节点的对应关系随之还会变化。为了回答该问题，我们需要一段处理逻辑来感知这些变化，并负责处理客户端的连接。</p>
<p>这其实属于一类典型的服务发现问题，服务发现并不限于数据库，任何通过网络访问的系统都有这样的需求，尤其是当服务目标支持高可用时（在多台机器上有冗余配置）。</p>
<p>服务发现有以下处理策略：</p>
<ol>
<li>允许客户端链接任意的节点（例如，采用循环式的负载均衡器）。如果某节点恰好拥有所请求的分区，则直接处理该请求：否则，将请求转发到下一个合适的节点，接收答复，并将答复返回给客户端。</li>
<li>将所有客户端的请求都发送到一个路由层，由后者负责将请求转发到对应的分区节点上。路由层本身不处理任何请求，它仅充一个分区感知的负载均衡器。</li>
<li>客户端感知分区和节点分配关系。此时，客户端可以直接连接到目标节点，而不需要任何中介。</li>
</ol>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20220304120137.png" alt="img"></p>
<p>许多分布式数据系统依靠独立的协调服务（如 ZooKeeper ）跟踪集群范围内的元数据。每个节点都向 ZooKeeper 中注册自己， ZooKeeper 维护了分区到节点的最终映射关系。其他参与者（如路由层或分区感知的客户端）可以向 ZooKeeper 订阅此信息。一旦分区发生了改变，或者添加、删除节点， ZooKeeper 就会主动通知路由层，这样使路由信息保持最新状态。</p>
<p>例如，HBase、SolrCloud 和 Kafka 也使用 ZooKeeper 来跟踪分区分配情况。MongoDB 有类似的设计，但它依赖于自己的配置服务器和 mongos 守护进程来充当路由层。</p>
<p>Cassandra 和 Riak 则采用了不同的方法，它们在节点之间使用 gossip 协议来同步群集状态的变化。请求可以发送到任何节点，由该节点负责将其转发到目标分区节点。这种方式增加了数据库节点的复杂性，但是避免了对 ZooKeeper 之类的外部协调服务的依赖。</p>
<p><img src="https://raw.githubusercontent.com/dunwu/images/master/snap/20220304163629.png" alt="img"></p>
<h2 id="并行查询执行"><a href="#并行查询执行" class="headerlink" title="并行查询执行"></a>并行查询执行</h2><p>到目前为止，我们只关注了读取或写入单个关键字这样简单的查询（对于文档分区的二级索引，里面要求分散／聚集查询）。这基本上也是大多数 NoSQL 分布式数据存储所支持的访问类型。</p>
<p>然而对于大规模并行处理（massively parallel processing, MPP）这一类主要用于数据分析的关系数据库，在查询类型方面要复杂得多。典型的数据仓库查询包含多个联合、过滤、分组和聚合操作。MPP 查询优化器会将复杂的查询分解成许多执行阶段和分区，以便在集群的不同节点上井行执行。尤其是涉及全表扫描这样的查询操作，可以通过并行执行获益颇多。</p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>数据量如果太大，单台机器进行存储和处理就会成为瓶颈，因此需要引入数据分区机制。分区的目地是通过多台机器均匀分布数据和查询负载，避免出现热点。这需要选择合适的数据分区方案，在节点添加或删除时重新动态平衡分区。</p>
<p>两种主要的分区方法：</p>
<ul>
<li><strong>基于关键字区间的分区</strong>。先对关键字进行排序，每个分区只负责一段包含最小到最大关键字范围的一段关键字。对关键字排序的优点是可以支持高效的区间查询，但是如果应用程序经常访问与排序一致的某段关键字，就会存在热点的风险。采用这种方怯，当分区太大时，通常将其分裂为两个子区间，从而动态地再平衡分区。</li>
<li><strong>哈希分区</strong>。将哈希函数作用于每个关键字，每个分区负责一定范围的哈希值。这种方法打破了原关键字的顺序关系，它的区间查询效率比较低，但可以更均匀地分配负载。采用哈希分区时，通常事先创建好足够多（但固定数量）的分区，让每个节点承担多个分区，当添加或删除节点时将某些分区从一个节点迁移到另一个节点，也可以支持动态分区。</li>
</ul>
<p>混合上述两种基本方住也是可行的，例如使用复合键：键的一部分来标识分区，而另一部分来记录排序后的顺序。</p>
<p>二级索引也需要进行分区，有两种方法：</p>
<ul>
<li>基于文档来分区二级索引（本地索引）。二级索引存储在与关键字相同的分区中，这意味着写入时我们只需要更新一个分区，但缺点是读取二级索引时需要在所有分区上执行 scatter&#x2F;gather。</li>
<li>基于词条来分区二级索引（全局索引）。它是基于索引的值而进行的独立分区。二级索引中的条目可能包含来自关键字的多个分区里的记录。在写入时，不得不更新二级索引的多个分区；但读取时，则可以从单个分区直接快速提取数据。</li>
</ul>
<p>最后，讨论了如何将查询请求路由到正确的分区，包括简单的分区感知负载均衡器，以及复杂的并行查询执行引擎。</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul>
<li><a target="_blank" rel="noopener" href="https://book.douban.com/subject/30329536/">《数据密集型应用系统设计》</a> - 这可能是目前最好的分布式存储书籍，强力推荐【进阶】</li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <a class="extend prev" rel="prev" title="上一页" aria-label="上一页" href="/blog/page/12/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/blog/">1</a><span class="space">&hellip;</span><a class="page-number" href="/blog/page/12/">12</a><span class="page-number current">13</span><a class="page-number" href="/blog/page/14/">14</a><span class="space">&hellip;</span><a class="page-number" href="/blog/page/51/">51</a><a class="extend next" rel="next" title="下一页" aria-label="下一页" href="/blog/page/14/"><i class="fa fa-angle-right"></i></a>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 2015 – 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">钝悟 ◾ Dunwu</span>
  </div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
      <span>站点总字数：</span>
    <span title="站点总字数">4.5m</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span>站点阅读时长 &asymp;</span>
    <span title="站点阅读时长">68:08</span>
  </span>
</div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="reading-progress-bar"></div>

  <a href="https://github.com/dunwu/blog" class="github-corner" title="在 GitHub 上关注我" aria-label="在 GitHub 上关注我" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>
<script src="https://cdn.jsdelivr.net/npm/darkmode-js@1.5.7/lib/darkmode-js.min.js"></script>

<script>
var options = {
  bottom: '64px',
  right: 'unset',
  left: '32px',
  time: '0.5s',
  mixColor: 'transparent',
  backgroundColor: 'transparent',
  buttonColorDark: '#100f2c',
  buttonColorLight: '#fff',
  saveInCookies: true,
  label: '🌓',
  autoMatchOsTheme: true
}
const darkmode = new Darkmode(options);
window.darkmode = darkmode;
darkmode.showWidget();
</script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1.8.0/dist/gitalk.css" integrity="sha256-AJnUHL7dBv6PGaeyPQJcgQPDjt/Hn/PvYZde1iqfp8U=" crossorigin="anonymous">

<script class="next-config" data-name="gitalk" type="application/json">{"enable":true,"github_id":"dunwu","repo":"blog","client_id":"c45bc13ca1d3d3aa4836","client_secret":"1907a9f0c22087badad3938e1d7dcba9078f88ac","admin_user":"dunwu","distraction_free_mode":true,"proxy":"https://cors-anywhere.azm.workers.dev/https://github.com/login/oauth/access_token","language":"zh-CN","js":{"url":"https://cdn.jsdelivr.net/npm/gitalk@1.8.0/dist/gitalk.min.js","integrity":"sha256-MVK9MGD/XJaGyIghSVrONSnoXoGh3IFxLw0zfvzpxR4="},"path_md5":"d3bac4b186fea6b9cfbbb1dd129a71db"}</script>
<script src="/blog/js/third-party/comments/gitalk.js" defer></script>

</body>
</html>
