---
title: 《大规模数据处理实战》笔记
date: 2023-03-15 15:15:07
order: 02
categories:
  - 笔记
  - 大数据
tags:
  - 大数据
permalink: /pages/0493ff/
---

# 《大规模数据处理实战》笔记

## 00 丨开篇词丨从这里开始，带你走上硅谷一线系统架构师之路

## 01 丨为什么 MapReduce 会被硅谷一线公司淘汰？

高昂的维护成本

时间性能“达不到”用户的期待

## 02 | MapReduce 后谁主沉浮：怎样设计下一代数据处理技术？

## 03 | 大规模数据处理初体验：怎样实现大型电商热销榜？

不同量级 TOP K 算法的解决方案不同：

小规模：Hash 即可

大规模：由于单机的处理量不足以处理全量数据，势必分而治之：分片统计，然后聚合（即先 map 后 reduce）

## 04 丨分布式系统（上）：学会用服务等级协议 SLA 来评估你的系统

SLA（Service-Level Agreement），也就是服务等级协议，指的是系统服务提供者（Provider）对客户（Customer）的一个服务承诺。

可用性：大厂一般要求可用性至少达到四个 9（即 99.99%）

准确性：准确率= 正确的有效请求数 / 有效的总请求数

系统容量：通常通过 QPS （Queries Per Second）来衡量

延迟：请求和响应的时间间隔

## 05 丨分布式系统（下）：架构师不得不知的三大指标

- 可扩展性（Scalability）
  - 水平扩展（Horizontal Scaling）
  - 垂直扩展（Vertical Scaling）
- 一致性（Consistency）
  - 强一致性（Strong Consistency）：系统中的某个数据被成功更新后，后续任何对该数据的读取操作都将得到更新
    后的值。所以在任意时刻，同一系统所有节点中的数据是一样的。
  - 弱一致性（Weak Consistency）：系统中的某个数据被更新后，后续对该数据的读取操作可能得到更新后的值，
    也可能是更改前的值。但经过“不一致时间窗口”这段时间后，后续对该数据的读取都是更新后的值。
  - 最终一致性（Eventual Consistency）：是弱一致性的特殊形式。存储系统保证，在没有新的更新的条件下，最终所有的访问都是最后更新的值。
- 持久性（Data Durability）：意味着数据一旦被成功存储就可以一直继续使用，即使系统中的节点下线、宕机或数据损坏也是如。

## 06 | 如何区分批处理还是流处理？

- 无边界数据（Unbounded Data）：是一种不断增长，可以说是无限的数据集。
- 有边界数据（Bounded Data）：是一种有限的数据集。
- 事件时间（Event Time）：指的是一个数据实际产生的时间点。
- 处理时间（Precessing Time）：指的是处理数据的系统架构实际接收到这个数据的时间点。
- 批处理：绝大部分情况下，批处理的输入数据都是有边界数据，同样的，输出结果也一样是有边界数据。所以在批处理中，我们所关心的更多会是数据的事件时间。
  - 应用场景：
    - 日志分析：日志系统是在一定时间段（日，周或年）内收集的，而日志的数据处理分析是在不同的时间内执行，以得出有关系统的一些关键性能指标。
    - 计费应用程序：计费应用程序会计算出一段时间内一项服务的使用程度，并生成计费信息，例如银行在每个月末生成的信用卡还款单。
    - 数据仓库：数据仓库的主要目标是根据收集好的数据事件时间，将数据信息合并为静态快照 （static snapshot），并将它们聚合为每周、每月、每季度的报告等。
- 流处理：流处理的输入数据基本上都是无边界数据。
  - 应用场景
    - 实时监控：捕获和分析各种来源发布的数据，如传感器，新闻源，点击网页等。
    - 实时商业智能：智能汽车，智能家居，智能病人护理等。
    - 销售终端（POS）系统：像是股票价格的更新，允许用户实时完成付款的系统等。

## 07 | Workflow 设计模式：让你在大规模数据世界中君临天下

略

## 08 | 发布/订阅模式：流处理架构中的瑞士军刀

略

## 09 丨 CAP 定理：三选二，架构师必须学会的取舍

略

## 10 丨 Lambda 架构：Twitter 亿级实时数据分析架构背后的倚天剑

Lambda 架构总共由三层系统组成：批处理层（Batch Layer），速度处理层（Speed Layer），以及用于响应查询的服务层（Serving Layer）。

## 11 丨 Kappa 架构：利用 Kafka 锻造的屠龙刀

略

## 12 | 我们为什么需要 Spark？

MapReduce 的缺点：

- 高昂的维护成本
- 时间性能“达不到”用户的期待
- MapReduce 模型的抽象层次低
- 只提供 Map 和 Reduce 两个操作
- 在 Hadoop 中，每一个 Job 的计算结果都会存储在 HDFS 文件存储系统中，所以每一步计算都要进行硬盘的读取和写入，大大增加了系统的延迟。
- 只支持批处理

Spark 的优点

- 性能比 MapReduce 高很多
- Spark 提供了很多对 RDD 的操作，如 Map、Filter、flatMap、groupByKey 和 Union 等等，极大地提升了对各种复杂场景的支持

## 13 丨弹性分布式数据集：Spark 大厦的地基（上）

Spark 最基本的数据抽象是弹性分布式数据集（Resilient Distributed Dataset）

RDD 表示已被分区、不可变的，并能够被并行操作的数据集合。

## 14 丨弹性分布式数据集：Spark 大厦的地基（下）

## 15 丨 SparkSQL：Spark 数据查询的利器

## 16 | Spark Streaming：Spark 的实时流计算 API

Spark Streaming 用时间片拆分了无限的数据流，然后对每一个数据片用类似于批处理的方法进行处理，输出的数据也是一块一块的

## 17 | Structured Streaming：如何用 DataFrame API 进行实时数据分析?

## 18 丨 WordCount：从零开始运行你的第一个 Spark 应用

## 19 丨综合案例实战：处理加州房屋信息，构建线性回归模型

## 20 丨流处理案例实战：分析纽约市出租车载客信息

---

读到此处，感觉收获甚少，暂时搁置阅读。

## 参考资料

- [大规模数据处理实战](https://time.geekbang.org/column/intro/100025301)