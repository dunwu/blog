---
title: HDFS 运维
date: 2020-02-24 21:14:47
order: 02
categories:
  - 大数据
  - hadoop
  - hdfs
tags:
  - 大数据
  - Hadoop
  - HDFS
permalink: /pages/90aeb6/
---

# HDFS 运维

## HDFS 命令

### 显示当前目录结构

```shell
# 显示当前目录结构
hdfs dfs -ls <path>
# 递归显示当前目录结构
hdfs dfs -ls -R <path>
# 显示根目录下内容
hdfs dfs -ls /
```

### 创建目录

```shell
# 创建目录
hdfs dfs -mkdir <path>
# 递归创建目录
hdfs dfs -mkdir -p <path>
```

### 删除操作

```shell
# 删除文件
hdfs dfs -rm <path>
# 递归删除目录和文件
hdfs dfs -rm -R <path>
```

### 导入文件到 HDFS

```shell
# 二选一执行即可
hdfs dfs -put [localsrc] [dst]
hdfs dfs -copyFromLocal [localsrc] [dst]
```

### 从 HDFS 导出文件

```shell
# 二选一执行即可
hdfs dfs -get [dst] [localsrc]
hdfs dfs -copyToLocal [dst] [localsrc]
```

### 查看文件内容

```shell
# 二选一执行即可
hdfs dfs -text <path>
hdfs dfs -cat <path>
```

### 显示文件的最后一千字节

```shell
hdfs dfs -tail <path>
# 和Linux下一样，会持续监听文件内容变化 并显示文件的最后一千字节
hdfs dfs -tail -f <path>
```

### 拷贝文件

```shell
hdfs dfs -cp [src] [dst]
```

### 移动文件

```shell
hdfs dfs -mv [src] [dst]
```

### 统计当前目录下各文件大小

- 默认单位字节
- -s : 显示所有文件大小总和，
- -h : 将以更友好的方式显示文件大小（例如 64.0m 而不是 67108864）

```
hdfs dfs -du <path>
```

### 合并下载多个文件

- -nl 在每个文件的末尾添加换行符（LF）
- -skip-empty-file 跳过空文件

```
hdfs dfs -getmerge
# 示例 将HDFS上的hbase-policy.xml和hbase-site.xml文件合并后下载到本地的/usr/test.xml
hdfs dfs -getmerge -nl  /test/hbase-policy.xml /test/hbase-site.xml /usr/test.xml
```

### 统计文件系统的可用空间信息

```
hdfs dfs -df -h /
```

### 更改文件复制因子

```
hdfs dfs -setrep [-R] [-w] <numReplicas> <path>
```

- 更改文件的复制因子。如果 path 是目录，则更改其下所有文件的复制因子
- -w : 请求命令是否等待复制完成

```
# 示例
hdfs dfs -setrep -w 3 /user/hadoop/dir1
```

### 权限控制

```
# 权限控制和Linux上使用方式一致
# 变更文件或目录的所属群组。 用户必须是文件的所有者或超级用户。
hdfs dfs -chgrp [-R] GROUP URI [URI ...]
# 修改文件或目录的访问权限  用户必须是文件的所有者或超级用户。
hdfs dfs -chmod [-R] <MODE[,MODE]... | OCTALMODE> URI [URI ...]
# 修改文件的拥有者  用户必须是超级用户。
hdfs dfs -chown [-R] [OWNER][:[GROUP]] URI [URI ]
```

### 文件检测

```
hdfs dfs -test - [defsz]  URI
```

可选选项：

- -d：如果路径是目录，返回 0。
- -e：如果路径存在，则返回 0。
- -f：如果路径是文件，则返回 0。
- -s：如果路径不为空，则返回 0。
- -r：如果路径存在且授予读权限，则返回 0。
- -w：如果路径存在且授予写入权限，则返回 0。
- -z：如果文件长度为零，则返回 0。

```
# 示例
hdfs dfs -test -e filename
```

## HDFS 安全模式

### 什么是安全模式？

- 安全模式是 HDFS 的一种特殊状态，在这种状态下，HDFS 只接收读数据请求，而不接收写入、删除、修改等变更请求。
- 安全模式是 HDFS 确保 Block 数据安全的一种保护机制。
- Active NameNode 启动时，HDFS 会进入安全模式，DataNode 主动向 NameNode 汇报可用 Block 列表等信息，在系统达到安全标准前，HDFS 一直处于“只读”状态。

### 何时正常离开安全模式

- Block 上报率：DataNode 上报的可用 Block 个数 / NameNode 元数据记录的 Block 个数
- 当 Block 上报率 >= 阈值时，HDFS 才能离开安全模式，默认阈值为 0.999
- 不建议手动强制退出安全模式

### 触发安全模式的原因

- NameNode 重启
- NameNode 磁盘空间不足
- Block 上报率低于阈值
- DataNode 无法正常启动
- 日志中出现严重异常
- 用户操作不当，如：**强制关机（特别注意！）**

### 故障排查

- 找到 DataNode 不能正常启动的原因，重启 DataNode
- 清理 NameNode 磁盘
- 谨慎操作，有问题找星环，以免丢失数据

## 参考资料

- [HDFS 官方文档](http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html)
- [HDFS 知识点总结](https://www.cnblogs.com/caiyisen/p/7395843.html)